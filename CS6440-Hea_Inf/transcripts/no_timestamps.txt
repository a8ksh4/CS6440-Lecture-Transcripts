Hi. Welcome to Introduction to Health Informatics.
I'm Mark Braunstein, and unlike your other Georgia Tech professors,
I was trained as a physician.
However, I came to medical school after MIT,
interested in applying computers to
medicine and ended up starting a few companies based on that work.
I started the last of these at Georgia Tech's Incubator,
the Advanced Technology Development Center.
And when it was acquired,
I joined the faculty to help create a program in Health Informatics.
This course is about Health Informatics,
which is the many applications of computing to the delivery of health care.
Since the 1950's, when computers could first store and process large amounts of data,
software developers have seen health care as a fertile domain.
Electronic medical records systems date back to at least the early 1960.
That's when Akron Children's Hospital and IBM created HIS,
the first computer based hospital patient information system.
Here, you can see it being tested by a nurse.
Another application is clinical decision support systems.
These guide physicians as they deliver care based on
scientific evidence and they date back to at least 1972, when work began on mycin.
Mycin, was a program for the optimal selection of antibiotics to treat infections.
Ambulatory electronic medical records systems for use outside of hospitals,
began a bit earlier.
In fact, as you can see here,
I oversaw the development and did some of the programming of one of these early EMRs,
starting in 1970 at the Medical University of South Carolina in Charleston.
Computer systems initially had limited capability,
so commercial vendors focused on a specific hospital department,
such as the laboratory or pharmacy.
As the use of these departmentally specific systems grew,
their inability to share data across vendors became problematic.
This led to the formation of the non-profit standards setting organization,
Health Level 7, and the development of
the first successful messaging standard for health data sharing.
This early standard was based on EDI X 12 technology for manufacturing in the 1980's.
You can see an example here,
and surprisingly, it's still in widespread use.
Over time, a few large vendors emerged with systems designed to meet
most of the major computing needs of a hospital and its associated clinics.
For reasons we will discuss later on,
meaningful clinical data sharing among these mega systems was problematic.
And independent access to the data they stored was very.
Today, all that is changing rapidly as the number
of health related open APIs and web tools explodes.
Of these, the most important is
fast health care interoperability resources or FHIR spelled
F-H-I-R. FHIR is a new standard based on
contemporary technologies and it's achieving dramatic acceptance and adoption.
FHIR offers the promise of open access to clinical data,
with the right permissions of course.
As you can see from these examples,
it is even turning electronic medical records systems into open app platforms,
similar to the smartphone in your pocket.
This is the first university level course based upon FHIR.
As we proceed, you will literally be working to help solve
real world health care challenges using the health informatics approaches of the future.
We'll now travel to Emory Health Systems,
EICU to look at an example of that from an earlier iteration of the course.
First, Mark, it's a pleasure to be here today.
I'd like to introduce my colleague, Cheryl Hiddleston,
who will tell you a little bit about what she does.
Hi. I'm Cheryl Hiddleston,
I have been a nurse for 33 years.
For 26 of those,
I've been in critical care,
and I currently run the Emory eICU program.
And my name is Tim Buckman.
I have the privilege being the founding director of Emory's Critical Care Center.
I'm the Medical Director of Emory's eICU program.
Perhaps, we ought to tell you a little bit about what an ICU is and what an eICU is.
That would be great.
You know, we all enjoy our health but at some point,
we all will face serious health problems.
And when our vital organs, heart, lungs, liver,
kidneys become compromised they can fail to the point where our lives are threatened.
That's where the ICU comes in.
Patients are admitted to intensive care units,
in order to stabilize their vital functions,
set the stage for healing and allow them to improve.
Now traditionally that's been all at the bedside, critical care nurses,
critical care physicians,
other allied health professionals working to stabilize the patient at the elbow.
But in the era of long distance telecommunication,
a new option has evolved. Cheryl, tell them about eICU.
The eICU is a program that provides
remote surveillance monitoring of patients in the ICUs at different hospitals.
We have cameras, monitors, and mics,
and speakers in each patient room that allows our team,
which is located remotely in
basically an office building to have bidirectional communication with the staff,
the family, and the patient who are in the ICUs.
With the monitoring that we do,
the system pulls different data from
the bedside monitor and
the electronic medical record and has different algorithms built in it,
and it allows us to catch when
patients are veering off trajectory into the wrong direction.
So we can call the staff at the bedside and help intervene.
Now it's a lot of data.
We have the same big data problem, the four Vs, the velocity, variety, veracity,
value that everyone has in the big data space.
The difference is we have to find problems and fix them right now.
Because if we don't deliver the right care right now for every patient every time,
the patient is going to suffer.
Let's talk about an example,
that is a prominent one in critical care.
We all have kidneys.
They allow us to not only get rid of excess water
but excess toxins and without good kidney function,
those toxins build up,
the various balance of electrolytes and fluids in the body goes awry.
And with total kidney failure, people can die.
So we have to find that problem and fix it right away.
One of the conventional measures
of kidney function is actually taken from the bloodstream,
a chemical called creatinine.
Creatinine is produced as a product of
normal metabolism by muscles and then excreted by the kidneys.
When the kidneys fail to function well, creatinine builds up.
And when the kidneys resume their function,
creatinine decreases in concentration in the bloodstream.
Now there are two or three problems.
The first is that creatinine isn't sampled continuously,
it isn't even sampled regularly, it's sampled irregularly.
So physicians at best have
an irregular time series from which to
try to reason whether the kidney function is getting better,
getting worse, or staying the same.
And if you look at the visualization on the left is conventional picture of creatinine,
a plot of creatinine measurements versus time.
And what you'll see is that creatinine rises when
kidneys fail in this sense when kidneys recover function.
But we needed a way to look more deeply into the data to discover whether there might be
hidden information in the time series that would allow us to
recognize even earlier first the kidney function is getting worse,
and even more importantly,
the kidney function is recovering.
Why do we want to know the kidney function is recovered?
We want to be able to
tell patients and families that things are getting better as soon as possible.
So we charged a team in the course with helping us develop a novel visualization.
That's shown on the right.
It's a phase diagram,
plotting the change in creatinine over time on the Y-axis
versus the concentration of creatinine on the X-axis.
And what you can see even as creatinine is rising,
there's an inflection point where the rate of change of that rise is falling.
That's our earliest signal that kidney function is
actually improving and being able to see these displays,
these phase diagrams allows us to recognize the problem earlier,
and even more importantly to recognize recovery earlier.
That matters to caregivers but it also
matters more to the patients for whom we deliver care.
I'll let Cheryl speak a bit about
the challenges we face even in
the standard clinical realm of bringing health care messages into our care environment.
As Tim said, normally for laboratory values,
they're checked intermittently, there's
no regular schedule that they're checked on necessarily.
It's done per a physician's orders and what they determine needs to be done.
So we have a database for all of the patients we provide care for and in order to
get more real-time access to that information and
have the data pushed out to us rather than having to wait for it to come in the system,
having someone look at it.
That's what we discussed with the students.
Now trying to get access to that database for
them was kind of a hurdle because it's patient information that's involved.
So we had to get compliance involved,
we had to get the IS resources involved to
make sure that the Georgia Tech students had access to the data,
so they could build the application.
So we could actually develop the tools.
Now what's interesting of course is that there are
international standards around healthcare messaging, so-called HL7 standard.
And we use that standard in our communications with the hospitals we serve.
The problem is that HL7 messaging has evolved
and Version 1 was primitive and Version 2 was manageable, Version 3, well,
it became seriously bloated,
often 60 pages of data just to report the single laboratory value.
And quite candidly, that's more than
current systems are able to manage efficiently and effectively in real-time.
Fortunately, the communities who
develop these standards recognized that they'd created a problem and said,
we have to do it faster.
We actually have to get Fast Healthcare Interoperability Resources up and running.
FHIR, that's what FHIR is all about.
And what our students have done,
they've helped us to take
our existing databases into which all the data are falling and said,
we can simplify not the incoming messages
because those are fixed by standards but outgoing messages.
We can help clinicians access those data faster and better by FHIR enabling the database.
And that really is a major event because data that's not available in
the moment is data that is
the delayed and decisions that are delayed and ultimately the care is delayed.
We recognize that every human being
is different but they get sick in a fairly patterned fashion.
So our job is to recognize the patterns.
You would think this would be easy but recognize that every human being has
time and we have a 13-dimensional problem with sparse data.
So picking up the patterns is tough.
We have a couple of things we can do though.
We can have machines recognize and pick out the patterns and our responses.
In fact, that's going to be much of the future of medicine,
to follow patterns and provide the responses that seem to be most common.
It's especially helpful in our environment because our patients are so complex
and threading down to the abstraction that matters,
the getting sick and what we can do to help
people get well is an important part of what we do.
What's going to happen in the future?
We think that there're couple of steps.
The first is a form of crowdsourcing.
We will ask our clinicians and ask the machines behind our clinicians to
keep track of what data patterns are clinically meaningful and which are not.
Second, we'll go into the data and begin to cull out the universal responses.
We'll find two or three responses to every problem.
But what we can do further and we can use the data
going forward to determine which of
the responses to the problem, actually leads to the better outcome.
This is emerging of knowledge based care.
Things have come from evidence-based medicine and code, things that have come,
this is emerging of knowledge based care,
things that have come from evidence data.
This is emerging of knowledge based care,
knowledge that's encoded in algorithms and decision trees with database care,
recognizing the 1,000 or 10,000,
or 100,000 nearest neighbors and
understanding what care has been provided and understanding the outcomes of those cared.
The eICU is a perfect training ground
for this because instead of asking clinicians at the bedside,
who are very busy taking care of patients,
"Oh, is this appropriate?"
"Is this an actionable item?"
It pulls them away from patient care.
So in the eICU, you have nurses,
who are trained in detecting when there's an anomaly and there's something different.
So it's a perfect area to try and build this sort of knowledge.
If we can improve our detection of anomalies,
improve our understanding of the options available to us,
and improve our understanding of the outcomes of those options.
We're going to get better outcomes for all of our patients.
In this lesson, we're going to talk about the U.S. healthcare system.
This is a complex topic that cannot be adequately covered in a single lecture.
So, I've provided suggested readings.
Some students wonder why I devote an entire lesson to
the US health care systems structure and economics in what is after all,
a health informatics course.
Many Georgia Tech students come to
this course with little background in the health care delivery system.
Health Informatics, the focus of this course is
the application of information technology to that delivery system.
I believe you need at least a basic grounding to appreciate the nature of
the system and the key roles Health Informatics can play in solving its problems.
To give some examples,
informatics can help avoid medical errors that often arise from inadequate information,
or the presence of more information than a human being can process.
It can help identifying reduce waste to unnecessary, or duplicative services.
It is critical to the surveillance of food borne analysis and disease outbreaks.
Data mining and many analytic techniques
are increasingly being used to find new medicines,
new treatment protocols, and new methods for earlier diagnosis.
These are just a few of the potential informatics benefits to health care delivery.
But each of them depends to one degree or another on the ability to share digital data.
As you'll see, now that most hospitals and around half of all providers have adopted
electronic record systems data sharing and interoperability is now the focus.
So, this course is largely about interoperability and
the role that the new HL seven fire standard plays in creating it.
To get ready for that,
we'll first discuss the US healthcare system and its problems.
And then, we'll begin the discussion of the role in
interoperable informatics landscape can play in solving them.
Americans often hear that we have the world's best healthcare system.
This is Dr. Brant James a
distinguished expert on healthcare quality at Intermountain Healthcare,
which is widely regarded as one of
the premier healthcare delivery systems in the United States.
Years ago he gave me the data for this graphic that shows that the
U.S. has the lowest mortality rates for high technology medicine,
the kind of care you need after a heart attack or major trauma.
That's the positive part of the story.
A Commonwealth Fund is
a private foundation that promotes a high performing healthcare system,
particularly for our most vulnerable citizens.
This graphic from its international research program shows that while the U.S. spends
around twice as much per capita on healthcare as six other industrialized nations.
Our overall rank is at the bottom on quality access efficiency and equity of care.
Our citizens also rank at the bottom with
respect to living long, healthy productive lives.
Lack of health insurance can increase health care costs.
This map shows that other than the U.S. virtually all developed
nations have universal health care that covers everyone.
The Affordable Care Act's major coverage provisions went into effect in
January 2014 and have led to significant coverage gains,
but as of the end of
The Institute of Medicine,
widely referred to as the IOM,
is the health care arm of the National Academy of Science,
which was founded in 1863 under President Lincoln.
According to the IOM the uninsured on average use
less health care than do insured persons and members of fully insured families.
That's lost utilization may be hidden from view,
but it can prove costly in terms of subs with ill health disability and premature death.
The Kaiser Family Foundation is
a nonprofit organization focusing on national health issues,
as well as the U.S. role in global health policy.
This 2013 Kaiser Family Foundation data shows
that uninsured people receive substantially less healthcare than the insured.
This 2015 data shows that the uninsured are likely to have no regular source of care,
to postpone or do without needed care,
or to postpone or not get needed prescriptions due to cost.
Kaiser Family Foundation goes on to say that
insured and uninsured people who are injured or newly diagnosed with a chronic condition,
such as diabetes or hypertension,
receive similar plans for follow-up care from their physician.
People without health coverage are less likely to obtain
all the recommended services than those with coverage.
Finally, because the uninsured are less likely to have regular outpatient care,
they are more likely to end up with expensive hospitalizations for
avoidable health problems and to experienced declines in their overall health.
When hospitalized, uninsured people receive
fewer diagnostic and therapeutic services
and have higher mortality rates than those with insurance.
Prior to World War II,
U.S. patients paid for most healthcare which was relatively inexpensive,
until the beginning of high tech medicine in the 1970s.
After the war, the U.S. economy experienced
explosive growth and employers were competing for workers.
Health insurance became an attractive but inexpensive employee benefit.
In the early 1960's,
the Federal Government created two major new health insurance programs,
Medicare for citizens over 65 and
Medicaid primarily for the poor and those with certain disabilities.
This graphic from the California Health Care Foundation,
shows our complex mixture of payment sources,
the contributions of which vary with the kind of care.
Until quite recently, most payments for health care services were pay for procedures,
where in simple terms,
individual providers and hospitals are paid,
on the basis of how much care they deliver.
Let's talk about wasteful spending.
I should say at the outset,
that this is an understandably contentious issue.
As you can see here,
the IOM has identified sources of waste,
and says that in aggregate they account for around 30% of all U.S. health care spending.
A ratio that has remained unchanged for decades.
The widely respected journal Health Affairs,
breaks wasteful spending into multiple categories.
First, are failures of care delivery.
This refers to poor execution or failure to adopt best practices,
such as for effective preventive care or patient safety.
Second, our failures of care coordination.
This means fragmented and disjointed care,
such as when patients move from one care setting to another called transitions of care.
Peer coordination turns out to be a major use case for health informatics.
Third, is over treatment.
Here that ignores scientific evidence.
This complex area includes defensive medicine done to avoid lawsuits.
As well as the use of higher price services that have negligible or
no health benefits over less expensive alternatives.
This is another major use case for informatics.
Specifically, clinical decision support.
You should read the Health Affairs paper for a more detailed discussion.
Fourth, is administrative complexity.
This is excess spending because payers our regulatory agencies create
inefficient or flawed rules and overly bureaucratic procedures.
As I alluded to earlier,
I believe the multiplicity of insurance plans and
government programs here in the US adds to these costs.
Fifth, is pricing failure.
This is when the price of a service exceeds that found in
a properly functioning marketplace which would expect to be
equal to the actual costs of production plus a reasonable profit.
For example, here in the US,
pharmaceutical costs are significantly higher than in other countries.
Surprisingly by law, Medicare is prohibited from
negotiating with pharmaceutical companies to get the best possible prices.
Last, are fraud and abuse.
In addition to the cost of the fraud itself.
This includes the cost of additional inspections and regulations to catch wrongdoing.
Earlier we said that while the U.S. excels in high technology care,
our overall health care quality,
efficiency, and safety results are poor.
In large part, this is because most health care costs are due to the incurable,
lifelong chronic diseases that our health care system is not designed to treat.
Patients with multiple chronic diseases account disproportionately for those costs.
Here's the opening paragraph of
a 2004 paper in public health reports that I strongly recommend you read.
Quote: In 2000, approximately 125 million Americans,
had chronic conditions, and 61 million,
had multiple chronic conditions.
The number of people with chronic conditions is
projected to increase steadily over the next 30 years.
While current health care financing and
delivery systems were designed primarily to treat acute conditions,
Quality medical care for people with
chronic conditions requires a new orientation toward prevention of
chronic disease and provision of
ongoing care in care management to maintain their health status and functioning.
Specific focus should be applied to people with multiple chronic conditions. End quote.
The paper then goes on to describe the care of those patients saying, quote,
while the average Medicare beneficiary sees between six and seven different physicians,
beneficiaries with five or more chronic conditions
see almost 14 different physicians in a year,
an average 37 physician visits annually.
People with five or more chronic conditions fill almost 50 prescriptions in a year.
This stunning fragmentation of the care of the people who drive
most health care costs is the central rationale for interoperability.
This is so key that I'll now interview one of the authors of
that paper Dr. Jared Anderson of the Bloomberg School of Public Health at Johns Hopkins.
Next, we're going to travel all the way to Baltimore to
the Johns Hopkins Bloomberg School of Public Health,
to speak with Dr. Gerard Anderson,
a professor there and the first author of
the paper I cite more than any other during this course,
"The Rising Tide of Chronic Disease in America."
Well Gerard, thank you so much for being with us today.
It's a thrill to meet you.
I'm glad to be here.
Great. A decade ago,
you and your colleague Jane Horvath,
published what I view as a seminal paper,
"The Growing Burden of Chronic Disease in America."
The students of the course,
if they've been paying attention are quite familiar with it by now.
And it opened my mind to the aggregate problem of chronic disease,
in a way that really no previous paper had done.
Which is why I view it the way I do.
So we're 10 years later.
Have we made progress? Where are we?
Well, we have made progress.
I mean I think what you knew already is that,
as you saw patients that had chronic disease,
but you didn't know how many patients there were,
and now we know that there are 150 million Americans,
almost one out of every two Americans that have one or more chronic conditions.
And that is sort of the new information that we were trying to bring 10 years ago.
Now what we're trying to do,
now that we have the attention of the policymakers,
is to start changing the delivery system.
That starts with prevention,
but it goes to care and cure for
these chronic conditions and there we're making a lot less progress.
I was more optimistic 10 years ago than I am now.
Most everything that we've tried recently has just not worked very well.
Well, here in the last few years,
we've tried to make the healthcare industry adopt health IT,
and we've tried to create health information exchanges.
We're still really early in that.
But are you optimistic that that will happen and that it will make a difference.
Well, it is happening,
so I'm very optimistic that it will happen.
What I don't think we've solved very well so far,
is that dashboard problem of a doctor.
I have 10 minutes to take care of a patient,
and she has seven things wrong with her,
she's seeing nine other doctors and I have 10 minutes.
If I spend most of that time looking at her medical record,
I now have five minutes to talk to her.
And so the challenge is,
how can we get that information out to
the physician in a timely fashion for that complex patient?
For the patient who only has diabetes, it's pretty easy.
But for that patient, who has diabetes and
congestive heart failure and beginning Alzheimer's and arthritis,
and is seeing all these different doctors,
and taking lots of different medications, that's the challenge.
I hope the students remember that comment because that's
basically what we're going to talk about in lesson six of the course.
Great.
Well, you also mentioned incentives.
I mean clearly the healthcare system has never been incented.
Do you see that working?
Are you optimistic that that's actually going to happen in
this endlessly complex adaptive health care system?
So, I was just amazed when I started this work in the 1990s,
that Australia had tried care coordination programs and they had and all failed.
And then I said,
but the United States can do it differently or the UK could do it differently.
And so I've been looking around the world for those models,
and I just don't see them yet.
I mean, it's just sort of,
we know what we need to do which is to get everybody on the same team,
probably with a nurse practitioner talking to all the doctors,
but we haven't been able to figure it out.
So most all of the demonstrations that we've tried,
both in the public sector and the private sector,
just haven't been able to save money,
reduce, improve outcomes, and improve satisfaction.
We just don't have very many of those things that hit all three of them very well.
And we're still working and so I'm optimistic that we will find it,
but so far, we just haven't been very successful.
Well, your paper actually ends on an optimistic note.
You point to the re-engineering the healthcare system a century ago,
around new knowledge in public health.
Is it so fundamentally different now that that optimism may be misplaced?
No, but I think if you read it a little more carefully,
what you'll see is I said,
we moved in 50 years from a system
oriented around infectious disease to one that's oriented on acute illnesses.
And then we got that done by about 2000.
And I said, it is going to take us 50 years to
reorient the healthcare system around chronic disease.
We have to start with the evidence base,
we have to know how to take care of somebody who has seven things wrong with her,
when the NIH and the FDA exclude all those people from clinical trials.
We don't have the educational system and the medical schools oriented around that.
We don't have the financing,
and so right now,
there isn't a real strong incentive for
hospitals and doctors to really go after these people,
to take care of them in an effective way.
In fact, because they don't know how to do it,
they want to run away from them in most cases.
But this is where the money is.
Two-thirds of Medicare spending is by people with five or more chronic conditions.
We've got to get the system right for these people,
we just don't know how to do it yet.
So, I can't speak to 50 years ago,
but 40 years ago,
I was a medical student.
First getting interested in this.
And I remember going to meetings,
and they would say, well here's where we are,
and if these trends continue and we don't do anything by right about now,
health care will be consuming 20% of the gross domestic product,
a number that's absolutely not sustainable.
Right.
Now I've seen projections from OMB and others,
that if we don't do anything it will be 40% in 50 years.
Do we have 50 years?
Well, when I started working and trying to
control health care costs in the 1970s, I said,
we'll never be able to sustain 10% of GDP on healthcare,
now it's close to 20.
So, I've stopped making projections as to whether or not we can afford to do something.
What we know is that by the time it gets to almost 30%,
which isn't that far along,
almost all the growth in the economy,
all the productivity growth in the economy will in
fact go to support the growth in healthcare,
and that's probably not sustainable.
But we don't know what's going to turn the ship around,
maybe it's IT, maybe it's changing the financial incentives,
but since everybody is making so much money in healthcare, and you know,
jobs are important and financial security is important,
it's going to be a really tough change.
So many of us speculate that eventually with our backs against the wall,
we'll adopt a single payer system like every other country on earth.
You think that's going to happen here in the US?
I was more optimistic in the 90s than I am today.
Basically, Americans love choice.
All you have to do is go to a grocery store and go down the cereal aisle and
look at 40 to 100 different choices of cereal,
whereas if you go to France,
you'll see two or three in most cases.
Choice is what makes America,
and is going to be really hard to get the private insurance industry out of it.
We can't even get right now,
many of the states, to embrace Medicaid,
so if they can't embrace Medicaid which is free money to them,
why would we think that they would go to a single payer?
I mean, I think it makes sense.
It means that we pay a lot more for healthcare
than other industrialized countries because of this choice,
but America seems to really like choice.
Well, thank you very much.
It's been a pleasure.
Thank you.
Maybe we'll be able to get together 10 more years and see what's happened.
I hopefully it will be more optimistic that time.
Are there examples of a better approach?
Yes. Earlier I mentioned health maintenance organizations.
And we'll now look at the oldest.
Kaiser Permanente was founded in 1945 by
industrialists Henry J. Kaiser and physician Sidney R. Garfield.
Edgar Kaiser famously described its economic model as "The less Kaiser does for patients,
the more money it makes."
This is because Kaiser offers a prepaid plan to employers.
Kaiser agrees to provide all needed care for a fixed amount per year.
The history actually dates to 1933,
when Garfield opened the Contractors General Hospital with 12 beds to
treat construction workers building the Los Angeles aqueduct in the Mojave Desert.
The hospital was in a precarious financial state.
Fueled by Garfield's desire to treat all patients regardless of their ability to pay.
Harold Hatch, an insurance agent,
proposed that the insurance companies pay the hospital
a total amount in advance for each worker covered.
The financial relationship between the insurance companies and the hospital was
efficient and allowed Garfield to focus on a new idea, preventative health care.
This is the first key takeaway.
When the health care economic model provides the right incentives,
the focus shifts to preventive care in order to avoid costs.
Kaiser is also a leader in care coordination and population health,
two key strategies for managing chronic disease that we'll discuss later on.
To support these strategies,
Kaiser has also been a leader in the use of information technology.
HIMSS is a large,
not-for-profit organization, focused on better health through information technology.
Its annual meeting is by far,
the largest event in the field.
In 2009, Kaiser received the first ever Stage 7 award.
This is HIMSS' highest level of recognition for
an environment where paper charts are no longer used.
That's the second key takeaway.
A care models that work best for
chronic disease rest on the use of information technology.
Kaiser's done well.
And today, it employs 186,000 staff and over
A large part of Kaiser's success is because it's concentrated in
a few areas where it has the market presence to own and operate all,
or most of its facilities and employ its physicians.
Can smaller care organizations deliver the kind of care that Kaiser provides?
Many feel the patient-centered medical home,
or PCMH, provides for this.
The concept dates to the early 1960s.
In fact, I worked in an early example of the PCMH,
where I oversaw the development of one of
the first electronic medical records systems starting around 1970.
The PCMH model is advocated by the American College of Physicians,
or ACP, which is the professional organization for internal medicine doctors.
It's also supported by the American Academy of Family Physicians,
or AAFP, the other large professional association of primary care physicians.
This is because their members are the doctors on
the front lines of managing chronic disease.
The ACP describes the PCMH as,
"A care delivery model whereby patient treatment is coordinated through
their primary care physician to ensure they
receive the necessary care when and where they need it,
in a manner they can understand."
The objective is to have a centralized setting that facilitates
partnerships between individual patients and their personal physicians,
and when appropriate, for patients' family.
Care is facilitated by registries,
information technology, health information exchange,
and other means to assure that patients get the indicated care,
when and where they need and want it
in a culturally and linguistically appropriate manner.
Note again, in this graphic from the AAFP,
the emphasis is on providing all needed
care and using information technology to manage that.
Earlier we mentioned that healthcare in the US was
traditionally charged based on the amount of care that was delivered.
This is usually termed pay for procedures.
HMOs are an example of an alternate model in which there is fixed reimbursement.
So if Kaiser spends less than its premium income it makes a profit.
In fact, like most nonprofits,
Kaiser still needs earnings to invest in its business.
However, this relies on Kaiser employing all the physicians,
owning all the hospitals and more.
Can we create something similar on a much smaller scale using physicians,
hospitals, and other community health resources that are already in place?
In 2006, Dartmouth professor, Elliott S. Fisher,
first used the term accountable care organization to describe such a proposed solution.
The details are complex but the basic idea is to create
a financial model under which existing community providers can organize and deliver
care in a way that improves the quality and lowers the cost of
care by fostering greater accountability
on the part of the providers for their performance.
One of the key provisions of
the Obama administration's Affordable Care Act was the creation of ACOs within Medicare.
This model is also now widely advocated by commercial health insurance companies.
Dr. Karen Bell is the chair of
the Certification Commission for Health Information Technology,
CCHIT, which is a not for profit HIT certification body with an educational mission.
In a June 2013 post on the Health Affairs blog,
Dr. Bell said that models such as
a ACOs must successfully implement seven business processes,
all of which rely heavily on the proper use of Health Informatics.
The seven processes are: care coordination, cohort management,
patient relationship management, clinician engagement,
financial management, reporting, and knowledge management.
To support this, she lists four primary requirements of an ACO HIT infrastructure.
The first demands the ability to share health information between and
among various internal and external providers,
patients, and their designated caregivers.
Second, there needs to be data integration from clinical,
administrative, financial and patient derived sources.
The third requires attention to HIT functions that support patient safety.
The fourth requires strong privacy and security protections.
Most health care organizations have a lot of work to do in order to achieve all of this.
Earlier in her post,
Dr. Bell says that quote,
the promise of Accountable Care is tempered by a dearth of
experience with care process redesign and culture change,
and of knowledge about the health information technology infrastructure
necessary to optimally support healthcare transformation, end quote.
To summarize, the need for health IT to support new care and payment models is clear,
but we still have a long way to go to develop and properly use those systems.
Next we turn to some of the key challenges to doing that.
So far we've talked mostly about the role of
Health Informatics to improve the delivery of care.
What about its role in ensuring we deliver the right care to every patient, every time?
This is a major concern of the Academy of Medicine,
which is the new name for the Institute of Medicine.
It recognizes that we are entering a new era of
medical science that offers the prospect of personalized health care.
It also recognizes that physicians and patients must deal with
an increasingly complex array of health care options and decisions,
and they need help to choose wisely.
That help in turn,
may require new knowledge about what works and when and for whom it works.
To achieve that, years ago IOM called for a learning health care system.
That it describes as a sustainable system that gets
the right care for people when they need it
and then captures the results for further improvement.
In simple terms, we need to gather data from care already delivered,
aggregated, and analyze it to learn from
the collective results of many care representatives.
We need a feedback cycle.
As shown in this graphic,
there are at least three key informatics challenges to
overcome in order to achieve a learning health care system.
First, providers must adopt digital records.
Second, no systems must be able to share data a characteristic called interoperability.
And third, that shared data must be aggregated,
analyzed, and presented in a clinically useful and timely manner.
Because of the federal government's high tech program,
that we'll discuss in the next lesson,
adoption is now a largely solved challenge.
Much of the excitement about fire rests on
its apparent ability to help overcome the interoperability challenge.
Fire apps, offer the prospect of solving the problem of
timely and useful presentation of the results of the new knowledge
gleaned from analysis of past care to busy physicians.
Here again, economics plays a key role.
If providers have an incentive to get it right and do that efficiently,
then they'll be interested in creating a learning health care system,
because they can more clearly see how they benefit from it.
Well, now consider one example,
when to discharge a patient after surgery.
>>I'm John Sweeney. I'm the Joseph Brown Whitehead professor of surgery,
and chairman of the Department of Surgery for the Emory University School of Medicine.
Muscle Insertion and chief Emory health care.
We became interested in this problem in about 2009- 2010,
and it was based on a landmark paper that was
published in New England Journal of Medicine in 2007.
In that paper the authors found that Medicare patients
discharged from the hospital we were readmitted an enormous number,
almost 20% of those patients.
And within 30 days after discharge the cost
to the health care system was in the billions of dollars.
And so, it was creating a significant amount of interest at the federal level.
And as part of the patient protection Affordable Care Act Section, 13:24,
which is the readmission Reduction Act was signed into law which
penalizes hospitals that have access readmission rates over what's expected.
And so, this has become a substantial problem and generated substantial focus for
hospitals around the country to reduce
their readmission rates and improve outcomes for their patients.
It's an interesting problem.
As we started looking at the readmission problem,
we realized that there were several factors at
play that needed to be considered not just the simple readmission.
The first was the decision to send the patient home.
One was the patient ready to be discharged.
And keeping in mind with that that the longer patient stays in the hospital,
the higher the costs associated with that.
And so, our doctors are incentivized to reduce costs
and move patients through the hospital care segment.
If they move too quickly, patients could potentially be readmitted.
And so, we felt that the tool that brought information to
bear that help providers make timely decisions,
that were more effective and reduce
readmission rates really could make a huge difference in
the outcomes for patients but also decrease costs for health care system.
I am a practicing general surgeon.
I do complex general surgery and so because my interest is in that area
and patients that undergo
complex general surgery can have readmission rates as high as 20%,
we initially focused on a large dataset of patients here at
Emory University Hospital that had previously undergone complex GI surgery.
And we looked at readmissions in those patients and with the help of
the economists working at Georgia State built a predictive model that
helped us with more likely
predicting one it was the appropriate time to send a patient home from the hospital.
We then took that tool into
the simulated setting and actually both using a computer simulation setting,
and also mock patient actors
in a simulation setting here in the Emory Center for experiential learning.
We actually showed that this tool does have benefit,
and we think that in the true clinical setting would lead to reduce readmissions,
decreased like this day,
and improve outcomes overall for our patients.
The big issue for us now is as we've put a considerable amount of work
into developing what we think is something that could
have some significant benefit at the bedside,
as how to be able to integrate an electronic record with
this decision support tool and really firers the mechanism for doing that.
It's the opportunity that's going to allow us to bring to bear what we've
spent a lot of time working on and what we
think is going to make a difference for patients.
And also, make the decision making process easier for provider.
The future of our tool I think is the next step,
is going to be a clinical trial with the tool and the clinical arena.
We've already shown the utility
both in the computer simulated setting as well as in a mock patient setting.
But in reality what needs to happen next is this tool needs to be
trialled in the clinical setting to demonstrate its utility.
The risks of readmission and the impacts of
a readmission as well as the impacts of a prolonged length of stay are significant.
And therefore, we think that this needs to be trialled in a
controlled setting before turn loose on the healthcare environment.
I'm James C. Cox.
I'm the Noah Langdale Jr.
Chair in Economics, the Georgia Research Alliance Eminent Scholar,
and Director of the Experimental Economic Center at Georgia State University.
I'm an experimental and behavioral economist,
which if you wondered,
what does an economist have to do with actual delivery of healthcare?
The words experimental and behavioral are the keys.
Because the centers of my areas of expertise are how
people respond to incentives and use information in making decisions,
and how one can design mechanisms to help them improve the decisions that they make.
In this case, the problem to be addressed is not lack of information.
Physicians are overwhelmed with information and the problem we face is how to use it.
Where my team at the Experimental Economic Center comes in is
to start with a large sample of the identified patient records,
do an analysis of that data to try and find
the predictors of unsuccessful and successful discharge from the hospital,
and then build on that a clinical decision support system with user
friendly displays that can aid the physicians in making better decisions.
First of all, the economist did the data analysis and then my I.T.
staff design the original CDSS that we used in experiments here at Emory.
We ran experiments with both resident physicians and fourth year medical students.
Initially, they were making decisions about virtual patients being represented
by computers for trained data of real patients.
We later did an experiment where we had patient actors called standardized patients.
There were two sources of information which
was the CDSS and the behavior of these standardized patients,
and this is the last step
before being ready to go out on the patient wards with an intervention.
Getting prepared to go take that last step onto
the patient wards is where we encountered really serious problems.
Because at that point,
we needed a version of the CD SS that can
interact with electronic health records in real time.
When we started to try and take that step,
we ran into very severe obstacles because you can
imagine protecting patient information is a central concern,
and we were asking for two-way communication.
At that point, both Cerner Corporation and Emory I.T.
essentially balked.
We were in near despair in not being able to get cooperation from Cerner and Emory I.T.
in trying to make the next step in getting out of
the laboratory and onto the patient wards.
We had a meeting here at Emory with the new director of Emory IT.
And he made us aware of
the fire standards and he invited Mark Grunstein to come,
who said to us, Well,
you've hit a brick wall,
but I know how to get through that brick wall.
And it is using fire compliance which is forthcoming.
And he provided to us the information we needed for the path forward and also provided
a path to start to walk down that path through
the projects that his class teams could do for us.
We were enthusiastic about learning about that path,
and having that opportunity to start walking down that path.
One of the project teams working on an initial version of
the app produced some alternative,
very nice displays of the information,
and this is critical because for the CDS to have value,
it has to have two properties.
One is it makes correct predictions about probability of
re-admission of a patient if you discharge them on any given day.
But the other thing it needs to do is to present the information in a user-friendly way.
So here's what in principle the problem to be solved.
The underlying model looks at each patient as though
as an individual patient that comes from a population of a very large sample,
for which we know the outcomes of previous decisions,
where a patient that looks like your individual patient today,
out of a very large sample of 30 or 40 thousand patients.
If you discharge your patients today,
do they look statistically more like
ones who it was unsuccessful and they were re-admitted,
or it was successful and they were not?
The critical thing then is not only to have the underlying correct predictions,
but to display them in a way that the physicians will actually find it easy to use.
And one of the class teams produce
these beautiful information displays and there are two of them.
One of them presents the information and is like rectangular block format,
another in a beautiful circular format.
But the nature of the information displayed is in
the lower left hand corner of the display,
is something that shows the probabilities of re-admission for patients,
and it'll show the time sequence
from the first day your patient was in the hospital up to the current day.
It displays the point estimate of the probability of re-admission,
unplanned readmission if you discharge them today,
and the 80% error bounds.
The center of the display
shows all of the variables in the patient's record including labs,
vitals, all the information,
and those displays are color coded.
And the color coding represents
the marginal significance on
probability of re-admission of each of those individual variables.
The user, then, can click on any one of those variable names in
the central display and that will open up on the right side of the screen.
The detailed information on that individual variable for
your patient including how it varied from the day admission up to the current day,
and how that time path of those readings compares
to the normal range of that particular variable.
In this lesson we will begin a discussion of
the key informatics tools needed to power a learning healthcare system.
These tools include electronic records for both providers and
patients as well as information sharing technologies to bind them together.
We will also discuss the challenges that we
still face in perfecting these systems to make
them both usable and useful in the real world of health care delivery.
In the previous lesson,
we saw that most hospitals and around half of
all providers now use an electronic medical record or EMR system.
It is easy to forget just how remarkable this is since as recently as
Perhaps even more surprisingly, in 2009,
only 1.5% of non-federal hospitals had one.
These statistics come from a pair of
important papers published in The New England Journal of Medicine,
generally regarded as the leading journal in the field.
I recommend you read them.
Federal hospitals who are excluded from the study,
largely because the Veterans Administration, the V.A.,
the nation's largest integrated health care system was
a pioneer and all of their hospitals had EMR as well before the study was done.
The V.A. has veterans information systems and technology architecture or Vista for short,
dates back to the 1980's and consists of nearly 180 applications for the VA's clinical,
financial, administrative, and infrastructure needs.
All integrated into a single common database.
Here is an example of Vista's capabilities,
showing that images can be retrieved by any physician in the system,
no matter where in that huge system those images are stored.
This capability is still not widely available elsewhere in U.S. healthcare.
So, in less than a decade,
we went from 4% of providers having a basic human system to around half.
How did this transformation toward
a more interconnected system occur in less than a decade?
Many people including me long argued that
only federal intervention would make EMR adoption happen.
A core reason for this is once again, economics.
Without federal intervention, hospitals and providers would have to invest,
to go through a difficult, time consuming,
and often frustrating transition from paper to electronic records.
Moreover, under the pay for procedure reimbursement model,
to the extent the EMR led to a reduction in unnecessary or duplicative care,
it might negatively affect their revenue.
Moreover, EMR adoption is an example of network benefits.
The more providers that have them,
the more valuable they become because of data sharing.
In such a situation it is always hard to find enough early adopters,
willing to innovate in the hope of some future gain.
This economic impediment was the basis for
the Health Information Technology for Economic and Clinical Health Act,
abbreviated Hi Tech, a part of the American Recovery and Reinvestment Act of 2009,
commonly called the Stimulus.
The details are complex,
but there were three basic elements of the program: First there was HIT certification,
that defined minimum functional requirements for EHRs and other clinical tools.
Second, there was meaningful use,
which defined the minimum use to which hospitals and providers must put their EHR.
Third, there were incentive payments made to
hospitals and providers for adopting a certified EHR,
and meeting the requirements of meaningful use.
These programs are of course interdependent,
and do not apply to all providers,
only hospitals and providers that participated in Medicare or Medicaid,
adopted a certified EHR,
and used it according to the prescriptions in meaningful use were eligible to
receive incentive payments in 2011 through 2015.
Incentive payments came to hospitals and providers
through their participation in either Medicare or Medicaid.
Providers could be eligible only for one,
but hospitals could be eligible for both.
There were annual limits to the amount of
the payments and the total amount that a provider
could earn depended on when that provider achieved the stages of meaningful use.
As of October 2015,
more than 479000 health care providers received incentive
Before we move on,
I need to clarify the difference between an electronic health record (or E.H.R.),
and an electronic medical record, or EMR.
EMRs, as the name implies,
are usually the digital records of a patient as
recorded by one or more of their providers.
Historically, that was the focus of electronic records.
An electronic health record is a complete record of a patient's health.
Today with the advent of the Internet, mobile apps,
wearable measurement technologies, and even social networking,
a complete patient view requires interoperability,
so that all their records from all of
their providers are combined with data from these other sources.
The Office of the National Coordinator for health information technology,
or ONC, administers the HIT certification program.
It is voluntary, and includes capabilities such as recording,
security, and interoperable sharing of health information.
As shown here, the program defines the technical requirements for health IT,
and the process by which commercial systems may become and remain certified.
Commercial authorized testing labs do the testing
using ONC provided criteria and test data sets.
Since hospitals and providers must acquire a certified EHR to receive incentive payments,
it's virtually a business necessity for EHR vendors to be certified.
ONC reports on its progress on it's HIT dashboard site.
This graphic from that site shows that as of July 2016,
to 337432 ambulatory primary care and specialist
physicians and other providers participating in the Medicare EHR incentive program.
While EPIK systems supply certified technology to 30 percent of all those providers,
there are 632 vendors in total,
something that clearly exacerbates the interoperability challenge.
Here you see that as of July 2016 175 certified vendors supplied systems
to 4474 nonfederal acute care hospitals
participating in the Medicare EHR incentive program.
This market is far more concentrated,
as only ten vendors supplied about 98 percent of hospitals.
But interoperability is still an issue among hospitals.
The reasons are not limited to technology:
too many hospitals and health systems seek to control access to
their digital records to make it convenient and hence more
likely that patients will obtain all their care from one source.
Importantly the top three vendors listed here have all announced support for
fire and smart on fire as an EHR connected platform for fire apps,
including those written by third parties.
This liberation of EHR data for innovative purposes may not be classic interoperability,
but it could lead to progress in solving some of
the EHR challenges we'll discuss later on in this lesson.
Meaningful use is a complex program in
three stages that coordinates with the approach to provider reimbursement for Medicare.
We can only cover the main points here.
The central goals of Meaningful Use are the use of
certified EHR technology in a clinically meaningful manner,
such as e-prescribing, for electronic exchange of health information to improve
quality of health care and to submit clinical quality and other measures.
The sub-goals for clinical care include: improving care coordination,
reducing health care disparities,
engaging patients and their families,
improving population and public health,
and ensuring adequate privacy and security.
Note that these goals align well with what experts
believe is needed to improve the management of chronic disease.
The developers of Meaningful Use were well aware of the mismatch we discussed in lesson
one between the focus of our healthcare system and the diseases that drive most costs.
This Meaningful Use timeline from the CDC shows that the program began in 2010,
and starting in 2015,
there were reductions in Medicare payments to
hospitals and providers that were not Meaningful Users.
The timeline in stage 3,
in particular, is highly political.
Many argue that the pace of the program is too rapid given
the complexity of implementing and properly
integrating these systems into a health care organization.
The CDC generally does a good job of clearly explaining the program,
so I would recommend their site for updates.
Next, we'll turn to some of the challenges of EHRs and their adoption.
Physician satisfaction with the EHR is an extremely important topic,
and one that will have widespread ramifications
for the effort to use Health Informatics as
a tool for establishing
a learning health care system and effectively using the new knowledge it creates.
In 2013, The Rand Corporation and the American Medical Association published what I
believe to be the best study today on
overall physician satisfaction including satisfaction with the EHRs.
The survey team selected 30 physician practices to achieve a good cross-section.
Each practice completed a structured questionnaire that included
questions about its electronic health record use and capabilities,
and participation in innovative payment models.
The survey team then visited these practice and conducted
semi structured interviews with 220 informants.
Finally, they surveyed 656 physicians in the 30 practices receiving 447 responses,
a 68 percent response rate.
Here are the results with respect to satisfaction with the practices EHR.
The majority of physicians believe the EHR
improves care quality but using it is inefficient of their time.
Interestingly, only 18 percent of
the physicians indicated they would revert to paper records if they could.
Disturbingly, according to the American Academy of Family Practice,
the AAFP, a strong advocate of the EHRs,
physician satisfaction with them is declining.
As our baseline in the AAFP 2010 survey,
American EHR partners is a new effort supported by 20 professional societies including
the AAFP and the American College of Physicians
another large physician group that advocates for EHRs.
American EHR has been collecting data since the AAFP survey in 2010,
and it claims theirs is the only EHR survey that
charts satisfaction over time and allows for the benchmarking of data.
Today, American EHR says it has collected over 7500 responses using the same core survey.
They say this allows them to have comprehensive breakdowns by specialty,
practice size, EHR type and so on.
The American EHR partners 2014 online survey of 940 physicians found that
to improve efficiency was difficult or very difficult.
to decrease workload was difficult or very difficult.
and 43 percent said they had yet to overcome
the productivity challenges related to their EHR system.
However, over 36,000 physicians received invitations.
So the response rate was only two point six percent.
It is certainly possible that
dissatisfied physicians were more motivated to express those feelings,
a phenomenon known as response bias.
I asked the American EHR about this and they say that
the 2014 results are actually
consistent with results they've been continuing to receive since then.
In any case, it seems clear that physicians
find the use of an EHR inefficient and challenging.
We next turn to why this is the case.
In 2009, the National Academies of Science
published computational technology for effective health care,
immediate steps and strategic directions.
Dr. William Stead, the distinguished head of
Vanderbilt University's biomedical informatics department was the coeditor.
The report states that quote,
"IT applications appear designed largely to automate tasks or business processes.
They're often designed in ways that simply mimic existing paper-based forms and provide
little support for the cognitive tasks of
clinicians or the workflow of the people who must actually use the system.
Moreover, these applications do not
take advantage of human-computer interaction principles,
leading to poor designs that can increase the chance of error,
add to rather than reduce work,
and compound the frustrations of executing required tasks.
As a result, these applications sometimes increase workload,
and they can introduce new forms of error that are difficult to detect."
This seems to me to be congruent with the results of
the physician EHR surveys we just cited earlier.
It's also suggestive of the concerns I often hear from physicians,
that their EHR provides a one size fits all approach to charting,
that doesn't capture the nuances of actual patient care.
In fact, the most common approach to electronic charting is
a template which as the report I just quoted
suggests mimics existing paper forms and largely
ignores the potential of a computer to be adaptive to the clinical situation.
The report identified seven information intensive aspects of
the IOM's vision of
a learning health care system that current EHRs often failed to provide.
I've abbreviated them here for legibility.
Comprehensive data on conditions, treatments and outcomes,
support to help providers and patients integrate
patient specific data where possible and account for any uncertainties that remain.
Support to help providers integrate evidence based
practice guidelines and research results into daily practice.
Tools to help providers manage a portfolio of patients and to highlight
problems as they arrive both for an individual patient and within populations.
Rapid integration of new instrumentation,
biologic knowledge and treatment modalities.
A combination of growing heterogeneity of locales for care provision,
including home instrumentation for monitoring and treatment,
lifestyle integration and remote assistance.
An empowerment of patients and their families in
effective management of healthcare decisions and their implementation.
This is a list of what I would call clinical deficiencies.
Many are of increasing interest because of
the new care and payment models we've discussed.
However, most current EHRs date from the era of pay for
procedure and emphasize support of billing and administrative processes.
These are complex large scale systems.
They're expensive and because of high tech now widely installed.
How might we fix or even replace them.
Here's one promising approach.
FHIR apps crafted to meet the needs of providers caring for specific conditions.
Here's an example of that for the care of
arthritis developed by the Geisinger Health System,
widely regarded as one of the nation's highest performing health care organizations.
Its user interface is specific to this condition and it can
display data recorded earlier by the patient, saving physician time.
Here's another approach.
The use of machine learning and specifically a neural network to enable the EHR
learn and adapt to the clinical approach used
by physicians to care for the problems they commonly see.
As shown here, once it has been trained on
a problem when the physician next sees that problem the Praxis EHR
presents their likely note but has
enough clinical knowledge to recognize what data fields must be specified at each visit.
The company claims that once the system is trained it actually saves physician time.
The approach seems to work since physicians consistently give
Praxis some of their highest user satisfaction ratings.
For some insights into the roles EHR connected FIHR apps may play.
We will now interview Tate Gilchrist's senior business developer
for Open Platform Services at the Cerner Corp.
>>Hi I'm Paula Braun. I'm an entrepreneur in
residence with the Centers for Disease Control and Prevention.
>>Hi. I'm Tate Gilchrist.
I'm a senior business developer at Cerner Corporation out of Kansas City, Missouri.
>>Tate, could you give us a high level overview of Cerner's history and current business?
>>Sure, Sure. So, Cerner was started several decades ago
by three very visionary gentlemen
sitting at a picnic table in North Kansas City, Missouri.
We've grown from that time in very humble roots into
a global healthcare information technology company in numerous countries the Middle East,
Australia, the UK, all over the United States,
Canada and we use a variety of
technologies to serve the healthcare systems that we support.
Cloud-based technologies such as SMART on FHIR,
population health cloud based technologies.
Cerner's committed a substantial amount of money to R&D every year and we do this in
an effort to really drive the innovation for
that's going to be needed to support the health of patients across the globe.
>>Great. And Cerner was one of the first to support SMART as
a platform for allowing third party developers to contribute to your ecosystem.
>>Yeah.
>>Can you share some insight and why you did that?
>>Yeah, again and I think it comes back to, you know,
the three gentlemen that I spoke of our founders
so very visionary individuals and they recognize that the way that we're currently
doing business and the way that the market is currently set
up is really not sustainable if we're going to achieve
the things that we want to achieve and so they
decided that we needed to pursue being an open platform company.
Taking the vast amounts of data that
our clients are generating and the patients are generating when they're
using our core EMR and through the use of APIs
to be able to open it up so that third party developers can come in with
these brilliant ideas that maybe we hadn't even
thought of or maybe we just hadn't gotten around to thinking
of yet and be going to take them and give them the tools to come in and take
their application and put it inside of our EMR so that
our providers and for the patients themselves can use too.
It's a very, very exciting time in our company's history and I'm very,
very happy to be a part of it.
>>Great. Now some have commented that SMART on FHIR is an academic exercise.
What's your take on that from your perspective at Cerner?
>>No longer an academic exercise, you know.
Cerner has been working with Argonaut group.
And others for several years now and SMART on FHIR.
And ah, it's, it's real now,
so we have some actual app usage.
We have numerous clients that have deployed the API,
that have built their own applications.
We have clients that have taken applications
from third party vendors that have used our tools,
that we have openly available to anyone,
even our competitors to be able to use
and have taken those applications and put them into
their production environments and were even started
seeing some early outcomes out of the use of those apps.
So while it's true,
it is very, very earl, we're very,
very excited about the progress that's been made and
the exponential growth curve is really starting to ramp up.
So we're very excited to see what the future will hold.
>>Surveys of physicians show that using electronic medical records can be inefficient.
What role do you think that apps can play in this?
>>Well, I think one of the great hopes with SMART on
FHIR app is that this is really an opportunity for us to
fully engage the physician in
the workflow process and in some cases in the app development process.
We've got numerous examples now of companies and of individuals that
have almost taken the classical example
of medicine so the bench to bedside approach, right?
A drug or device would have to go through a clinical vetting process, a study, etc.
Healthcare Information Technology is typically not that way but with SMART on FHIR,
we can have innovative developers and innovative individuals that can take
clinically vetted content that is specific to
the physician and can now take that and put that in the physician's workflow.
The hope is that, by using that,
that would advance patient care,
increase physician satisfaction and a rising tide is going to lift all boats.
>>Cerner has also announced that it will be supporting CDS Hooks.
How do you think that that will help with
the further adoption of clinical decision support tools?
>>Well, CDS Hooks is very,
very exciting and we have a numerous number of developers that are
anxiously awaiting our ability to be able to deploy it for their use.
From a broad concept, you know,
a provider doesn't want to have to do another click to invoke an app.
With CDS Hooks, the hope is not only will in
response to say a clinical event or an open chart or something of that nature,
that a SMART app workflow can be kicked off.
But the notion of having CDS Hooks available as a tool for
a developer will pull in all of these CDS specific content,
companies that can create innovative apps,
lift patient care, and produce superior outcomes.
>>Where do you feel that EHR's with an app platform will take us in the coming years?
>>Well, that's a pretty big question.
I mean, I think that we know we've made great progress but if we
are truly to look at the promise of FHIR and the use of
open standards and the notion of the EMR as
essentially on a platform much like an iPhone or Android device.
The possibilities really if you think about them are endless,
but if I'm really to see,
to see into the future and see what I think that
potentially could be the grand vision of things.
The notion of the patient having access to their own data to be able to try
these multitude of consumer apps that these
thousands of consumer apps that are out there for chronic care,
whether it's diabetes, congestive heart failure, etc.,
we need FHIR and we need a robust ecosystem and
a platform to be able to allow developers to be able to build that.
Secondly, the notion of being able to feed data to
the research community so the notion of FHIR bundles being able to push data out.
So, in that situation,
you're not looking at FHIR as merely a tool to
live in operability but to really lift medicine,
as a whole, and drive the health of patients and really human beings in general forward.
>>Thank you so much.
>>Thank-
Patient facing health informatics tools is a rich and increasingly interesting field
particularly because of the growing use of apps and
mobile devices for patients to report on and measure their behavior,
activity, and physiologic parameters.
Those new technologies even have a name, mHealth.
It will be the topic of a later lesson.
In this one, we will address some of the other tools
and approaches to patient engagement through informatics.
Some are old ideas while others are quite new.
The changing economics and care models in healthcare are increasing interest
in all of them.
Should patients be the aggregation point for all their health data?
Should they contribute data they have documented or recorded using devices and apps?
Should they have access to their physicians notes,
and even the ability to suggest corrections?
Will their use of personal technologies engage them and lead to better outcomes?
These are some of the key questions,
and potential benefits that arise from the concept of a personal health record, or PHR.
The term first appeared in a 1978 paper,
but it was really not practical until around
and the increasing availability of the Internet.
Of course the almost universal use of
smartphones provides a near ideal ubiquitous PHR platform.
The original idea was a patient maintained record,
but you can see from these questions it's scope is expanding in our connected world.
Today the Markle Foundation's Connecting for Health initiative
defines a personal health record as quote,
an electronic application through which individuals can access, manage,
and share their health information,
and that of others for whom they are authorized.
In a private, secure,
and confidential environment, end quote.
Despite technical progress, adoption of
PHRs and other tools for patients remains an issue.
A recent paper suggests that current adoption is around 20% to 30% of
patients but forecasts say the majority of patients will use a PHR by 2020.
There are several challenges to adoption: getting the data to patients,
privacy concerns, patient engagement, and usability.
We will cover each of these at a high level.
For more, I refer you to a recent paper that discusses PHRs
and their challenges in some detail.
Once again, interoperability is a key issue.
Absent it, how does PHR data get into a patient's personal record?
This becomes even more problematic if they receive care from
several providers that we have learned patients with
multiple chronic diseases typically do.
The most common form of personal health record is a browser-based patient portal.
Enterprise software vendors often supply portals and automatically
populate them with data from their EHR and their other clinical systems.
Here is an example of a modern patient portal provided by
Marshfield Clinic Information Services (MCIS).
This company is a spin-out from the Marshfield Clinic,
one of the most highly regarded health systems in
the US and an advanced user of informatics.
Note that it brings together a patient's health record,
reminders of needed tests and procedures,
messaging, and even financial and administrative services.
One of the key goals of meaningful use is to ensure that patients have
electronic access to their records no matter where they receive their care.
In fact, meaningful use has a term for this: view,
download, and transmit or VDT.
And it's a key measure for providers.
In Stage Two, more than 50% of all unique patients seen during
each 90-day reporting period must have had timely access to the health information.
More than 5% must have actually used this capability.
The second measure seems designed to incent providers to
explain their VDT tool and encourage their patients to use it.
Some research suggests that this provider engagement is effective.
There are also meaningful use measures related to
sharing of health data at transitions of care.
Continuity of care document or CCD is an HL7-specified,
XML-formatted electronic patient summary and is one way to meet this requirement.
As you will see in the health fault exercise that follows,
it's also a way for a patient to easily load
all their EHR data from all their providers into a PHR.
The second challenge is patient concerns about
the loss of privacy if their health data is stored in the cloud.
In a 2008 Markle Foundation survey of 1,580 adults,
and 53% had similar concerns about health insurers.
The Affordable Care Act provision outlawing the use of preexisting conditions to deny
health insurance may have alleviated
these concerns to some degree with respect to health insurers.
However, with data breaches increasingly common,
including in health care,
this issue is likely to remain a serious challenge.
Finally, there is the challenge of getting patients to use these tools.
Several studies have asked patients what functions they most want from a PHR.
Unsurprisingly, these include access to
their past medical history including immunizations, lab tests,
and medications, as well as access to their appointments,
and communication with their providers.
Patients often want to access their family member's records.
Age, lack of computer literacy,
and unfamiliarity with medical terminology are often impediments to PHR use.
You'll have an opportunity to explore these challenges and
usability in particular in the exercise that follows.
We will use Microsoft's HealthVault PHR because it is free, public,
and does a good job of demonstrating some key PHR concepts, capabilities, and challenges.
Here you can see that HealthVault records
the common health information patients say they want to keep track of.
It can also upload data from numerous personal devices and apps.
Finally, it provides for uploading health information from a patient's providers.
HealthVault displays the patient's health record in tiles.
Each user can decide which ones they want on their personal health dashboard.
Here you can see two menu items we will be using, documents and sharing.
I've expanded the documents menu.
Notes support for continuity of care documents, or CCDs,
along with older formats such as the CCR,
a predecessor to the CCD,
and even files from spreadsheets or word processing software.
Patients can also upload images.
Note that this patient has six CCDs,
which could have come from six different providers caring for their various problems.
We will discuss CCDs in more detail later but as I mentioned earlier they are
pre-FHIR HL7 standard for an XML formatted patient summary.
The Meaningful Use Stage 2 objectives for care coordination and
patient engagement require the latest HL7 document standard, called CCDA.
So all states to certify EHRs can produce CCA documents.
CCDs are a specific template within
the CCDA standard that is ideal for loading data into our personal health record.
Any software that supports the standard, as HealthVault does,
can upload and should generally be able to correctly store data
from CCDs created by the patients providers EHR.
HealthVault does this when patients push the add items button.
I've highlighted one of the CCDs listed and then
clicked on the dot dot dot link to bring up a menu.
Importantly, most browsers will render XML documents in reasonably human readable form.
Here you see the CCD I had highlighted after I
clicked on The View details link in the menu we just looked at.
I think you'll agree that it is quite readable.
The CCD file CS 6440 sample CCD is available to you on the course site.
Your exercise is to first create and
HealthVault account and then upload this CCD into it.
Once you have done that,
click the Add items box next to its name in the list of CCD documents to experience what
an actual patient would need to do in order to
decide what data from their record to load into their PHR.
Next, click on the sharing item in
the HealthVault menu we discussed a moment ago to bring up this screen.
Note at the top that patients can invite someone,
such as family members,
to share their data.
Those invitees receive an email invitation like this one.
Be sure to click on share only the types of information selected below.
Since patients express concern about privacy,
they might well want to choose what information they wish to share.
Spend a few minutes looking at the choices and I think you will quickly appreciate why
understanding medical terminology is one of the challenges patients face in using a PHR.
Now spend some time exploring the various sharing options offered on this page.
Do you agree that computer literacy might also be a barrier to some patients using a PHR?
Finally, do you think there might be an even easier,
more usable way for patients to express these preferences and choices?
If you own a device, or use an app,
that can record health data,
I suggest you try to upload data from it to HealthVault.
As you can see here, there's an extensive list of supported apps and devices.
Might a fire enabled ecosystem of EHRs make all of this much easier for patients?
At a recent HL7 fire applications roundtable meeting at Duke University,
several vendors presented firebase solutions
for patients to aggregate data from all their providers.
Medley I was one of the new companies that presented at Duke.
To use their app, patients must first identify their providers.
To facilitate this, the app links to
a directory containing 4.2 million provider profiles.
To make searching easier,
patients are defaulted to their current location,
but they can search anywhere.
Having selected a provider,
patients can choose what data and date range they want to load into their app.
They then log on using their credentials for the chosen provider's patient portal.
One arm of the Medley O app seeks to create a meaningful medication list using
fire medication order resources from only the providers who wrote the prescription.
However, as you can see here,
every new refill for a prescription creates
a new fire medication order resource that makes us a long list.
A company's solution is to reconcile the orders using the RX norm CUI
number: a six digit numeric code that very specifically represents medications.
We will look at RX norm later.
They then group the orders based on this six digit number so the list,
as you see here,
contains each medication only once.
Patients can see each prescription,
the dates, and the prescribing physicians.
Care evolution also presented a PHR at the Dubfire applications round table.
The company says that it provides
secure interoperability solutions for population health management,
care coordination and consumer engagement.
Its myFHR, family health record app,
runs on the web and in iOS devices and leverages fire to enable consumers to
aggregate and manage their health data from
multiple hospital or physician office portals.
Consumers can view and manage their medications,
allergies and lab results.
The app also supports wearable sensors and connected devices,
such as glucometers, weight scales,
and blood pressure monitors,
provides notifications for upcoming appointments,
overdue preventive screenings and immunizations, and drug-drug interactions.
We will now see a video demonstration of myFHR provided for this course by the company.
Before we watch that video,
I would like to provide a personal note.
While I was still in training,
I cared for a patient who eventually died because he was
taking two simultaneous prescriptions for prednisone,
the steroid medication mentioned in the video.
A tool like myFHR might well have prevented that tragedy from occurring.
So at this point we're starting with Mary,
who has already established an account and logged in.
You notice she gave herself some patient notes and
she also has uploaded a report that includes a diagnostic X-ray.
For this demo, we're going to show off some of
the fire connection capabilities of My FHIR.
So we're going to go over to the Settings tab and click on Add a provider data source.
This list shows all the available provider data sources.
You can also search by state, zip code,
name or anything else like that.
In this case, we're going to connect to Epic.
In this case, we're going to allow access and that will take us back to My FHIR app.
In the app, in this case,
we need to associate the Mary A account from
Epic to the Mary A account that My FHIR knows about.
This only happens if not all of
the identifying fields can be lined up between the patients,
that as My FHIR sees it and as the provider sees it.
So now, you can see we have a connection to Epic sandbox as a data provider.
And right now, the the app is going out and downloading
Mary's information from Epic and loading it into the system.
And as you can see, when we refresh this,
the date has been downloaded a few seconds ago.
If we go back to Mary's profile,
we can see she now has medications.
If we click into the medication list,
we can see everything that my FHIR is aware of and in this case,
all of it came from that Epic connection.
Going back to the setting screen,
we're going to connect to another data source.
In this case, it'll be CareEvolution's provider data source.
CareEvolution provides a screen that allows the user to
select the patient from all the patients that they have access to.
If CareEvolution's provider allowed Mary to see her children,
or her parents, or her spouse,
they would also be listed in this list right here.
And depending on who she's trying to log in as,
and whose data she's trying to download,
she would select them from the list.
In this case, she'll just select herself and you'll see that the CareEvolution FHIR and
provider is added to the list of data sources and we fetched data.
Now when we look at the medications,
we see a combined list from both data sources.
In this case, it's quite a bit longer.
You can also see,
that we've called out that not all of your providers know about all of
your medications and we can drill into that to see exactly what it means.
On the summary screen,
you'll see that all the providers know about
these four medications and only some providers know about these four medications.
But since only two of them are currently active,
we're only going to focus on those.
So you can see CareEvolution is unaware of this one and Epic is unaware of this one.
If you wanted to, you could drill down and
take the perspective of one of these two providers.
In this case, let's say we have an appointment at the Epic provider.
Now, when talking to the doctor or nurse during your appointment,
you can say that you're not aware that I am
taking Prednisone and that's coming from CareEvolution.
So they can add that to the list and be aware of everything that you're actually taking.
Now, let's add one more data source.
In this case, we're going to connect to the Cedar-Sinai test box.
Cedar-Sinai is actually running a higher end point in production
and patients that go to Cedars-Sinai as one of their providers,
will have a log in to production and be able to pull their data into the My FHIR app.
Since Cedar-Sinai uses Epic,
the screen should look familiar.
It looks exactly like the Epic sandbox.
And after everything has been established,
you'll see Cedar-Sinai has been added to the list and is currently
waiting for its first update.
And now we fetched data.
So again, if we go back to the profile,
we'll see there's a couple of extra things in
here that we were able to pull from Cedar-Sinai,
including immunizations and allergies.
We can also see that the medication list has grown in this case, by quite a bit.
If we wanted to, we could provide a little extra detail here by changing the view.
And now, we can see who the prescriber is,
what the medication class is and where each of these pieces of data came from.
So you can see there's quite a bit of varying data from Cedar-Sinai.
In this case, we can see that Lisinopril is known by all three providers but
only Cedar-Sinai knows about this one.
We also have a feature where if we know about all medications Mary is taking,
we can notify the user about things like drug-drug interactions.
So in this particular case,
we can see that there is an interaction between an SSRI and an NSAID.
And because we know that that's an important interaction and that
Mary should be aware that it could cause intestinal bleeding,
she should probably talk to her doctors and do something about it.
We can also allow Mary to edit this medication list.
And say for instance,
she's not actually taking this Potassium Chloride.
When she updates the list,
Potassium chloride will be added to the bottom in her inactive.
She can also choose to add medications that none of her providers know about.
For instance, she can say that she takes Melatonin to help her sleep.
And now, Melatonin has been added to the list.
We discussed patient portals as a way to automate giving patients
their data that may be limited to data from a single health system.
We then looked at how a PHR or a fire app can make
this task more manageable across providers.
Could it be even easier for a patient to see
all their data no matter where they receive care?
Since they pay for most of it,
each provider's health insurance company,
should have a comprehensive view of their care.
No matter where it takes place.
This claims data has limitations.
For example, while claims would show when a lab test was performed,
they would not have the result.
However, it may often be
the most comprehensive longitudinal view of
a patient's care that is practically available.
Medicare's recognize that and his blue button on
fire initiative is an innovative approach to patient empowerment.
Paul LeBrone, my colleague and entrepreneur and residence at the CDC,
will now talk with Mark Scrimshaw,
Entrepreneur and residence at CMS to learn more about blue button on fire.
Hi? I'm Matt Scrimshire,
I'm a CMS Blue Button Innovator or entrepreneur-in-residence at CMS.
Mark, what's an entrepreneur-in-residence?
And how did you end up in this role?
Interesting you should ask that.
I describe it as being paid by the federal government
to cause trouble inside the federal government.
You know, I think an entrepreneur is someone with a passion
or naivety to think they can change something for the better.
And so, I've always been passionate about Blue Button and so,
I got invited to go in and a tweet
said you should apply for this position and I ended up there.
So, that's how it goes.
Power of the little birdie.
Absolutely.
Mark, can you explain the Blue Button on FHIR project,
and how you came up with the idea.
Blue Button on FHIR.
Blue Button's been around for nearly seven years and,
but it's basically a text file that a beneficiary or
consumer can download from the portal that they use.
The problem is that every Blue Button falls
different which is a real pain for us as developers.
The idea was it didn't really come from me,
but from CMS saying they wanted to upgrade that to become basically a data API.
So basically data is a service,
and I was brought in to actually tackle that project.
The reason it became Blue Button on FHIR is just really a combination of circumstances.
I often describe myself as lazy,
so I didn't want to go and create my own API if there was one out there in the industry.
The advantage of using an industry API is as
the API matures and the tools around it mature, everybody wins.
The idea was really to build Blue Button,
the Blue Button text file that CMS distributes to
beneficiaries as a data API in
structured data format that something the industry is going to be able to recognize.
Mark, can you tell us about the size and scope of the Medicare population and
the claims data set that will be made available through Blue Button on FHIR.
Sure. We're making the Blue Button API at CMS available to
all Medicare beneficiaries and
that's actually a population of somewhere around 38 million,
on medicare.gov itself is around I
think 29 million beneficiaries that actually have accounts.
In terms of the data,
we're releasing a part A,
part B, and part D data.
That's the hospital, the professional, and pharmacy data.
That's in the current Blue Button file
and they currently receive three years worth of data.
If you run that up,
it's somewhere between six and eight billion records
that we're going to be making available.
In your perspective, what are the advantages and disadvantage of
claims data as a source for patient facing apps?
I think the fact that it is just claims data.
The VA and CMS both published Blue Button.
The VA actually has a lot of clinical data in their information set and
that shows that the veterans come back to download that data more frequently.
For us, we really just have the part A,
part B and part D claims data.
It is claims data, but it's also something that
patients will actually recognize because they usually see the bill.
There were a bunch of these,
what we're looking at is because we're building with the FHIR API that the API can be
extended to cover other data sets or other resources within the FHIR specification,
so the Blue Button API could be used for example in a hospital situation or
maybe for the Veterans Administration and be able to release those other types of data,
but using the same basic Handshakes that we are trying to pioneer here at CMS.
After the patient has given authorization?
Exactly.
With blueprint on FHIR,
how do you handle access to the appropriate data?
There's a number of aspects to that question.
Firstly, the Blue Button API will connect a beneficiary to their data.
We'll be matching them.
That's one slight change to
the FHIR specification is that we will be sort of overriding and saying,
"No Paula, you can only get your data."
So, we're limiting what they can release.
It's an important thing to understand some developers
think that by connecting to the Blue Button API,
they can get at those 38 million patients' records.
No, you have to recruit each patient and get them to authorize your access,
so there's that aspect to it.
Then there's the question of well,
how do we choose about trusting applications?
Well, that's a really good question and that is fairly complex because on the one side,
you've got CMS or any other data holder in
this industry takes really seriously the security of their data.
At the other end of the spectrum,
you've got the directive from the Office of Civil Rights and you've got enshrined HIPAA.
The fact that a patient has an absolute right to their data.
Additionally, a lot of people say, well,
what about data being sent off to a hacker in Russia?
Well, actually the fact is,
that a patient can knowingly choose to send their data to a hacker in Russia if they,
if they want to, that they are perfectly at liberty to do that.
The question is we want to try and take steps so that they don't unknowingly do that.
One of the things that we've certainly been pushing with CMS here is
saying every data holder in this industry has the same problem.
Every developer aiming to do work in this industry has
the same problem of having permission to connect to the API.
Well, with Blue Button on FHIR as an API,
you as a developer can connect and get a key,
but you have zero access to any data until a beneficiary gives you access.
What we're trying to stimulate a discussion
around is really the establishment of let's call them
trust communities or endorsers that could endorse third-party applications,
and those applications could bring some sort of token to a data holder like CMS and say,
"Hey, we've been checked out over there."
And in that way what it does is it then starts to
create a scenario where the patient could
see a badge that says this application has been validated by this organization,
or maybe knows somebody who created
an application over the weekend and they want to share it with their family.
Yes they should be able to do that,
but if they do that and we see that they did
that application doesn't have some sort of validation token,
we can at least ask the patient, the consumer,
if they want to do something stupid and share their data with that application.
It's a complex scenario and I think we have to have a range of
solutions that tie together to reduce the risk for the data holder,
make it easier for the developer to integrate
with lots and lots of different data access points,
and the patient to have a clue about what they share and who they're sharing with.
What benefits does CMS hope to achieve by
allowing patients to access their own data through Blue Button on FHIR?
Well, I think we see that really we're entering an era of more retail medicine.
The patient, the consumer is going to take more control over their health.
Well, how do they do that without data?
The Blue Button on FHIR API is really trying to
open up the gates so that consumers can get access
to their data and find partners they
trust to help them look at that data because they do not want the data for its own sake,
they want to do something with it.
They want whether it's to donate it to research,
to put into a personal health record app or some concierge app or
their doctor's EMR because they trust their doctor.
It's going to be their choice.
And we want to simply make the data flow so much like Todd Park said,
it's really about like creating the,
being the knower of` health care,
allowing the data to flow and lets
an ecosystem of applications spring up service particular needs.
And network effects will start to kick in.
Absolutely. When I was
first starting out on this role somebody actually reached out to me and said,
"so, are you going to be building a diabetes app?"
And I said, "No, we're, we're building a pipeline."
And if you were an expert on diabetes,
go and build that app.
What are your hopes and future plans for Blue Button on FHIR?
We're actually building the Blue Button on FHIR API as a two part API.
We're building on the reference platforms that are already emerging in the industry,
and we built a front-end.
It's all open source,
so we would love other institutions and organizations to take our front-end and plug it
into FHIR modules that are coming out of all of the big EMR vendors.
There's that opportunity to create
a more consistent API for a growing ecosystem of applications to connect into.
I think the other side of it is dealing with this issue of trust for applications,
we have to solve this problem for the data holders,
the developers, and the patient.
And so, I'm looking to see that,
to try and stimulate that work,
and to that end there's a few of us that have been working on this opensource front-end.
You can go to GitHub,
look at Transparent Health,
find HHS OAuth server and you'll find our code.
What we're doing is we're evolving that into a not for
profit foundation so that we can have both the commercial and noncommercial entity,
because any organizations looking to seriously append
on an API like this is going to as they say in the industry,
one to throat to choke.
They may want to license some sort of service or support from an organization,
and I think that's a good thing because that would potentially
create longevity around the API,
and see it as it lives on and continues to get developed.
We'd love to see it get adopted not only in this country,
but internationally, which is certainly within
the realms of possibility because FHIR is an international standard.
Thank you so much for your time.
It's a pleasure.
As an alternative to any of these approaches for
giving patients the data from their AHR records,
why not give them direct access to those records?
Dr. Schenck and Warner first proposed
this radical idea in the 1973 New England Journal of Medicine.
In 2010, Beth Israel Deaconess Medical Center, in Boston,
Geisinger Health System in rural Pennsylvania,
and Seattle's Harborview Medical Center,
launched an exploratory study of the idea,
funded by the Robert Wood Johnson Foundation.
Primary care doctors invited their patients to
read their notes via secure online portals.
The results were published in 2012,
in the prestigious journal Annals of Internal Medicine.
According to this effort, now called OpenNotes,
the big takeaways were,
doctors reported little change in their workload.
Patients overwhelmingly approve of note sharing.
Few patients are worried or confused by their notes.
Today five million patients have access to OpenNotes.
You can visit https://www.opennotes.org for more information.
But we will now watch two videos provided by OpenNotes.
The first, shows how patients report reading
their notes helps them feel more in control of their health and health care.
This second video provides evidence that patients can
provide quality control from their own notes.
Even if we're having a discussion between sort of patient and doctor,
and the person seems to fully understand everything,
then the family or patient can walk away and 10 minutes later we'll have a discussion.
We'll say, did they say this or did they say that?
Like, there's big amnesia.
I forget what was said about the medication.
I can go back and see what medication,
and what the dosages and all the things that I'm supposed
to know are all recorded in that note.
Having it written down,
it's almost like there's another person telling you to take your meds.
I almost think of OpenNotes as closing the loop for me in many ways in that,
I meet face to face with the patient we have a conversation, I document it,
then I picture her going home and reading it later.
So it does feel like it extends the visit,
enhances the relationship, really sort of cements it in many ways.
It's actually allowed me to be more present in my visits,
perhaps ask some more thoughtful questions in
a moment because I know that that note is coming.
It's not just the conversation that we have for two minutes but they
have a document to back it up and to come back and to clarify themselves.
The second session that we had,
she said to me,
what do you think about the idea of putting our therapy notes into PatientSite?
I said, oh my God, I love that. She goes, why?
I go, because in my world I forget.
For me I go back to my open notes all the time.
My husband is very hard of hearing and so you can imagine, I mean,
even with perfect hearing I miss what doctors say sometimes,
and he's really lost so it's been a godsend that I can find out what the doctor told him.
>>When you think about the diagnostic error or anchoring around a diagnosis,
having the patients read their note and actually see that
the physician clearly hear and understand the symptoms I was describing,
it has the opportunity to break a diagnostic anchoring.
>> One physician referred to me as having type 2 diabetes.
And someone had mentioned that a surgery that I
had was on the right side but it was on the left side.
So I've been able to go in and just let
the physicians know that you've made a mistake and they've corrected it.
>>It's not just patient engagement,
it's really about patient empowerment in care.
So we are basically inviting the patient,
we're nudging them and really asking them to go in and use this
and not just read it in a sort of passive way but give
us feedback on it and tell us what we could do,
what we did wrong, and tell us what we could do to make it better.
That's huge. We have not done very much of that in medicine.
We've just told the patient what to do.
>>I think one of the benefits for everybody moving away from
doctor knows best to doctor and
patient working together is that it's going to be recognized.
So the team owns the outcome.
>>I guess I am somebody who believes that trust will
be easier to come by between doctor and patient if there's more candor and openness.
Doctors and patients and family members who know that
there's a level of transparency will shift their behavior.
>>The thing that I care about the most with our department is what we call culture,
and culture is built in small acts.
Every little small thing you do that makes the environment more respectful,
more inclusive of patients creates that culture.
This is probably not a small, thing this is a big thing.
But for me, that's what this is,
this is another aspect of a way to be respectful,
inclusive and partner in patients for the ultimate goal
of improving their care and their satisfaction with our care.
So that's why I love openness.
Another aspect of patient empowerment and engagement
that many find exciting is the use of
social networking around health care challenges
and problems a group of patients have in common.
We will now interview Sally Okan,
vice president of advocacy,
policy and public safety at patients like me.
A pioneer in that realm.
So this morning I'm talking to
Sally Okun who's the Vice President

of Advocacy, Policy, and Public Safety
at Patients Like Me here in Cambridge.

Sally, thank you so much for
taking the time to be with us today.

&gt;&gt; Thank you for having me Mark.

I really appreciate
the chance to talk to you.

&gt;&gt; So we've talked before,

and I'm always fascinated by the story
of how Patients Like Me came to be.

So, would you tell us that story?

&gt;&gt; Sure, absolutely.

You know, it's not uncommon at all for
a one patient or

a one family story to actually
be a driver behind innovation.

Whether it's in healthcare or
some other experience.

And for our company,
it was very much that.

So, Stephen Haywood, who was 29 at
the time he was diagnosed with ALS,

had two brothers, Jamie and Ben Haywood.

And a good friend Jeff Cole,

who at the time of Steven's diagnosis
decided to dive in deeply and

figure out how they might help to
stall the progression of his disease.

Or, in fact, try to cure his disease.

All of them coming out of MIT,
engineer-minded and

solution oriented, and so

they really wanted to find some ways of
being able to help Stephen through this.

What they found was rather frustrating.

A lot of the research wasn't
available for them to be able get at.

Some of the information that they
were receiving was conflicting.

And they ultimately decided that much
of what they were actually learning was

from other patients and families who
were dealing with the same issues.

And decided that they really needed to
find a way of being able to bring those

patients and families together to better
learn and connect with each other.

And ultimately find ways of being able
to monitor track their own experiences.

Bringing that together, you start to
learn about the collective experience

and the collective
wisdom of everyone else.

So Patients Like Me was actually
born out of that kind of model.

Bringing people together, helping them
find different ways of being able

to problem solve in their own times of
living with illness, but also finding

ways of being able to connect to the
opportunities to contribute to research.

And that was a big
component of what we do.

&gt;&gt; Well, there's a wonderful story about
the ALS community on patients like me,

contributing to research around
a report out of Italy I think it was,

that maybe lithium would
benefit these patients.

Can you tell us about that?

&gt;&gt; Sure.

You're exactly right.

It was a small Italian study that
was done and it indicated, or

it claimed actually that the use of
lithium carbonate was actually slowing

the progression of ALS in
a small subset of patients.

What our patients on the site, who
are already part of a community that was

tracking and monitoring their condition,
many of them went to their doctors and

said I want to try Lithium.

And in this particular population,

the doctors will oftentimes try to work
with their patients to try to determine

an appropriate use for
an off label indication.

So in this case many of
the patients started using Lithium.

In fact,
we had about 348 patients on the site,

who were actively taking Lithium
under their clinician's review and

starting to track their
experience with that.

And they came to us, very activated,
to say can you help us start to gather

the data in such a way that we can
actually start to determine whether or

not this claim from this
study is right or wrong.

What we learned in a very short
period of time, quite frankly,

in nine months, we were able to
demonstrate with this group of patients,

that the claims that were made in
the initial study were not holding up,

that the progression was continuing.

There was no indication that the
progression was slowing as a result of

using the product.

So we took that opportunity to suggest
that this was an environment within

which patients who are activated and
interested in participating in research

could contribute their data
in a very meaningful way.

We took it to the next step, however.

Because we understood that
we have a biased population.

So our research scientists and data
scientists spent time developing a novel

algorithm where they could match
patients who were using Lithium

with patients who actually had a similar
disease course but were not on Lithium.

So they were able to create a control
group, that actually then was

useful in being able to support the
report that we ultimately showed, which

was that Lithium really did not have
an impact on the progression of ALS.

In fact you know, for
some patient's it could have been

a concern because they were actually
taking a drug that might have had

adverse effects that they didn't
necessarily need to incur.

It was a great opportunity to show the
power of the patient research network.

&gt;&gt; So, you began with amyotrophic
lateral sclerosis but

you've certainly expanded
well beyond that.

Can you tell us about the other
conditions or the number of

conditions and the number of communities
are now on Patients Like Me.

&gt;&gt; Sure.

We currently have about

We cover over 2,000
different conditions.

Initially when we came out of the first
few years with Patients Like Me,

we were really relatively
small communities that were

focusing a lot on these very serious,
neurological conditions similar to ALS.

With MS and that sort of thing.

And since then we've really
expanded quite a bit.

So today we have communities
are focused on, Multiple Sclerosis is

one of our largest communities still,
about 40,000 patients.

We have a very large community
of fibromyalgia patients.

Patients for whom the system
isn't necessarily very helpful.

Because it's such as complex
condition with a lot of symptoms, and

not a treatment in sight right now.

Many mood conditions.

So we have a lot of patients
who are using the site for

monitoring their depression or
their anxiety disorders.

But then other conditions such as
epilepsy, rheumatoid arthritis,

many of those are also in
the thousands of patients.

We're seeing more and more,
some of the more rare conditions and

often times, parents coming on to
the sites to start to monitor and

track their children who have some
unusual and rare conditions as well.

So, it's really expanded,
just, exponentially, frankly,

from where we began and it's very
exciting to have the opportunity to

have so
many different conditions represented.

&gt;&gt; Well this is a health
informatics course, and

I know from discussions we've had
in the past that there is a lot of

informatics sitting under this beautiful
user friendly, non technical site.

Can you tell us a bit about what it
takes to actually make this thing work?

&gt;&gt; Sure it does take
a lot of engineering.

Much of our company,
we have about 80 staff now.

Much of our company are engineers,
software developers,

designers, user experience specialists.

Then we also have the other side of
the house which is research scientists,

data scientist and clinicians, who are
trying to bring the two worlds together,

very much in health IT perspective.

So on the clinical side, for example, we
actually take all of the data that comes

in from patients, and we actually
code that against the standardized

terminologies that you would find in
an electronic health record for example.

&gt;&gt; Can you tell us which ones?

&gt;&gt; Sure, we actually code against most
of the ones that you would imagine.

So ICD, SNOMED, we use mEDRA for
side effect data,

which is what the pharmaceutical
industry as well as the FDA uses for

monitoring adverse events.

We use Multum database right now for
our drug database.

But we're moving more
towards using RxNorm.

Again another one of the standardized
terminologies that's within

the UMLS library.

So we try very much to
use existing standardized

databases in order to be able to
normalize our data in some way.

So that it ultimately could be able to
be interoperable with other systems.

Right now that's not as transparent
on the site as you might imagine, but

when you go behind the scenes,
we can then begin to look at

how many ways have people
talked about their symptom,

against a particular
specific clinical concept.

And there could be 30 different
ways that patients actually express

one clinical concept.

So, that's actually contributing to
the development of a patient vocabulary

that actually maps back
to clinical concepts.

And there's probably close to eight or

patient's voice that we've actually
then mapped to clinical concepts.

&gt;&gt; Super.

I know you've recently, we talked
earlier about clinical research, and

you emphasized that the Lithium study
really isn't a controlled trial,

in the classic sense.

But you guys are helping your users,

your patients find and get involved
in clinical trials, I understand.

Can you tell us about that?

&gt;&gt; I can.
And we have a few ways of doing that.

One is that we download every night,
the data from cliinicaltrials.gov.

And so a patient can look at their
profile the next morning and see,

based on their profile data, which
trials they actually matched against,

within 25 miles of their home.

Gives them a place to begin.

Then we've also just recently
announced a service that we're

going to be provided to
the pharmaceutical industry.

It's called Trial Access.

We've learned from our patients through
surveys that we've done with them,

that many of them have been invited
to participate in trials, and

many of them have not been
satisfied with the experience of

those who actually did participate.

Sometimes it's because there wasn't
enough patient-oriented consideration

into what it took to
participate in a trial.

So what we've learned is that by having
this service called Trial Access,

we're actually going to be
helping patients participate

in the development of trials,
right from the very start.

So they're better able to say, this
particular intervention is going to be

very inconvenient for
me to be able to do.

Had you considered that?

Now another way of being able
to state that could be, if

I'm going to have to have a blood sample
drawn, we need to determine how far away

I'm going to need to go to get that, or
can someone come to my home and do that?

So there's different ways that patients
can actually contribute practical advice

to the child development [CROSS_TALK].

&gt;&gt; So patient-centered clinical trials.

&gt;&gt; Absolutely.

&gt;&gt; A new concept.

&gt;&gt; All the way through the system.

And actually even also to the point
where they are participating in

the evaluation of that trial.

How did it go?

And being able to get some
findings back to them.

Right now,
you participate in a clinical trial and

you never know what the outcomes
of that trial were.

And if you have access to a journal, you
might be able to find the publication at

some point, but
much of that data isn't published.

What we're saying, and
we're suggesting, and

we're hoping, that the industry
really begins to embrace.

Patients need to have some feedback.

There needs to be a mechanism that
if I've contributed my data and

I'm participating in this study.

I'd like to have some sense
of how it all went and

how it did contribute to new knowledge.

&gt;&gt; Well great, so that sort of leads
to my last question, which is,

I'm going to ask you to
get out your crystal ball.

What do you see as the future
of Patients Like Me,

at least that you can discuss?

And specifically,

and I'm not sure I know the answer
to this one, as I'll be interested.

How do you see Patients Like Me
being involved in VDT, the move for

patients to be able to upload
their electronic records and

share their data with each other and
with other clinicians?

Well, we have a lot of
exciting things going on.

And some of the projects that
we're currently working on

are very much about that.

We're doing some testing and
piloting of sensors and

mobile devices and wearables.

Trying to figure out ways of being able
to give patients the opportunity to have

access to these devices, bringing
that data into our platform, and then

ultimately finding a way of bringing
that data into the clinical records, so

it can be useful.

But there's a lot that you, as you might
imagine, that goes along with that.

We need to think about how
do we standardize that data,

how do we understand how
to code that data so,

we're just really beginning to learn and
those projects are just launched.

We've just actually sent out the
packages to the patient participants, so

they can start to do that
active data collection.

We see the platform as being an
environment where patients can truly be

a part of the changing healthcare
system in an area where we've

never really had access to their voice
in such a systematic way before.

And we believe that, actually,
that contribution will

really help us achieve the promise of
a continuously learning health system.

Without that voice, we're sort of
operating in a bit of a vacuum.

So we are continuing to build
the platform with that in mind.

We hope, within the next year or so,
to really have the ability to have that

interoperability data exchange, so that
we might be able to pull in data from

an EHR record, to unburden the patient
from having to enter all that data in.

But you know,
there's another facet to that.

The patient can also verify the data.

&gt;&gt; Exactly.

&gt;&gt; And really reconcile
the medication list for example,

as part of the helping to then
achieve something that an electronic

health record holder needs to do.

They need to reconcile
the medication record and

this is a way of being able to do that.

So there's a variety of ways that we see
our ability to be able to take advantage

of that kind of view, download and
transmit type of technology.

But we want it to be bidirectional.

Let's get data going back and forth.

So that ultimately each record is
a reflection of the full 360 view of

the patient.

&gt;&gt; You raise a really interesting point.

I was at a talk recently from
someone at the Geisinger Clinic.

Which is a very well known
health system in Pennsylvania.

And they have an open chart initiative,

which allows patients to
see their actual charts.

And one of the benefits they've
seen is that patients find and

help them correct mistakes.

&gt;&gt; Errors, exactly.

You know, it's really very common for

something to be on a record that isn't
quite accurate, or for a patient to see

a medication that they may have taken,
ten years ago, but no longer take, and

be able to say to the doctor, this is
not accurate let's fix it together.

One of the things I've been playing
around with is this equation, and

I've been talking about it a lot lately,
and that's this notion of shared data.

So my data as a patient, your data
as a clinician, our data together.

Actually can, when you add that into
a shared decision making model,

ultimately leads to a shared
accountability for the outcomes.

So that we actually all have
the opportunity to share in

the ways that I can improve my health.

I can have my health be more
reflective of what matters to me.

But at the same time I'm understanding
the kinds of things that are,

a clinician needs to know in order
to be able to take better care of

the needs that I have so.

&gt;&gt; Well as soon as I
get back to Atlanta,

I'm going to encourage our
friend Marla to sign up.

So if you see a woman with a lot
of problems named Marla sign up,

you should know that I sent her to you.

&gt;&gt; Well the other thing to keep in mind
with that in mind is that the site has

levels of privacy that allow a patient
to use a username or their real name.

But I would want to be sure that people
do know that we do take great strides to

be sure that the experience for patients
is safe, they can trust the site,

they can feel comfortable about
being able to exchange information.

&gt;&gt; Students know who Marly is,
you don't.

&gt;&gt; I don't [LAUGH].

&gt;&gt; Thank you very much.

&gt;&gt; Oh, thank you.

&gt;&gt; Great talking to you.
You now know that chronic diseases drive most U.S. health care costs.
Once diagnosed, they're usually not curable.
What patients do in terms of behavior and compliance with
their treatments is critical to success in managing them.
As a result, there has long been interest in the potential of technology in
the home to create a more continuous and coordinated approach to care of these patients.
This is yet another old health informatics idea,
only now coming to fruition.
Here's a photo of Steve Kaufmann,
one of the early innovators in this space,
with Hank, his home assisted nursing care robot.
Hank offered a wide variety of voice control nursing services
to patients at home in the mid 1990's.
Among other things, Hank dispensed medications at
the proper time and took physiologic measurements,
such as blood pressure with its patient-operated devices,
using the technology of the day.
During the same period,
I was one of the founders of a company that provided
an electronic records system for
the home care nurses who took care of patients after they left the hospital.
We could see the benefit of knowing more about the patients between
nursing visits and reinforcing the instructions the nurses provided.
We developed this roughly cigar-box-sized touchscreen device that,
like Hank, spoke to the patients.
It, too, had integrated physiologic measurement devices.
Of course, as you'd expect,
software for home care is now available on smartphones.
This example is from AlayaCare, a Canadian company.
It provides nurses with a patient overview at a glance on their phone,
along with important documentation,
administrative, and billing functions.
Patients record some of the data as is illustrated here.
This example question would be part of something similar to
a Likert survey that collects the patient's point of view on a daily basis.
Along with vital signs data coming from the peripherals,
it informs an algorithm we'll discuss later.
Of course, it is no longer necessary to provide
integrated physiologic devices since they are
consumer-level products and most have wireless Bluetooth syncing capability.
The company says, it can sync data from over 200 devices.
It brings this data together,
as shown here, for quick review by the nurse.
Finally, this dashboard provides nurses with a quick overview of their patients.
It provides a graphical representation of the incoming data from various devices.
Importantly, since a value might be normal for one patient but abnormal for another,
each measure has patient-specific upper and lower bound thresholds
that trigger workflows for various care team members.
If a threshold boundary is detected,
a risk score is calculated using rules developed by machine learning.
The risk score is a combination of the patients ICD-10 diagnoses,
demographic information, vital signs data,
and their Likert survey.
AlayaCare train their model using data sets from their remote monitoring partners
that critically include events such as hospital re-admissions or E.R. visits.
In 2013, Grahame Greive,
the leader of the global HL7's FHIR effort,
posted in reference to semantic interoperability quote,
"Let's not pursue the holy grail right now."
End quote. At present,
FHIR does not attempt to address semantic interoperability in large part because of
the additional complexity that would introduce to an already complex effort.
I will give you a sense of that complexity here,
but a complete treatment of the subject is well beyond the scope of this course.
There are many strongly held points of view
about the feasibility of semantic interoperability.
There are also strong advocates for
various approaches to a semantic interoperability standard.
We will now discuss one of the latest approaches.
The Clinical Information Modeling Initiative, or CIMI,
is another HL7 working group conceived by the same fresh look task force that birth FHIR.
Its mission is to improve the interoperability of healthcare systems through
shared implementable clinical information models.
The ultimate goal is semantic interoperability.
It is important to understand that data exchange and the use of
coding systems alone is insufficient to achieve semantic interoperability.
There are many codes for lab test or clinical diagnosis.
In the case of a lab test,
codes could specifically indicate which of several available methods the lab used.
And this could affect the interpretation of the result.
Other codes might just indicate what kind of test produce the result.
For a diagnosis, there can be many levels of coding detail and specificity.
There can also be structural differences in coding systems.
Providers can differ as to how and when they use these codes.
Finally, as we will now discuss,
multiple EHR is going to address the representation
of the same clinical concept differently.
Here's a simple illustration of the variability of
representation and of the semantic interoperability problem CIMI is trying to solve.
Three EHR systems represent the concept of suspected lung cancer differently.
In the general practice EHR on the left,
it is a compound construct created by combining three structured data elements.
In the hospital EHR on the right,
it's a single concept,
but polyclinics EHR in the middle combines both approaches.
There isn't a right or wrong way to do this,
but three different ways in parallel makes it harder to aggregate
the data meaningfully for analysis or to share it to coordinate care.
among these three practices.
Here, this CIMI graphic uses shapes to represent
the different ways the three EHR systems represent this single clinical concept.
For the purposes of illustration,
we're assuming the blue hexagon,
the approach used by the general practice EHR,
is the preferred shape,
and a hypothetical translation servers might put
all the instances of this clinical finding into that shape.
This is essentially a standard structure in which terms always go in the same place,
somewhat like in the HL7 messages we discussed earlier.
FHIR resources also provide
a standard structure specifying where data elements are located.
In that context, semantic interoperability specifies what formats and values to
use in specific clinical scenarios often called use cases.
As shown here in the most advanced CIMI proposed solution,
data not only goes into a consistent location,
but the terms are also translated into an agreed upon standard.
Now, a hypothetical FHIR app gets the same structure and
terms even though the source systems use different representations for both.
As I mentioned earlier,
semantic interoperability is difficult to
achieve given the complexity of health care data,
the many ways in which it is represented and the many contexts in which it is used.
We will discuss FHIR profiles later,
but they essentially constrain the standard for a particular use case,
thus, they can specify the preferred shape.
CIMI anticipates that its models will connect to an informed or
constrained FHIR through model derived profiles.
Next, we look at some exciting capabilities that
might be practical given semantic interoperability.
Earlier, we discussed some innovative approaches to physician charting.
Now that we have discussed semantic interoperability,
you can better appreciate the approach to
EHR documentation that Applicadia has developed.
Richard Esmond, the company's chief technical
officer and co-chair of the CIMI work group,
has prepared a short video for this course.
In it, you will see what he calls a graph
that is always focused around a clinical concept node
and presents the relationships it has to any other concept nodes known to the platform.
The node at the focus could be from SNOMED, ICD,
LOINC or RxNorm, some of the health data standards,
we will discuss in the next lesson.
It also might be a synthetic knowledge element that the company has parsed
or analytically computed and then attached to that node through a relationship.
Finally, a small but growing number of nodes are derived
from the clinical knowledge artifacts in CIMI models.
The video, though short,
is very rich conceptually and illustrates a number of interesting possibilities.
The use of voice recognition for medical documentation.
The use of an NLP to properly place voice narration into the traditional sections of
a medical note and even the proper body system area of the review of systems,
a key part of a medical note.
Automatic encoding of free text notes into
complex data standards such as SNOMED and ICD-10.
The further use of NLP to properly map voice narrative to the clinical concept graphs,
thus, creating a basis for semantic interoperability.
The use of a concept graph to guide the physician to properly
code into the very clinically detailed ICD-10 system.
The discussion of the history of present illness part of the note
concerning the patient's knee problem, illustrates this.
Similarly, this use of a concept graph could help the physician properly report
quality metrics or to remind them to provide
important but missing clinical details for a concept they've identified.
I urge you to study the video carefully using this list of capabilities.
The patient appears Anemic and pale, period.
Patient's heart rate is 98 and blood pressure is 120/80, period.
Go to history of the present illness.
The patient presents with severe pain and swelling in
the left knee due to micro-tears in the patella tendon, period.
And just to show you a little bit about what's going on the background.
So, we're taking the statement and running it through
computational linguistics to extract out all the key data points.
Then we have mapped that to an in-memory graph.
The graph contains a hybrid of
have woven together and then made it computable and processable.
And that's actually how we perform all of
our clinical decision support matching to clinical models.
Because at the end of the day, we're not saving the statement in the medical record.
We're saving the IDs using FHIR. So, clear this out.
Because that allows us to do things like ICD 10 coding.
So, this is not enough specificity to come up with
a fully refined ICD 10 building code. So, we're going to prompt.
Only swelling. It's traumatic.
And this is the initial count.
So, here's all our ICD 10 codes.
Here is the structures that we are going to be
saving using FHIR into the electronic medical record.
And over here on the left, this is the statement that
we're going to throw away. I'll do a few more.
Acetaminophen, 500 mg. Twice a day for two weeks with food as needed for pain, period.
The patient needs a bilateral mammography, period.
Now, as you noticed,
we're actually determining where in the medical record that each bit of
information goes based on the information that we extract out from it.
Go to review of systems.
The patient's breath sounds a normal, period.
The patient's heart sounds are normal, period.
So here, it's determining body system,
again, by the information that we extract out of the statement.
The patient's grandmother died of lung cancer 10 years ago, period.
The patient had an appendectomy four years ago, period.
So here, this is going in
the medical record for this patient but it's
going in as information about their grandmother.
In other words, the patient isn't dead the grandmother is dead.
Effectively, once you have information about each statement,
so many things about the capture of clinical information can be automated,
including clinical decision support in real time,
in figuring out where to place things in a medical record.
At the end of the day, the goal is to put
the clinicians attention back on
the patient and away from having to serve the needs of the system.
Anyway, thanks for watching this demo.
Earlier I said there are many points of view on semantic interoperability.
Lloyd McKenzie is an internationally recognized expert
in HL7 data modeling and design and an adviser to Canada Health Infoway,
an organization with roughly the same role that the ONC plays here in the US.
In March 2013, he posted this on Graeme Greaves blog,
"Really robust semantic interoperability is going to be dependent on machine learning and
other technologies that will allow the computer to be at least as
good at reasoning and inferring context as humans are now.
At which point we won't need discrete data at all.
Computers will be able to take a big blob of text, dictation,
images and so on and extract all the relevant information
needed for their functions without it being neatly divided up for them."
I believe this is an important point of view.
Later, we will talk more about the potential for machine learning in healthcare.
For now, it is worth noting that the explosion in the use of this technology
was in large part due to the availability of huge digital data sets on the internet.
After all, the learning part of machine learning comes about when
computers process a huge number of examples of something.
This might be pictures of cats.
It might be examples of some text translated into another language.
It also might be EHR notes about rheumatoid arthritis.
Those first two data sets have been widely
available for some time now because of the Internet.
To be fair, they are also quite a bit more consistent than EHR notes.
Finally, of course, there are no privacy laws covering
cat photos or openly available translations of text.
Nevertheless, with EHR adoption now widespread and assuming we can
solve the easier levels of interoperability and have broader access to clinical data,
might semantic interoperability be best left to machines to figure out?
The meaningful use criteria promote
robust interoperability between the systems used by patients,
providers, and healthcare institutions.
Meaningful use stages progressively demand
compliance with this patient engagement framework,
or PEF, developed by
the HIMSS Foundation and the National eHealth Collaborative that are now merged.
You can see how the stages of meaningful use align with the PEF.
Stage one of meaningful use,
the Engage Me phase of the PEF,
specifies that patients can view and download their electronic health record.
Stage two, the Empower Me phase of the PEF,
is far more ambitious,
and specifies integration with the Health Information Exchange,
or HIE, our next topic,
as well as e-referral coordination among providers,
ambulatory and hospital records integration,
the addition of images and video to EHRs,
and the inclusion of data from commercial labs, radiology, and pharmacies.
We're currently quite far away from having all of this everywhere,
but each of these capabilities is available in at least some places.
Presumably because of Meaningful Use,
a New York study showed the reported rate of PHR use increased from 11 percent,
More directly to the point,
the proportion of the PHRs provided by doctors or
healthcare organizations increased sharply from 50 percent,
This research also showed that the mean age of PHR users was 47.2 years,
and 80 percent had a physician who used the HRs.
Later in this lesson,
we will discuss health information exchange for HIE,
technologies for sharing health data.
First, any transport mechanism for HIE must assure privacy, security, and trust.
Privacy means sharing data only with patient permission.
Security means protecting that data from access by unauthorized entities.
To create trust an entity must ensure
the identity of other entities with which they share data.
Here in the US, the Health Insurance Portability and Accountability Act of 1996,
or HIPA, created a privacy rule.
The government says it quote,
establishes national standards to protect
individuals' medical records and other personal health information,
and applies to health plans,
health care clearing houses,
and those health care providers that conduct
certain health care transactions electronically.
The inclusion of health insurance plans and claims clearing houses,
and the focus on electronic transactions such as claims for payment,
may seem surprising to those of us focused on clinical use cases.
But the law also mandates uniform standards for electronic transmission
of administrative and financial data relating to patient health information.
The intent was to move these transactions from paper to
electronic form and that has been quite successful.
The rule also gives patients rights over their health information,
including rights to examine and obtain a copy of their health records,
and to request corrections.
HIPA penalties can be substantial and may include prison time.
So staying within the law is a priority in virtually all healthcare organizations.
We touched on privacy in the healthful exercise.
When you saw how patients could specify the subset of their data they wish to share.
In practice, patients still typically sign a form provided on
a clipboard in the waiting room and agree to
share all their medical record data for treatment,
payment and health care operations, so-called TPO.
In simple terms, this allows sharing of
their data with others involved in their treatment,
such as when their doctor refers them to another physician.
It also allows use of their data in claims for payment for services
rendered and for operational purposes such as quality reporting.
Beyond the routine use encompassed by TPO,
there are many secondary purposes for using health data.
These include comparative studies,
policy assessments, and life science research.
These uses of identifiable or so-called protected health information,
PHI, requires specific permission of the patient.
De-identification removes data from privacy rule protections by
eliminating 18 specified fields that could identify the individual patient.
Limited data sets still contain dates for admission,
discharge in service provision,
date of birth, date of death and city state and zip code.
The use of limited data sets for research does not require specific patient permission,
but it does require that the data be treated the same as
PHI since re-identification is possible,
given the inclusion of this temporal and demographic information.
To avoid this, in some circumstances,
researchers randomly alter dates and
other data where this will not compromise its research value.
Genomic data presents special challenges because each patient's genome is unique.
So altering the genomic data can severely compromise it's value.
There is a second approved but less often used method in which an expert,
who may have a statistical mathematical or scientific background,
certifies that the risk of re-identification is very small.
This can also involve some manipulation of
the data so the NORC group at the University of Chicago has developed XID,
a tool shown here that uses
proprietary statistical methods to give data owners the ability
to experiment digitally and refine their desired risk and analytic utility thresholds.
Public key encryption or PKI uses a pair of public and private keys,
X.509 certificates to secure data.
In simple terms, a certificate authority issues
the keys and binds them to the identity of an entity.
Before that, a registration authority,
which could also be the certificate authority,
verifies that the entities who they claim to be.
The keys are large numbers with a mathematical relationship that is prohibitively time
consuming and expensive to discover using currently available computing technologies.
As a result, data encrypted using either key can only be unencrypted using the other one.
Importantly, the public key is freely shareable but the private key must remain secret.
However, as we will now see there are use cases for using either key to
encrypt something and the opposite key to decrypt it.
In the most common use case shown along the top,
the sender encrypts a document they wish to
share using the intended recipients public key.
Since only that recipient has the matching private key,
only they can decrypt and read the document.
As shown along the bottom,
PKI also involves a digital signature.
Its purpose is to prevent tampering and impersonation in digital communications.
Creating it involves hashing which is the transformation of a string of characters
into a usually shorter fixed length value or a key that represents the original string.
A hash is then encrypted using the sender's private key.
The encrypted hash along with
other information such as the hashing algorithm is the digital signature.
The reason for encrypting the hash instead of the entire message or document is that
a hash function can convert
an arbitrary input into a fixed length value which is usually much shorter.
This saves time since hashing is much faster than signing.
Any recipient can confirm the source of the document by
decrypting the digital signature using the sender's public key.
Please note that this in no way compromises the sender's private key.
It just confirms that the digital signature was encrypted using it.
Also since the document was in hash,
this does not compromise confidential patient information.
The use of digital signatures is an example of
technology to establish trust in the origin of a document.
However trust says no purely technologic solution.
Some trusted organisation ultimately must verify that entities involved in
the exchange of health information are who they claim to be.
Hospitals already do this when they credential
providers to care for patients in their institution.
Establishing trust is harder when patients become involved in adding
information to their EHR or in retrieving information from it.
Think back to how fault's support a direct email for data sharing.
How might a provider know for sure that
such an email they receive actually comes from their patient.
This problem is harder when patients receive care from multiple organizations,
each of which must trust that the other has properly validated their identity.
Because we do not have a universal patient ID here in the US,
just being sure of the identity of patients can be challenging.
Sure, thanks. And I'm glad to be here.
I really got involved in open source Linux blockchain,
all of these technologies,
all of that, got my start at Georgia Tech.
I enjoyed just surfing what was then
the new internet back in the days of Mosaic 1.0 and before JavaScript,
before mobile apps, before animated web sites.
It was just basic HTML 1.0 and graphics that load really slowly.
And that was the atmosphere that I was raised in at Georgia Tech.
The dorms had just been wired for ethernet,
which was incredibly exciting.
We didn't have to do the slow dial up to connect to Hydra,
the multi CPU computer at the time the Acme Cluster replaced.
And it was an exciting time.
That was ethernet, that was the internet and that was open source.
You could, for the first time,
download software that was not proprietary,
that you could really open up the guts of and explore as much as you wanted.
And so after all my classes were done each day at Tech,
I would go to my dorm.
I was admittedly, did not see the sun often at times.
I spent a lot of time in front of the computer and I was downloading Linux.
I was downloading the GNOME Project.
All of these were the early precursors to what
you see today in Linux data centers and Android,
user interfaces et cetera.
So that self-exploration is what led me to open source.
I started with Linux 0.99
back when Linus Torvalds was still at the University of Helsinki.
Linus, a couple of years before,
in 92 which was my first year at Tech.
Linus had just posted the very first version of Linux and he said,
hey I've got my own version of Unix.
It's kind of like Minix.
Why don't you try it and download it?
And that kick started an open source revolution.
I came into that about a year or two after the initial Linux versions were downloaded.
It was amazing to not just receive a bunch of floppy disks,
which were at the time how you delivered software and load that into your computer,
you had no source code.
It booted up Microsoft DOS or MS Windows 3.1.
And that was it. Open source just blew all that to smithereens.
You could as a software engineer,
open up the car hood,
look inside, understand why it works how it works and then change it.
And the beauty of software and this is why I'm not a mechanical engineer,
this is why I am a computer scientist, is that you can change something,
press a button that says test, and if it explodes, which it usually does on the first try,
You can go back reset to the beginning and try another tweak and do it again.
That's what I love about software.
That rapid iteration process allows you to develop so much more rapid.
And so that open source process led me to Linux and
the open nature of open source meant that this university student could create a patch,
a software change, post it on a mailing list and have
a bunch of other professional software developers critique it,
provide feedback and ultimately integrate that change,
my change as a university student,
into this operating system that everyone uses worldwide.
And that really gives you frankly a little bit of an ego boost.
It gives you, makes you feel good that your change was accepted, reviewed,
welcomed and that peer review process
helps the community adjust to risk and avoid errors.
So that was my journey from the open source that I was coding in my dorm room
led me to Linux and my contributions to Linux as it's the ideal,
sort of meritocracy environment,
the Linux environment as you contribute more
you are trusted more and you learn more and you gain more experience.
And so it's a positive feedback loop whereby as
the years went by I became a better and better Linux developer.
I understood more and more about the hardware process.
I had taken Jim Greenlee's assembly language class
at the College of Computing where I learned MIPS assembly language.
But it was the Linux kernel that really taught me why you do what you do.
Why CPUs are architected as they're architected.
And so that open source process feeds back into other developers as well.
I was able to share that knowledge,
not only with other Georgia Tech students but
with other people in the community and you wind up mentoring,
spreading the knowledge and that led to a career at Red Hat.
Red Hat saw what I had been building,
contributing and they said, "Hey,
do you want to come work for us and build Linux professionally?"
So that Linux, that Linux experience which started in the dorm room,
started with volunteer self-motivated development eventually led to
an over 10-year career and that contribution to open source,
that experience in open source,
also sort of led me to where I am today which is in the blockchain industry,
which is another open source technology as well.
That's right. Late in my Red Hat career, circa 2010,
I was browsing what was a popular web site at the time, slash.org moniker news for
nerds and just basically everyone in the tech community at the time.
Definitely read that website.
It talked about a decentralized digital currency which was
open source and I had experience in distributed computing at the time,
and I had been a skeptic.
I thought to myself,
there's no way this can work.
You've got to have a central cluster of computers.
A central management system of some sort and I was happy to be proven wrong.
I looked at this open source technology and because it was open source,
you can open up the hood inspect the technology gain your own trust in that technology.
And that was my journey from Linux to blockchain,
was that there was a new exciting innovative open source project
which it disrupts the existing business flows,
it breaks new boundaries,
it creates new trust avenues.
And that was very, very exciting.
And so just like 15 years before in my Linux career, it was open source.
I was self-motivated.
I download the source code,
saw some changes that ought to be made.
I thought in my humble opinion.
So I made those changes,
submitted those to the then leader of the project Satoshi Nakamoto,
a pseudonym nobody, mysterious figure,
nobody knows who he really is and he accepted those changes.
So it was just like my first foray into Linux when Linus Torvalds,
the leader of Linux accepted my first patch to the Linux kernel.
It was humbling. It was rewarding.
It was very exciting and it was clearly the cusp of what we now see as
an entire industry, the blockchain industry.
Well, that's the question of the hour and more difficult to answer than you might imagine.
Blockchain is at once a database technology.
It's a technology that has a secure log of changes to a ledger.
It's a distributed network distributes those changes in that database,
that ledger to multiple nodes in a computer network,
all of which are cross checking each other to make sure that that ledger,
that database retains its integrity.
And so this is a very resilient technology, blockchain technology.
If you have a some of those nodes in the network are
malfunctioning then the network is resilient,
it automatically detects and routes around those changes.
And for this reason, it's essentially a reduced trust, very secure database network.
And the reason why that's interesting is that you can use it to deploy
some types of business cases and scenarios which benefit from that reduced trust.
The first use case being bitcoin which is
entirely dependent upon all of the nodes in this computer network.
Arriving at the same answer that Jeff has certain amount of digital currency,
say 100 units of bitcoin and Jeff transfers these to Bob, say 50 units of bitcoin,
this distributed ledger updates my balance
from 100 to 50 and Bob's balance from zero to 50.
Now we can obviously accomplish this with
a centralized database fairly easily and that's what banks do today.
The innovation in blockchain is that you don't necessarily
have to have a centralized authority to execute highly secure database updates.
In this particular case, currency.
The security of a currency is reliant upon this highly secure technology.
And so without that extremely high level of security,
you would not be able to reduce the level of trust required to use the system.
And so this has various cross-border,
cross company, cross organization,
cross business unit type of advantages whereby blockchain is more secure,
therefore you can create connections that can otherwise not be
connected. Well, there's really a lot of potential I think for blockchain in
health care but it is very, very early days.
As we like to say, the software has a lot of rough edges right now.
And so just pragmatically as a business person to a customer,
I would say that the roll-out is going to take several years,
but the potential is that it's worth it.
The potential is, is that we can have a more secure provider licensing,
more secure medical records,
we can utilize associated technologies such as digital identity,
smart contracts, and encryption to really put the patient in control of their own data.
We call that self-sovereign data where you are in control of
your data as a first principle and you permission your medical data to say your provider,
your hospital, your insurance company and
you're the one who is in control of that data permissioning.
And so therefore you're in control as a first pass as to who sees your very,
very private medical data.
And so encryption, a digital identity and anchored in
this very secure database technology blockchain
is absolutely going to make health care more secure,
put the patient in more control as well
as enable what I call gap filling is that today as you,
patients bounce between providers,
as providers bounce from state to state,
there are gaps and records.
And records for example for a provider in
North Carolina might be different from the records for a provider in Georgia,
even though it's the same provider.
It's just a information technology problem,
a data sharing problem that blockchain and some of these cross
organizational technologies really help to solve.
Absolutely. So based on my experience in Linux and I really saw Linux grow up from
a university project to a project that was trusted by startups
to a project that was trusted by
Fortune 500 companies and their data centers of their most critical data.
That flight path was really assisted by in large part Red Hat.
Red Hat took the open source community in one side,
enterprises in the other side.
Normally the open source community doesn't really get along with large business.
They're ideological, they're very have different motivations et cetera.
There are a lot of rough edges professionally.
And on enterprise they don't necessarily understand how to contribute to open source,
how to approach the open source community and how to
capture all that innovation that's coming out of open source.
Red Hat, their core idea was sitting in the middle and speaking
both open source and hacker ease and speaking enterprise on the other side.
And that's really the core vision for block,
is that blockchain has a lot of very fantastic,
very innovative developers with
themselves a bit of rough edges about them and enterprise,
specifically financial services and banks,
they have very, very specific compliance needs.
Risk needs legal needs and you need someone in the middle who can
talk blockchain to enterprise as well as talk blockchain to hackers,
bring the two together and create
a professional risk adjusted product that is essentially enterprise grade blockchain.
So that's what block does is we sell an enterprise blockchain product to small startups,
large enterprises sort of the Red Hat of blockchain.
A Health Information Exchange or HIE is
a specialized network for secure sharing of patient data.
There are various HIE architectures that correspond
functionally to the three forms of interoperability we discussed earlier.
You should recall that the first form of interoperability is
simple transport of the data from one provider to another.
The transport mechanism has no knowledge or understanding of the data.
ONC created the Direct Project in 2010 to specify a simple, secure, scalable,
standards-based way to send authenticated encrypted health information
directly to known trusted recipients using secure email.
This is a graphic illustrating Direct or simplification it assumes among other things,
that both providers are using the same Direct server
which is called a Health ISP or HISP.
You can see the Direct bills on existing technologies for email and securing data.
We will discuss those in a moment.
Most EHR, HIE and PHR vendors including HealthVault, support Direct.
Here, I have clicked on the HealthVault,
Health messages menu choice.
You can see that my HealthVault account
automatically provides me with a special Direct email address
that can be used to securely send and receive
health data only to or from other Direct email addresses.
In Sunny HR's providers can initiate Direct messages from within
a charting session such as when they're referring a patient to another provider.
We will now briefly discuss some of the standards and processes used by Direct HISPs.
To ensure secure transport,
Direct combines the Simple Mail Transport Protocol or SMTP with
special Direct email address as we just discussed and associated with X.509 certificates.
In most cases, an entity wishing to have an email address and credentials issued
goes through a process documented in a trust framework established by DirectTrust,
a collaborative nonprofit association of health IT and healthcare provider organizations.
This trust framework supports both provider to provider and
bi-directional exchange between consumers or patients and their providers.
Direct uses Secure/Multipurpose Internet Mail Extensions (S/MIME),
a public key standard for encrypting e-mail attachments
can be in virtually any format from a fax image to a PDF,
to a structured XML formatted, HL7, CCDI document.
Direct uses encrypted and signed Message Disposition Notifications
(MDN) to confirm delivery.
This can be particularly important in situations such as when
a lab sends a critical result back to the ordering provider using Direct.
Domain Name Servers (DNS),
the internet's equivalent of a phone book,
maintain a directory of domain names
and translate them to Internet Protocol IP addresses.
Lightweight Directory Access Protocol (LDAP) is
an Internet protocol in e-mail and
other programs used to look up information from a server.
Direct uses both DNS and LDAP to discover the certificates of
message recipients prior to sending
a message in order to fulfill the encryption functions of S/MIME.
You will recall that the second form of interoperability
provides a structure that contained the elements,
so that the receiving system knows what each element represents,
even though it may have no semantic understanding of its contents.
A common example is electronic lab reporting
results back to the provider who ordered a test.
Earlier, we mentioned HL7's Messaging Standard that dates from the 1980s.
The version 2 standard, you see,
here is based on edX 12 technology from that era.
The two lines in red are test results.
You can see that other lines may contain only a text message.
So this is not entirely a tightly structured standard.
With some study, you should be able to figure out
the contents of most of the fields in this message.
You should also agree that it is not nearly as human
readable as an XML formatted message.
The newer v3 HL7 Messaging Standard uses XML.
But v2 is baked into many existing systems,
and according to the CDC,
and despite its age in 2013,
compliant messages using various versions of the v2 Messaging Standard..
The most sophisticated form of HIE creates semantic interoperability,
thereby bridging the many ways the same concepts can be
expressed by providers and represented in EHRs and other clinical systems.
This involves a complex process that maps external representations of
clinical concepts to some standard developed or adopted by the HIE.
The premier example of this here in the U.S. is
the Indiana Health Information Exchange or IHIE, pronounced, "I-hi."
It says it is the largest such organization in the country.
This claim is easy to believe based on these participation statistics from the IHIE site.
Here you see a high-level diagram of the IHIE technical architecture.
The data governance box is where the curation of data
occurs to establish semantic interoperability.
Here on the right, you see that this governance enables a number of value-added services.
These include the reporting of laboratory test results we discussed earlier and of
the quality metrics that are increasingly required for
providers under the new payment models we discussed in lesson one.
The Regenstrief Institute in Indiana created
the expensive and sophisticated technology used by IHIE.
Support for that came from the Regenstrief Foundation,
a philanthropic organization that describes its mission as,
"To bring to the practice of medicine
the most modern scientific advances from engineering,
business and the social sciences;
and to foster the rapid dissemination into
medical practice of the new knowledge created by research."
Absent such unfortunately rare funding source,
this type of HIE is usually economically impossible to create.
In the case of IHIE,
as you see here,
all the curated data is aggregated and stored centrally.
This architecture is convenient for data governance, analysis and reporting.
However, it makes buy-in difficult for organizations that might be leery of turning over
their data and concerned about how it may be used and how their performance might look.
Again, Indiana has a special case where, over the years,
IHIE has gained the trust of the many care organizations we saw enumerated earlier.
This level of trust in a shared,
centralized architecture is rare.
The concept of a federated HIE goes a long way toward resolving these concerns.
In this model, the data stays at the source.
There is a standard for queries and responses and,
based on the query,
participating organizations usually have the option of responding or not.
In a federated model,
either the nodes must translate their data into
some standard response format or they must map
their information into a standard data model usually stored in
a separate server that can then serve to handle queries and responses.
By far the most successful example of this is
the Observational Medical Outcomes Partnership or OMOP and its OMOP data model.
OMOP was created to enable
active drug safety surveillance with government and pharmaceutical industry support.
Here you can see its global reach.
We built our Georgia Tech FHIR server using the OMOP data model.
While we will not discuss it in any detail here,
there's also a model that blends the centralized and federated approaches.
In it, all data is stored centrally but in
so-called data lockers that remain under
the control of the entity that is the source of the data.
That entity typically has the same control of
the use of the data they would have in a federated model.
Next, we will talk to my Georgia Tech colleague, Dr. Jon Duke,
who came here from the Regenstrief Institue that created
the technology used in the Indiana Health Information Exchange.
Jon was also a founding member of
the Observational Health Data Sciences and Informatics or
OHDSI initiative that developed analytic tools for exploring data in the OMOP model.
This example is a heat map showing the distribution of
diagnoses in a population of synthetic patients on our Georgia Tech FHIR server.
Population-level analysis is not supported by FHIR but might be in the future.
Thanks very much for having me, Mark.
So before coming to Georgia Tech,
I was at a place called the Regenstrief Institute which,
amongst informatics folks, is a pretty well-known place.
It's the home of one of the earliest physician order entry systems called Gopher.
Also the home base for LOINC which is well-known as well as OpenMRS,
a global open source medical records system.
Regenstrief Institute was a place
where I spent eight years focusing primarily on clinical decision support,
a lot of work about how we can design alerts that are more effective,
how we can create more influential designs
for driving behaviors and decision making amongst physicians.
Regenstrief Institute also is a place that has been a hub for
many years for I'm thinking broadly about the future of informatics,
and my time there was fantastic.
I was very excited to have a chance to come down to Georgia Tech
and take some of the work that we've done in the academic medical centers and
bring it to a technology-oriented institution like Georgia Tech.
Sure, so OHDSI is originally, let me start over there,
so OHDSI actually originally formed as something called OMOP back in 2008.
And that stands for the observational medical outcomes partnership.
OMOP itself was funded by the foundations
of the NIH which was kind of a collective of life sciences,
pharmaceutical companies that came together to say,
how can we understand observational health data
better and look at the research methods, in part,
to get ahead of what was called Mini-sentinel then Sentinel that was part of
an FDA initiative to use observational data to track drug safety.
The OMOP program was very successful in putting together a model of
clinical data, and it grew over a period of five years to
look at pharmacovigilance or drug safety in some very novel ways.
But at the end of the five year funding period,
the lead scientists said, we want to keep going and we want to answer
questions related to comparative effectiveness, related to data quality,
related to value-based care and other areas in healthcare research.
And so they banded together and converted OMOP into something called OHDSI,
which now has expanded to, as you mentioned,
a much larger set with data in the OMOP common data model on over 660 million patients.
There's participants in OHDSI from over 20 countries, So it's become quite large.
So converting data from a source system whatever it may be,
whether it's a Medicare claims document,
whether it's from an electronic medical records system into the OMOP common data model,
which is the standard, is a process we call ETL: Extract, Transform and Load.
And that's certainly used in other areas in addition to health care.
The reason it can be challenging is you have to really understand your data.
You have to understand the source data and
where different types of information are maintained.
You also have to understand the target common data model,
document and the format of how that works.
The most important thing around doing ETL or a transform
into the OMOP CDM is to have people understand the local data environment.
How it gets in there and, basically,
going through the process of mapping up codes can take some time.
The investment, though, is very worthwhile because once you've done it,
there's a lot of off the shelf capabilities that working at OMOP and OHDSI
brings you that are derived from the work of
people literally across the world using that same data model.
One of the other great things about
OMOP as a common data model in the OHDSI network is that
a researcher in California at Stanford can write code that will run on data in Japan,
in Australia, in the UK,
all with a common code base.
So it allows people to ask a question in
their local home environment and actually get results coming in from all over the world.
I think there's very few other ways that you can do something on
that scale globally than with OHDSI and OMOP.
I would agree with that.
I think there are so many nuances that have been, in fact,
proven out in many of the OHDSI research studies where we
look at the same question in different environments,
inpatient and outpatient environments,
EMR-based environments, claims-based data environments and,
indeed, there is a huge amount of
variation that's based on local factors that need to be brought into account.
And it's not that you want to hide those but you want to understand,
you want to recognize and you want to account for them where you can.
So I would agree very much.
A federated model allows that individual local nuance to be brought
to it and it's probably the most effective way to go about doing observational research.
Sure. We've just completed one study looking at a question that the FDA put
out on their website late last year
where they were looking at the question of the safety of a particular medication.
But it's a very rare adverse event they were curious about,
which something called angioedema.
You don't see it very much so if you want to study the risk of angioedema,
you're going to need millions and millions of patients to get at that question.
So with OHDSI, with a network that large,
you can actually ask a question of that across tens of millions,
even hundreds of millions of patients and be
able to generate information which, in this case,
we did and it'll be coming out in a journal currently in
press that did not show effect of that medication and the risk of angioedema.
Another great example of where we would use OHDSI in a research study is for looking at,
for example, the patterns of treatment across hundreds of millions of patients.
How are people being treated for hypertension?
How are people being treated for diabetes?
It may seem very intuitive that there's recommendations out for
the best process or pathway for treating hypertension.
But when you look at what's happening out in the real world it's very different.
So using the OHDSI framework allows you to look at these very large questions.
On a smaller scale, doing predictive models for individual patients,
the best way to generate an accurate predictive model for an individual patient is
to start with tens of millions of patients to begin with and hone in on.
So, generating predictive models around questions of safety,
questions of optimal treatment is another major use case OHDISI.
The federal high tech program supported the development of state HIEs.
As a result of that,
of growing EHR adoption,
and of the data sharing requirements of meaningful use,
the Robert Wood Johnson Foundation reported that as of 2014,
including ambulatory health professionals and other hospitals.
This was up from 62 percent in 2013 and 41 percent 2008.
The shared data might include laboratory results,
radiology reports, clinical care summaries, or medications.
Despite this growth HIEs reported many barriers.
Only 46 percent of our operational HIEs and 38 percent of HIE efforts
in the planning stage reported that they were able to
cover our operating costs with revenue from participants.
This has long been an ongoing issue with HIEs.
So we will now consider how technology might make them more
sustainable or possibly unnecessary in the future.
With the dramatic growth in open APIs, fire adoption,
and the concept of health care app platforms,
it is tempting to speculate about the future of health information exchange.
Will specialized networks for health data sharing even be needed?
In an open standards based inter-operable Health Informatics landscape.
Many have felt for some time now that cloud based platforms,
or coordinated collaborative care,
would wrap the complex mix of underlying EHRs and
other systems into something far more useful and usable.
And some are coming from large companies with the expertise and
resources to take on hard long term problems.
Here you see a screenshot,
from the salesforce.com health cloud,
that the company announced in late 2015.
It represents a patients X terminal or
professional health care team on the right and allows them to interact with each other,
with the patient, and with the patient's internal team on the layout.
This internal team might, as shown here,
consist of family members or even professionals the patient has chosen to consult.
Earlier, I mentioned that the Veterans Administration was
a pioneer in EHR development. The V.A.
is developing a cloud based digital health platform or
DHP to create inter-operability between its Vista EHR,
the military health system,
and community based care resources that use a variety of EHRs.
Georgia Tech created a proof of concept,
showing how fire could connect the V.A.
with community based providers outside its system.
The DHP could also provide health care data analytics,
ideally in real time,
and an API for data extraction potentially creating an app platform.
At least in its pilot form,
it uses a sales force health cloud for care coordination and patient management.
Here you see a diagram of
a possible HIE architecture in a fire enabled informatics ecosystem.
The HIE concept is still present,
but it has essentially become a platform for fire apps.
This second graphic suggests an HIE architecture that is entirely API based.
These are all interesting and exciting new models for HIE.
It is possible that one of them will become the new standard.
It's equally possible that all three may find a role.
But no matter what happens,
health care seems to be heading rapidly toward
an inter-operable framework with the potential,
among other use cases,
to address the long standing need for
continuous coordinated care of the chronic diseases we discussed in lesson one.
Data and interoperability standards are
the virtually ubiquitous plumbing that underlie
most contemporary health informatics systems and tools.
Given the complexity of healthcare,
it should not be surprising that this is a complicated topic.
So we will divide it into three sections.
In this section, we will first discuss the evolution of
standards and then we will focus on standards for representing health data.
In the next session,
we will discuss how that data is packaged,
transported and shared using interoperability standards developed before fire.
In the third section,
we will cover fire in some detail.
Along the way, I will ask you to use some external web tools and APIs
to explore and better understand these important data standards.
While they may be old,
they're used widely including in the latest fire standard.
Why do we need data standards?
We discuss that as a part of examining semantic interoperability,
but it's useful to consider it more specifically here.
This simple illustration helps to make the differences and ambiguities in representing
healthcare data clear using a seemingly obvious data element, the patient's gender.
Here, system A represents males with a one and females with a zero.
Over here in system B, that is reversed.
The two systems are using the same language of ones and zeros,
so they are semantically similar,
but they cannot inter-operate without some intermediate translation process
that maps one to the other or both to some common representation.
Should you mix data from these two systems without such an intervening curation process,
gender might be impossible determine
accurately for care delivery reporting and other purposes.
Over in system C,
M is used for male and F for female.
System C is semantically different from systems A and B.
It uses a different language to represent gender.
Moreover, system C recognizes that gender may be ambiguous and represents that with a U,
a concept the other two systems do not deal with.
Interoperability between system C and
the other two systems would require a translation from
its language to theirs or a translation of
all of these approaches to a common form, a standard.
Since undetermined gender is not represented in systems A and B,
some accommodation for that would also have to be made,
particularly if the rate of undetermined gender is of interest for research or reporting.
If something is seemingly simple as gender can lead to this much complexity,
imagine what happens with the concept of a patient's diagnosis,
which is inherently somewhat subjective,
can have thousands of possible values and,
as we'll see, can be described at varying levels of detail.
We've got a sense of that in the Applicadia video in the last lesson.
That is why data standards have been developed.
But as we will also soon see,
they can themselves get quite complex and can be problematic as a result.
Standards evolved over many years to encompass more aspects of medicine,
to code them in more detail,
and to adapt as technology changed.
We will divide this evolution into three dimensions.
Structure, purpose, and technology.
We will discuss the first two in this segment,
and technology evolution in the next one.
The structure of standards has evolved in
large part to take advantage of the capabilities of computing.
Early data standards were lists such as medical diagnoses,
laboratory tests, or medications.
We will refer to those list standards as classifications.
As the use of computers and health care grew,
so did interest in the standards community to describe
more detail and to represent relationships among clinical concepts.
We will refer to a standard that can code for relationships as an ontology.
The goal here is often semantic interoperability,
as we saw in Lesson two.
You may remember this graph of clinical relationships from the Applicadia video,
and their nuanced multi-layered representation of
clinical details, concepts, and relationships.
Note here that Applicadia is using both ICD-10 and SNOMED to represent concepts.
These are both ontologies that are able to represent
concepts relationships which is at the core of what Applicadia is trying to do.
The purpose of standards has also evolved.
Pre-computing, all of the early standards were for data.
Physicians would use the International Classification of Disease,
ICD, in their charting, primarily for billing.
The clinical laboratory would use a classification with the acronym,
LOIC, for their tests.
And the pharmacy would use one of
several relatively simple classifications to represent the medications they dispensed.
In the 1980s, computers were increasingly installed by hospitals.
The focus was largely on the revenue producing departments such as billing,
laboratory, pharmacy, and radiology.
They and the nurses stations where orders originate,
and to wish results are sent,
needed to share information.
Often, each of these departments was using a specialized,
independently developed, not interoperable proprietary software module.
This led to the formation of HL7 and the development of its messaging standards.
Using this technology, a physician could
order a lab test or medication at the nurses' station.
And as shown here,
that order could go electronically to the clinical laboratory to do the test,
or to the pharmacy to deliver the medication.
In the case of a test,
the results could come back to the nurses' station
using a different message from the same standard.
The next evolution was standards for clinical documents.
A message would typically be an order for a single lab tests or medication.
However, the physician who would care for a patient after hospital discharge,
requires a complete summary of that patient's care.
This is the role of document standards.
You worked with one of them,
the HL7 CCD, in the health fault exercise.
As is often the case with standards,
more than one was developed by different organizations, as shown here.
Today, they've been reconciled into
the Consolidated Clinical Document Architecture, or CCDA.
However, you may still run into a CCR,
CDA, or C32 formatted clinical document.
More recently, as computers have become even more powerful,
standards have been evolving to represent clinical processes and workflows.
We will not cover these standards in any detail,
but IHE is an initiative by healthcare professionals and
industry to improve the way computer systems and healthcare share information.
Here's an example from IHE of schedule workflow,
SWF, that integrates the ordering,
scheduling, imaging acquisition, storage,
and viewing activities associated with radiology exams.
Analysis of this workflow leads to identification of
the actors and transactions needed to accomplish the task.
Properly implemented, these standards could provide benefits including
greater efficiency and a reduction in errors
caused by unnecessary variations in patient care.
Implementation does involve many areas of the hospital and many systems,
so it requires a concerted effort.
Nevertheless, given the cost of modern imaging equipment,
this is a good use case.
The IHE radiology group says that hundreds of
commercial radiology-related information systems have incorporated its solutions.
The final dimension of standard's evolution is technology.
Early messaging standards used EDI/X12,
itself a standard that had evolved in other industries to automate business processes,
such as ordering, invoicing, and payment.
EDI/X12 dates from the early days of computing,
when memory and storage were dear.
So, as you saw earlier,
it is quite cryptic and compact.
With some effort, you could tell that the message
involved a clinical lab doing an HIV test.
The results were in red,
but most of the other details would not be obvious without a guide.
Here's an example of one.
You may recall that in the discussion of HIPAA,
you learn that a primary reason for the law was to move
the industry to electronic financial and administrative transactions.
A key example of that is the ANSI 837 electronic claim,
that is also in the EDI/X12 format used by HL-7 messages.
This is a small part of a guide to the 837 format.
Newer messaging and document standards use XML,
a more modern syntax that is verbose,
but has the advantages that it is more human readable,
and can be rendered in a browser.
You saw that in the HealthVault exercise.
Here's a lab test in the newer HL7 V.3 XML format.
While it is still not particularly readable,
we can more easily tell that it is a blood glucose level after 12 hours of fasting,
and its value of 182 is high as indicated by the age.
We can also see that the normal range for this test is 70 to 105.
The five key data standards we will now discuss are
international classification of diseases, or ICD-10,
current procedural terminology (CPT ),
logical observation identifiers names and codes(LOINC),
national drug code (NDC),
and systematized nomenclature for medicine (SNOMED).
ICD and CPT are widely used in the US because in most cases,
they are required for medical billing.
CPT and NDC are US-specific.
There are classifications although CPT increasingly has
sub-codes to provide more details about a procedure for more precise billing.
LOINC is not quite an ontology,
or provides significant details about clinical tests,
and is in use internationally.
ICD-10 and SNOMED are internationally used ontologies
capable of representing clinical relationships among their elements.
When we discuss fire later on,
you will see that it builds on these data standards
and fire resources specifically reference them.
ICD is the oldest data standard dating directly back to the 1800s and
more indirectly to earlier centuries when researchers
became interested in the causes of human mortality.
One of these was John Gaunt,
who in the mid 1600s,
probably some of the first research on the causes of human mortality.
The history of ICD is quite interesting,
so I posted a link you can read if you desire.
Traditionally, ICD was a list or classification of medical diagnoses,
maintained by the World Health Organization,
WHO, and updated every 10 years.
ICD-10, adopted in 1994,
is the current version,
and work is well underway on ICD-11 for its schedule release in 2018.
The US finally adopted ICD-10 on October 1, 2015.
Well, after most other countries.
The switch was a substantial effort,
because ICD-10 is a major quantitative and qualitative expansion
of ICD-9 as you can see here.
ICD-10 has more than five times as many codes
to represent very specific clinical details.
Note that it can provide laterality,
so in this example for breast cancer,
it can indicate in which lower outer quadrant the disease was located.
In fact, ICD-10 is an ontology,
capable of representing clinical relationships.
For example, as shown here,
we can encode the fact that the patient has gout affecting their left shoulder,
but they have not yet developed a uric acid deposit,
called a tophus, in that shoulder.
ICD -10 codes are required on health care claims.
Potential uses of the added detail in
ICD-10 could include more appropriate provider reimbursement,
and preventing fraud caused by duplicate billing for the same service.
However, as the Applicadia video demonstrates,
the complexity of the coding system is itself a problem for both providers and payers.
You will find ICD-10 codes in FHIR resources.
Current Procedural Terminology or CPT is a classification of
medical procedures maintained and updated annually by the American Medical Association.
Like ICD, it is required for virtually all reimbursement.
CPT code is divided into three categories.
Category 1 codes are five digit numbers for
widely performed procedures and are divided into sections for anaesthesiology,
surgery, radiology, pathology in clinical medicine, and medicine.
Category 2 codes are for the collection of quality and performance metrics,
and are four digits followed by an F.
Category 3 codes are also four digits followed by an I,
and are temporary to allow for new or experimental procedures.
Each code has a full, medium,
and short description as you can see here,
by the various levels of detail for naming a flu vaccination for different purposes.
Given its use in billing,
a CPT code may provide details necessary to determine the proper charge.
Here, codes for a psychotherapy visit indicate
the length of the visit and the amount a provider patient interaction.
That charge would be more or less depending on the code used.
Here are the factors that determine the code,
and hence the charge for an initial patient office visit.
Clearly, there is some subjectivity to the selection of the code.
CPT codes may appear to be simple,
but given their critical role in billing and subtleties such as we have discussed,
selection of the right code is important,
and billing personnel require training to code correctly.
The goal typically is to submit the largest,
but, hopefully, legitimate bill.
Earlier in our discussion of health information exchange,
we mentioned the Regenstrief Institute in Indiana.
The Institute also developed and it maintains
the LOINC code system for laboratory tests and clinical observations.
You will find references to LOINC in a number of fire resources.
Each code is a number with up to seven digits.
While the codes themselves are deceptively simple,
their names contain important details in their five or six components, as shown here.
These components or parts are separated by colons.
In this example, the first part,
the component or analyte,
a substance of interest is,
alpha-1 globulin, a protein that is a marker for inflammation.
We can see here in the optional six part that electrophoresis determine it's level.
Here in the fourth or specimen part,
we see that the test was performed on a blood serum or plasma sample.
Test results with a unit of measure of mass in the numerator,
and a volume like milligrams per decaliter in the denominator have mass concentration,
MCnc, as you see here in the fifth part.
Finally, Pt in the third part indicates that the measurement represents a point in time.
The national drug code is a U.S. specific standard for
medications maintained by the U.S. Food and Drug Administration or FDA.
As shown here, it consists of a simple 10 digit, 3 segment number.
The first segment indicates that
the manufacturer labeler or vendor is Pfizer consumer products.
The second indicates that the product is Advil.
The third part indicates that the packaging is 24 tablets in a bottle.
Pharmacy was an early target for health information technology.
In fact, I worked on one of
the first ambulatory pharmacy systems in the early to mid 1970s.
As a result, codes for medications were also an early development.
As the use of commercial pharmacy software grew,
companies created proprietary coding systems for the many aspects of medication
including clinical issues such as
drug drug interactions not covered by the simple NDC product codes.
Starting in 2001, the National Library of Medicine
created RxNorm to reconcile these commercial codes.
Each medication has a unique RxNorm RXCUI number
of up to eight digits that can be used to retrieve a great deal of information.
You will find references to RxNorm in fire resources.
The development of the Systematized Nomenclature of Medicine, or SNOMED,
traces its roots to a project began in the 1960s
by Dr. Arnold Pratt at the National Institutes of Health,
or NIH, to use natural language processing to
machine code pathologist free-text dictated notes.
Thus, from the outset,
it was an ontology representing relationships among its concepts.
Today, it extends to all of medicine and is maintained by
the International Health Terminology Standards Development Organization (IHTSDO).
SNOMED is huge and complex.
The most recent US version of it,
SNOMED CT subset for clinical medicine,
still has over 311,000 concepts with over 1.3 million relationships among them.
Given its scope, you may find references to SNOMED CT in many types of FHIR resources.
In this course, we'll focus only on SNOMED CT. Concepts are
the basic component of SNOMED CT and have
a unique nine-digit SNOMED CT identifier or SCTID.
Each SNOMED CT concept also has a unique human-readable Fully Specified Name or FSN.
Here, I have used
the official IHTSDO SNOMED CT browser to search for the term hypertension.
I got 705 matches and selected one of
several that has a Fully Specified Name of hypertensive disorder,
systemic arterial, which I'll just call hypertension in what follows.
Its SCTID is 38341003.
Here, you see the 14 synonyms for hypertension.
This list could be quite useful in processing text notes or problems from
a structured list and might contain one or more of these alternative terms.
You can also see the hierarchical nature of SNOMED CT.
Hypertension is a child of disorders of cardiovascular system that is
a child of disorder of body system and so on all the way to the top of the hierarchy.
Any intermediate level of this hierarchy could
be useful in grouping patients for analysis.
Hypertension, in turn, has 23 sub-disorders called children.
These can also be useful for grouping patients for analysis.
The browser also provides a diagrammatic hierarchical view.
A careful look at this shows how SNOMED explicitly
reveals important computable clinical relationships.
Absent this, how might a computer know that
hypertension is associated with an increased blood pressure?
Here's a second, more interesting,
example for prolapse of the mitral valve due to rheumatic disease.
A physician would know that
the root cause was a streptococcal infection that triggered the body
to attack the heart valve because of the similarity of some of
its surface proteins to those of the bacteria.
How would a computer know this?
SNOMED makes it explicit.
Finally, the references view provides a great deal of
potentially useful information in the form of
relationships between the current concept and others.
You can see that they are in five groups,
we will discuss only the first two but I would suggest you explore the others.
Associated findings are clinical findings that might
occur with hypertension such as a family history of the disease.
Associated with, are clinical findings that hypertension patients may have.
I've expanded that view here to show, for example,
that they might have one or more of a number of kidney diseases
that can cause or be caused by high hypertension.
Again, this is potentially very useful information for analysis of clinical data.
SNOMED is quite a bit more complex than I've presented here in this brief overview.
Nevertheless, I hope I've been able to convince you that it can be a very valuable tool.
You now have an overview of how standards have evolved over
the years in terms of their structure, purpose and technology.
You should think about the difference between simpler classifications such as NDC,
CPT and ICD prior to version 10 and a complex ontology such as SNOMAD.
The standards community has struggled over the tension between perfection,
a standard that can represent medicine all of its detail and practicality,
standards that can actually be deployed and used in the real world.
This dichotomy extends equally to the topic of our next lesson,
interoperability standards, and it eventually lead to fire,
the subject of the following lesson.
In the last lesson,
we looked at the evolution of standards and examined data standards in particular.
For use in an actual patient care,
standardized clinical data typically along
with other non-standardized data such as free text nodes,
must be packaged into a useful and usable form and
set using widely accepted data sharing standards and approaches.
Many people feel that these standards and approaches will increasingly be FHIR APIs,
but only a few EHR installations currently support FHIR.
We will look at FHIR in the next lesson.
In this one, we will look at the standards for
packaging and sharing data that predated FHIR.
In what follows, I will give you an overview of many of the key components of HL7 with
a particular emphasis on those that support data
sharing for care coordination and patient engagement.
First, you should understand that over the years,
HL7's mission has expanded greatly from messaging and from
the basic but pragmatic approach taken in v2 message standards development.
The results of these newer efforts are controversial and some would now argue that
HL7's later standards were overly
complex and too difficult and expensive to implement in practice.
In the last lesson,
what I provided was actually a simplistic comparison between HL7 v2 and v3 messages.
We will now look at that in more detail to help us understand
the evolution of HL7 standards development.
HL7 v2 is not plug and play.
In fact, the concept was just getting started back then.
In the hardware world, it certainly was not very common.
V2 provides 80% of the interface and
a framework to negotiate the remaining 20% on a case-by-case basis.
Thus, developing a v2 interface between
any two systems requires coding and has a certain degree of customization.
Part of the reason why is that v2 is not based on a standard model.
The key goal of HL7 v3 development was to get as close to plug and play as possible.
It uses the Reference Information Model,
or RIM, in an effort to provide consistency across the standard.
The goal of the HL7 Reference Information Model,
or RIM, is to document the actions taken to treat a patient.
A request or order for a test is an action.
The reporting of the test result is an action.
Creating a diagnosis based on test results is an action.
Prescribing treatments based on a diagnosis is an action.
RIM defines the semantics of a common set of
administrative financial and clinical concepts
in order to describe these actions and foster interoperability.
Here you see a diagrammatic representation of
all the RIM concepts or classes and their relationships.
I provide a link to a webpage from which you can explore them all.
The four shown here are core or backbone classes.
Every happening is an act that is either being done,
has been done, can be done,
or has been requested or ordered.
Examples include clinical observations,
medication administration, medical procedures or patient encounters.
Act relationships represent connections between acts such as composition,
preconditions, revisions and support.
Participation defines the context for an act such as author,
performer, subject or location.
The participants have roles such as patient,
provider, practitioner, specimen or health care facility.
Entities such as persons, organizations, material,
places or devices play these role.
How can a single act class represent all of the elements of a clinical action?
Their definition, requesting or ordering them,
or reporting the result.
This is the role of the Act.moodCode that
specifies whether the act is an activity that is defined,
is an event, has been requested or ordered,
or is promised, or is the subject of a future appointment.
Here's an example of a patient registration message in both V2 and V3 formats.
You will not find anything related to RIM up here in the V2 message.
Down here in the V3 version,
you see processingModeCode Code=T.
Over on the FHIR website,
you can easily find this table that explains
the possible values of this code, its value set.
And T indicates current processing.
So that is the status of this patient's registration.
The state of processing of an administrative task is
but one example of the great level of detail in RIM.
To get a further feel for this,
let's focus on the special arrangement code for this patient encounter.
We see here that this is a leaf of the act,
meaning it is a particular example or instance.
Its value is DSET, D-S-E-T.
It indicates there is a discrete set of possible values.
Again, a value set for this field.
Once again, as you see here,
the FHIR site is a great way to discover these values.
These codes for special things a patient might need at arrival for
an encounter and the possible values are wheel for wheelchair,
add-bed for additional bedding,
int for interpreter, att for attendant and dog for guide dog.
You might be wondering where I found the value sets for
RIM codes over on the FHIR website.
Earlier, I said that FHIR builds on existing standards.
And that is true for RIM as well but with exceptions.
Scope. It should be clear by now that the goal
of RIM is comprehensive representation of the health care domain.
FHIR resources represent only those data elements
that are expected to be used by most implementations.
FHIR uses an 80% rule.
If approximately 80% of systems using resource will support a particular data element,
then it is part of the core standard.
A specific subdomain can add other elements as needed using FHIR extensions.
FHIR profiles both constrain resources for
use case and define extensions appropriate to specific subdomains.
Source of data elements.
All data elements in HL7 v3 instances come from either the RIM or
data types developed by the International Organization for Standardization or ISO, I-S-O.
In FHIR, this is true of most but not all resources and data type elements.
Some FHIR resources deal with content that is outside of the RIM scope.
And in a few instances,
FHIR adjust data types to accommodate issues not yet supported in RIM.
Nuance. As you've seen,
RIM attempts to convey the meaning of instances through attributes like the mood code.
FHIR codes are generally limited to attributes with a rather concrete business meaning.
Finally, in FHIR, a value set is just another type of
resource that can be sent as part of an instance just like any other piece of data.
As a result, although FHIR uses RIM data elements,
it's possible to implement FHIR with absolutely no knowledge of the HL7 RIM.
This greatly facilitates rapid development.
The Clinical Document Architecture or CDA define HL7 V3
RIM-based documents assembled from
administrative and clinical data for particular purposes.
You saw one of these when you did the HealthVault CCD activity.
You should also recall that a consolidation effort produced
the newer CCDA or Consolidated Clinical Document Architecture standard.
Here's the first part of the CDA you used in the HealthVault activity.
I have highlighted instances where it refers to the RIM.
I leave it to you to consider the tradeoffs between value,
complexity and ease of implementation that this reliance on RIM brings with it.
CCDA documents are assembled from templates,
essentially reusable XML components.
Templates are defined at the document,
section, or data entry level.
These correspond conceptually to
a paper form where the document as a whole consists of sections,
each of which consists of fields into which data is recorded.
Here is the CCD we just looked at,
but I have now also highlighted two references to templates.
There are CCDA template guides posted and I've provided a reference to one from HL7.
Templates have an OID,
a globally unique ISO identifier.
As you can see, the first has
an OID of 2.16.840.1.113883.10.20.22.1.1.
The second differs from the first only in the last digit.
Both of these are document-level templates.
The first defines a document header for use in the U.S. domain.
This serves a purpose quite similar to FHIR profiles
in that it constrains the document to U.S. specifications.
Here you can see that it specifies that there must be
exactly one realmCode and its value must be U.S..
It is more interesting to look at the second template.
This specifies constraints for a continuity of care document or
CCD in conformance with stage one meaningful use.
Here, you see that it specifies the sections that must be contained in
the CCD so that it adequately supports use cases such as transitions of care.
Each of these refers to a section template and
the HL7 site provides links to these more granular templates.
If you first click on the link to the medication section template,
and from it click on the medication activity link,
you get to this data entry level template.
Note that it in turn links to specific value sets such as the medication route.
Clicking on that link brings up a page listing all the routes
specified by the U.S. Food and Drug Administration.
It also links to specialized data entry templates.
This one is the medication information entry level template
that could even contain a pre-specified product strength,
form or concentration such as Amoxicillin 400mg/5mL suspension.
Clicking on its medication clinical generic drug link
shows that the specification must be made using RxNorm.
Clinical Decision Support or CDS is
an early and particularly interesting domain within Health Informatics.
Its purpose is to provide clinicians, patients,
and others with knowledge and personalize information,
intelligently filtered or presented at
appropriate times to enhance health and health care.
According to ONC, "CDS tools include
computerized alerts and reminders to care providers and patients, clinical guidelines,
condition-specific order sets, focused patient data reports and summaries,
documentation templates, diagnostic support,
and contextually relevant reference information, among other tools."
We will discuss three key clinical decision support projects to illustrate
how early researchers recognized it as
an opportunity and the challenges to successfully implementing it in practice.
My purpose in placing this discussion here is to set the stage for appreciating how
two key capabilities of FHIR and SMART on FHIR are making clinical decision support,
a far more approachable and clinically-useful tool.
The first is facile retrieval of EHR data in a standard format,
facilitating the integration of FHIR apps into any EHR.
This also obviates the need for any redundant data entry by the provider.
The second is seamless integration into the provider's workflow,
making the use of clinical decision support far more efficient and therefore more likely.
Finally, this discussion will expose you to some of what I consider the most fascinating
parts of the history of Health Informatics and the vision of some of its pioneers.
Beginning in the mid 1950s,
Dr. Homer Warner, one of the founders of Health Informatics,
began using computers for decision support in
cardiology at LDS hospital in Salt Lake City, now Intermountain Healthcare.
In the 1970s, Dr. Warner and his colleagues
created the Health Evolution through Logic Processing,
or HELP system, one of
the first electronic medical records systems and
perhaps the first designed to assist clinicians in decision making.
Intermountain replaced HELP II,
the successor to HELP,
with the Center system in 2015.
Dr. Warner died in 2012 and Intermountain named its research center after him.
The American Medical Informatics Association, or AMIA,
awards a cash prize in Dr. Warner's honor each year at its annual symposium.
You can see here that
the HELP system's knowledge based decision processor received data from
virtually all areas of the hospital to
provide a variety of clinical decision support tools.
Expert panels organized much of
the clinical knowledge and an early example of knowledge engineering.
In fact, in 1997,
Dr. Warner published the book,
Knowledge Engineering and Health Informatics.
Here in a diagram from that book,
you can see how clinical findings link to a diagnosis.
Note that this includes logical rules stating that if
findings A or B and any of the two other four findings are present,
the diagnosis is confirmed.
Here you see that HELP uses bayesian statistics to relate findings to diagnoses.
Note here in this system diagram we saw earlier,
that HELP included a longitudinal clinical data repository.
I doubt that many in the field today
realize that such a system was functional that long ago.
Yet, another early example of clinical decisions support was Internists,
developed starting in 1974 at the University of Pittsburgh by Dr. Jack Myers,
an internal medicine physician,
and Dr. Harry E. Pople,
a computer scientist and pioneer in artificial intelligence.
Health Informatics is often the first place the new computer science technique appears,
but according to Volume 64 of the Encyclopedia of Library and Information Science,
"Applying abduction to artificial intelligence problems began with
Harry Pople and his system, internist."
In 1985, book, Logic of Discovery and Diagnosis in Medicine,
describes the program as,
"an AI partial simulation of Dr. Myers
clinical reasoning using his own internal knowledge base".
The goal of internists was to make
the appropriate diagnosis in a given clinical situation.
In that same book,
Dr. Pople describes the methods used and I will summarize his chapter here.
He explains why a Belgian approach or a branching logic,
essentially a network approach that starts with a presenting complaint, as shown here,
is inadequate to deal with the real world of clinical diagnoses where
new or conflicting data may arrive too late to assist with an interim decision,
and it may even arrive in random order.
Internist contained a knowledge-base consisting of some 500 disease entities,
organized into categories by disease system,
and there are over 3000 clinical manifestations.
This diagram of liver diseases and their related conditions and
manifestations illustrates these relationships,
and is from a chapter by Dr. Pople in the 1982 book,
Artificial Intelligence in Medicine.
You can see that each disease entity has a corresponding list of manifestations,
weighted on a scale of one to five,
based on the frequency of their occurrence in that disease.
Inversely, a scale of zero to five reflected
the strength of the association of manifestations to diseases.
Finally, there was a representation of causal,
temporal, and other relationships among entities.
This structure is in many ways,
suggestive of a SNOMED whose predecessor, SNOP,
was by then an operation at NIH but I don't know if the Internist team was aware of that.
Internists ranked disease entities that explain any or all of a patients findings,
reflecting their goodness of fit to the data.
It then formulated questions for the physician,
as shown here, to discriminate among the equally-ranked entities.
In this example, the computer is considering the diagnosis of
acute Disseminated Intravascular Coagulopathy or DIC,
a dangerous, potentially life-threatening
condition in which blood clots form in the small blood vessels.
Much like an attending physician might do on rounds with physicians in training,
it is asking for the results of
the pertinent laboratory tests to confirm or rule out the diagnosis.
Once a diagnosis was considered identified,
it was added to the patient's problem list.
Its manifestations were considered accounted for,
and the process repeated.
While Internists worked, in complex cases,
they are often considered inappropriate possibilities and
wasted clinician's time answering questions with respect to that.
To overcome this, Internist-II used the heuristic that recognize that
certain manifestations are distinctly
characteristic of a disease or category of diseases.
Jaundice, which is prominent in this diagram we just saw,
is highly suggestive of
liver disease so the initial focus in a patient with this symptom,
should be on this disease category as it
would be if a physician were making the diagnosis.
Internist-II also introduced a multi problem generator.
Essentially, a search process beginning globally with health problems as shown here.
It terminated when at least one problem hypothesis accounted for all clinical findings.
However, that hypothesis might or might not specify specific diseases.
If there were sufficient cues in the data,
further hypothesis reduction could reduce the possibilities to specific problems.
Finally, if further reduced the problem list by exploiting its database of causal,
temporal, and other relationships,
yet another process, analogous to what actual physicians do.
The goal of the Arden Syntax

is to provide a standard approach to
describing medical logic so that it can

be shared across EMRs to support
Clinical Decision Support or CDS.

CDS is the idea that computers
can suggest optimal therapy

based on a patient's electronic record.

Or spot potential mistakes
before they happen.

To do either, they not only
need the electronic record,

they need to understand at least
a limited domain of medicine.

That's where Arden comes in.

Arden consists of medical logic modules,

or MLMs,
each supports one clinical decision.

Here's a group of five MLMs used to
provide clinical decision support for

the use of Warfarin, a common but
potentially dangerous blood thinner

often given to patients with strokes or
other potential blood clotting problems.

Too little of the drug
may mean another stroke.

Too much can cause excessive,
or even fatal, bleeding.

Warfarin levels can be effected by many
other drugs and even the patient's diet.

So it's a very tricky drug to manage.

A clinical test called PT/INR is used
to assess the degree of blood thinning.

You can see here that the modules,

once they are fed clinical data about
the patient, such as their PT/INR,

can make Warfarin dosage
recommendations to the physician.

I refer you to the text for
the internal details of the Ardent MLMs.
The basic Arden unit is Medical Logic Modules,
MLMs, each of which contains sufficient knowledge to make a single clinical decision.
As illustrated here, MLMs used the Backus-Naur form, BNF,
a notation for context-free grammars,
otherwise used to describe the syntax of computer programming languages,
document formats, instruction sets, and communication protocols.
Each MLM can have four categories of information.
Maintenance, Library, Knowledge, and Resources.
This example from Dr. Ribshek illustrates two of these,
and I've highlighted them in yellow for you.
Here in the library category,
you see that the purpose of this MLM is to check
each new penicillin prescription for a penicillin allergy.
Here in the knowledge category,
you see that the triggering event is that
the newly prescribed medication belongs to the penicillin class.
Of course, the way to determine that might well be EHR-specific.
Here you see the logic to evaluate the decision,
and here, the action to take if its value is true.
There is now an Arden XML schema and this diagram of it details all four categories.
In addition to the two categories we saw earlier,
each MLM also contains management information to help maintain
the knowledge base of MLMs and links to other knowledge resources.
Health personnel can create MLMs and implement them in
any EHR or clinical information system that conforms to the Arden specification.
Keep in mind that each MLM can drive one decision,
so in practice, a group of MLMs may be required.
Here, five MLMs help provide clinical decision support for the use of warfarin,
a common but potentially dangerous blood thinner often
given to patients after thrombotic strokes caused by clots,
or to treat other potential blood clotting problems.
Too little of the drug may mean another stroke,
too much can cause excessive and even fatal bleeding.
Warfarin interacts with many other drugs and even the patient's diet,
so it is a tricky drug to manage.
Physicians use a test called PT/INR to assess the degree
of blood thinning to manage the warfarin dose in each patient.
You can see here that the modules,
using clinical data about the patient including their PT/INR,
can make warfarin dosage recommendations.
This part of the MLM specifically deals with a lab test,
the creatinine level, that measures kidney function.
It is important to know the patient's kidney function
before giving the dye because the kidneys remove the dye,
and it can cause kidney damage.
As a result, Arden needs to know the creatinine level.
And to get it, dam = PDQRES2 in curly braces, highlighted here,
must be interpreted by the EHR in
a particular hospital to fetch that value from its proprietary database.
The purpose of Arden is to share clinical decision support logic,
but because EHR have not been regularly interoperable,
the work involved in implementing Arden locally has led to low Arden adoption.
This impediment is so serious and widely known that it even has a name,
a curly braces problem.
This leads us to one of the key advantages of FHIR that I
mentioned earlier as a reason for this discussion of clinical decision support.
FHIR-enabled EHRs would present creatinine in a consistent form,
as a FHIR observation resource.
As a result, a hypothetical clinical decision support FHIR app
need have no knowledge of the EHR's internal data structure or representation.
It would not need to be adapted to each EHR,
greatly reducing development cost and facilitating implementation and hence,
the likelihood of clinical decision support adoption.
We will discuss integration with workflow and process.
The second major advantage of FHIR and SMART on FHIR
in support of clinical decision support in the next lesson.
In 2011, Australian HL7 standards guru,
Grahame Grieve, proposed a new interoperability approach
he called Resources for Healthcare or RFH.
He said that it would define a set of resources to represent
granular clinical concepts for use on their own or aggregated into complex documents.
In other words it would be composable so that unlike with complex CCDA documents,
developers could request only the information needed for their particular use case.
In part because of that he said this flexibility could
offer coherent solutions for a range of interoperability problems.
He went on to say that technically RFH is designed for the web.
The resources are based on simple XML with
an HTTP based restful protocol where each resource has a predictable URL,
where possible open internet standards are used for data representation.
Later that year the HL7 board authorized a fresh look task force to
examine the best way to create
interoperability solutions with no preconditions on what those solutions might be.
The idea was not to start all over but that based on prior attempts
by HL7 and other groups the task force would consider new approaches to interoperability.
Grahame joined the effort and at its outset hosted several key questions on his blog.
What are we trying to do?
What do our customers want?
What exchanges are we trying to serve?
Are we doing syntax or semantics?
Does the market even wants semantics?
HL7 has two quite different stakeholders in vendors and large healthcare programs.
Can they agree on what they want?
Grahame ended up leading the resulting standards development effort renamed
Fast Healthcare Interoperability Resources or F-H-I-R, FHIR.
We've touched on FHIR throughout the earlier parts of this course.
Now we will look at it in more detail.
Grahame's vision guides FHIR development.
So, before we delve into the standard,
it's important to understand his philosophy.
The FHIR Data Model consists of resources as Grahame propose for RFH.
Unlike HL7's CCDA and RIM,
resource contents are intentionally limited.
FHIR's 80% rule is the operative guideline and it informally states that
each resource should contain
only those data elements needed for 80% or more of its anticipated use cases.
Of course, as Grahame has posted,
there are other considerations such as safety and consistency.
All standards efforts must grapple with tension between comprehensiveness and usability.
In essence, this approach means that in FHIR,
usability is a top priority.
Grahame's second principle is around how to verify the standard.
Historically, a vote of standards developers approves the standard they created.
Input from software developers who have worked with proposed FHIR resources,
APIs, and other elements of the standard guides further development of FHIR.
Again, usability is a priority.
The third principle is the use of
Cross Industry Web Technologies to search for resources and to create,
read, update, and delete them, CRUD, C-R-U-D.
This makes the standard more approachable and hence,
more attractive to modern developers,
and provides the basis for FHIR base mobile and web apps that can be EHR-agnostic.
The FHIR data model is instantiated in a set of what will
probably be some 150 or more modular resources.
The current release 3 version of the standard organizes
its 117 resources and related documentation in the five levels you see here.
Level 1 is the standard's basic framework and consists of 30 resources.
Level 2 supports implementation and binding to
external specifications and contains 26 resources.
Level 3 provides structural and process elements of
real world healthcare systems and provides 37 resources.
Level 4 is for record keeping and data exchange and contains 13 resources.
Level 5 provides the ability to reason about
healthcare processes and contains 11 resources.
It is likely that the number of resources will increase,
and existing ones may change over time.
So, I provide a link to the resource index page on the FHIR site.
It summarizes the resources and their subdivisions in several useful ways.
Note the number after each resource indicates its maturity on a scale of zero to five.
These numbers will also increase over time as standards definition proceeds.
At present, the lower levels are generally more mature.
We cannot cover FHIR comprehensively in this survey course,
so I can't overemphasize the importance of studying the excellent,
well-organized FHIR website to gain a fuller understanding of the standard.
To get you started on that,
here are a few particularly interesting resources.
The definition of a resource is itself contained in the resource resource,
in the foundational framework part of the foundational level.
Earlier, I said that valuesets can be represented in a resource.
It is the valueset resource in the terminology division of the foundational level.
Later, we will discuss FHIR profiles.
The structured definition resource in
the conformance division of the second implementation level represents profiles.
The group resource in the third level specifies a particular set of patients,
providers, medications, and so on,
for purposes such as reporting or tracking.
The subscription resource in
the other division at the foundational level is used to create
a push of FHIR resources that match criteria specified in the resource.
Finally, level 5 includes support for clinical reasoning.
Earlier, we discussed clinical decision support,
and I pointed to tight EHR integration as a benefit of
FHIR to obtain provider adoption of these tools.
The new CDS Hooks specification,
developed by the same Harvard group that created SMART on FHIR,
supports the integration of clinical logic,
similar to what we saw with the Arden Syntax into EHRs in order to,
among other things, launch FHIR apps when
a patient's clinical situation suggests they might be of value.
A goal of FHIR release 4 is to unify
the CDS Hooks specification with the clinical reasoning module.
This should be another important step toward broader use of clinical decision support.
When I last asked Graham,
he estimated that the first normative version of the standard might appear in 2018.
Until then, FHIR is a Standard for Trial Use, STU.
You may see the term Draft Standard for Trial Use, or DSTU,
but STU is now HL7s preferred designation.
There are examples of most resources on the HL7 FHIR site in XML,
JSON and Turtle formats.
Any student taking this course is probably familiar with XML and JSON.
Turtle, Terse RDF Triple Language,
is a format used by the World Wide Web Consortium,
W3C, in its Resource Description Framework,
RDF data model for the proposed semantic web.
RDF extends the linking structure of the web using Uniform Resource Identifiers, URIs,
to describe relationships between things,
as well as the two ends of the link in a triple,
comprising a subject, predicate and object,
each of which can be a URI.
This informal graph from the W3C RDF primer shows
how this construct could power a semantic web
that understands entities and their relationships.
Here as is often the case,
the Mona Lisa is at the center of attention.
Here we see that Bob is a person who likes
this painting that was created by Leonardo da Vinci.
As in our earlier discussion of semantic interoperability,
it is worth considering whether there is a need for
a semantic formalism in an era when machines are increasingly figuring these things out.
I have posted links to the HL7 FHIR site's discussion of
RDF and to the W3C Semantic Web Health Care and Life Sciences Interest Group.
This simple example shows some key parts of an XML-formatted FHIR patient resource.
Local information such as its last update and its local resource ID,
an HTML presentation of the key information for human consumption,
or if the receiving system is not able to interpret the structured information,
any local extensions to the standard,
the standard-defined structured data content.
Here is an example of a JSON-formatted FHIR allergy intolerance resource.
The highlighted area contains the text for display for reasons we just discussed.
Here, I had removed that text so we can more easily focus on the structured information.
It begins by showing that this allergy problem is clinically active but is unconfirmed.
Patients often report allergies,
but that does not mean they experienced
an actual allergy as opposed to a medication side effect.
This allergy is for penicillin,
and according to the Mayo Clinic,
research has shown that penicillin allergies may be over-diagnosed,
and that patients may report a penicillin allergy that has never been confirmed.
A misdiagnosed penicillin allergy may result in the use of
less appropriate or more expensive and possibly more dangerous antibiotics.
Here, you see that this allergy is in the medication category.
Medication is one of four allowed values for an allergy intolerance category.
Here you see the entire value set,
the list of allowed values for this data element
taken from the relevant page on the HL7 FHIR site.
Food, environmental, and biologic allergies such as to
an X-ray contrast agent or a vaccination can also be documented using this resource.
Knowing that it is a medication allergy could be helpful to
software so that it knows to check on it when prescribing new medications.
Here you see a reference to an RxNorm code or RxCUI
penicillin is a group of antibiotics and this is only one part of the penicillin group.
Patients allergic to one member of the group
are usually presumed to be allergic to the entire group.
So I think the RxCUI of 70618 might have been a better choice.
I'll leave it to you to verify that and find out what
this RxCUI is for with the RxNorm tool you used earlier.
Here, you see that the allergy manifests itself as hives,
an outbreak of swollen,
pale red bumps or plaques or wheals on the skin.
This should be the SNOMED CT code for hives.
I leave it to you to verify that with the browser you used earlier.
These references to RxNorm and SNOMED CT
illustrate an important characteristic of FHIR we mentioned earlier.
It builds upon existing standards via
terminology bindings that specify these relationships.
Here, you see all the terminology bindings for this one resource.
I provide a link to a page from the FHIR site listing
all the terminology bindings used in the standard.
Here is a simple example to show how FHIR
also rests on key elements from earlier HL7 standards.
As you see here at the top,
the marital status value set comes from HL7 v3.
If you go to the detailed description tab on the patient resource page on the FHIR site,
you will find this section for marital status.
Click here on the marital status codes link and you will get to the same table.
FHIR resources have a logical identity or ID that is
unique among all resources of the same type on each FHIR server.
Just to be clear,
the patient resource ID will usually be different on each FHIR server,
so it cannot establish patient identity across servers.
However, there is a discussion of the use of FHIR for
a master patient index on the patient resource page of the FHIR website.
And there is even this value set to indicate the quality of a patient query match.
I mention this as much as anything to show you how rich the FHIR standard is
becoming and to urge you to explore it further.
Here, further down in the allergy resource we've been exploring,
you see references by ID to the patient,
"example" who has this allergy as well as to the practitioner,
"13" who recorded it.
These references can be absolute or relative.
Once assigned, the identity is never changed.
However, a copy of that resource on
another server might not be able to retain the same logical identity.
As shown here via these references,
FHIR resources create a network of information.
The unique identifier of a resource instance is
an absolute URI constructed from the server base address,
the resource type, and the logical ID.
When the literal identity is an HTTP address,
this address can generally retrieve or manipulate the resource,
as I illustrate here using the public HAPI, H-A-P-I, FHIR server.
Here are the three parts of the URL.
The server base address of fhirtest.uhn.ca,
the resource type of
baseDstu2/Patient that combines the resource type with the version of FHIR,
and the resource ID of 3535.
Finally, here you see that as it should,
the internal reference to the FHIR ID matches the one in the URL.
You should easily be able to do the same
using the Georgia Tech or any public FHIR service.
Simply search for a resource and then note
its literal URL and the three parts that make it up.
Before moving on, note the use of DSTU in the URL we just looked at.
As I said earlier,
you're likely to run into this,
even though the preferred term is now STU.
They are equivalent.
Note that implementation should not assume that
the identity of a resource is always resolvable to a literal server.
It may be temporarily unavailable or may not be available by policy,
such as firewalls or in some cases it may not actually exist,
such as the use of resources outside of a RESTful environment.
Logical ID literal references are case sensitive.
They can be up to 64 characters long and
contain any combination of upper and lower case ASCII characters,
numerals, dashes, and periods,
as illustrated by the patient ID of "example" we saw earlier.
I have posted a link to a video that demonstrates
the use of clinFHIR to create FHIR resources.
ClinFHIR is an excellent open public comprehensive FHIR resource created by David Hay,
a leader in the FHIR community.
I strongly recommend you explore it.
In a real world scenario,
health system vendors usually create Fire resources from data stored
in a proprietary database designed and built before Fire existed.
When a Fire app or a REST API ask for a resource,
special software often called a Fire adapter or server must know how to
get data elements from that database and package them into the Fire resource format.
The data that populates that Fire resource will therefore
depend on the underlying system.
If that system stores clinical observations only as text,
then even though Fire specifies them,
LOINC codes will not be available in the Fire resources that system creates.
Alternately, the design is so the Fire adapter
might make the effort to add any missing codes.
In either case, there is no assurance that
different EHRs represent or code a concept the same way.
Many major healthcare enterprise software vendors including Epic, Cerner and Meditech,
the three most widely installed,
have released at least a preliminary Fire server,
sometimes with integrated support for the Smart and Fire applet form.
We will look at the examples of this later on.
Finally, again at present,
most vendor support is for the reading of resources.
Support for the rest of CRUD is more difficult for vendors to implement
because of the need to verify the various checks and safeguards used in their systems.
This will come later if at all.
HL7 maintains a web page that summarizes the ever growing list of
health IT system vendors and
other organizations interested in Fire along with a link to their site,
contact information and a brief description of their intended use of the standard.
There are four FHIR paradigms to accommodate different workflows.
They are the FHIR REST API,
FHIR Messages, FHIR Documents,
and FHIR-based web services.
We will not cover message or document-based exchange,
but you should be aware that they exist and are potential replacements for
the earlier HL7 messaging and document standards we've discussed.
I refer you to the FHIR site for discussion of these paradigms.
The site also discusses the potential use of FHIR in
web services based on other service-oriented architectures.
The FHIR API paradigm uses representational state transfer, REST,
that relies on a client-server stateless,
cashable communications protocol, typically, using HTTP.
Here, you see a simple illustration of the FHIR HTTP format.
The endpoint or base is the address of the FHIR server.
This is followed by a resource type and its resource ID.
This example would find the patient with
a resource ID of one on this particular FHIR server.
I assume anyone taking this course knows what client-server architecture is.
As shown here, statelessness essentially means that
the necessary information to handle the request is contained within the request itself.
This might be as part of the uri,
query string parameters, body, or headers.
Thus, with no prior knowledge,
and no need to remember the transaction,
any machine in a vast server farm could handle the request,
return the appropriate response,
and be available for the next request.
The response from the server to the client is similarly self-contained.
Clients can cache responses.
Well-managed caching, partly or completely,
eliminate some client-server interactions,
further improving scalability and performance.
In FHIR, the four HTTP verbs,
host, get, put and delete, implement CRUD.
Post creates new resources,
get reads existing resources,
put and delete update or remove existing resources.
Here, you see a complete list of the currently defined logical FHIR interactions.
This part of the standard is at maturity level five,
so it's essentially in the final form.
Note the three sections,
instance, type, and whole system interactions.
In the instance section,
note that patch, a fifth HTTP verb,
can be used when a client is seeking to minimize its bandwidth utilization,
or in the scenario that a client has only partial access or support for a resource.
This might be the case in healthcare given the emphasis on privacy and security.
In the type section,
note that FHIR defines two interactions of particular interest in healthcare.
History retrieves the sequence of prior instances of either a particular FHIR resource,
all resources of given type,
or all resources supported by the system.
History can be quite useful given the clinical importance of
trends and changes in patient status.
This is a good place to explain FHIR bundles.
These are a collection of resources into
a single instance along with some context information.
For history of a patient's blood pressure,
without specifying a time period,
the server would send an observation resource bundle
containing all of the past measurements.
However, a bundle need not consist of the same resources,
so when representing some summary of a patient's record
would likely contain many different resource types and values.
Here's an example of that using the public Hapi.Server.
A search for the observations for Patient 10506 has found 12 of them.
Here is the accompanying JSON.
You can see at the top that it is a resource bundle.
Next is the context information to put what follows in the proper perspective.
The first observation is a systolic blood pressure of 130 millimeters of Mercury.
The next one is for heart rate,
a clinically different observation.
The value is off screen but should you be curious,
it's 68 beats per minute.
Also, in the type section,
search is a particularly rich and important part of the FHIR standard.
In the simplest case,
a search is executed using a get operation,
where one or more name equals value pairs,
encoded in the URL, specify the parameters.
You can explore search using the forms provided on Grahame Grieve's FHIR server.
This is part of the extensive list of
search criteria for patients supported by the server.
As you can see, I've asked for all females born in 1955.
I get this one result, Eve Everywoman.
Try this yourself, and right after the server-based URL,
you will find patient/ specifying the resource to search.
If you look carefully in the long string that follows,
you will find birthDate=1955 and gender=female,
the two operative name equals value pairs.
When you try it, keep in mind that the data on public servers can change,
so this particular example may or may not work as it does here.
Searches are constrained to one of
three contexts in order to control what resources are considered.
I'll discuss each and show you the applicable format.
A specified resource type,
as in the example we just did,
where this was patient resources.
A specified compartment, that might be a specific patient,
perhaps, with a specified resource type in that compartment.
We did that earlier when we look for observations for only Patient 10506.
All resource types where the parameters must,
of course, be common to all the resource types.
Arguably, one of the most attractive features of
FHIR for developers is its composibility.
Each FHIR resource is an independent object and can
be retrieved as needed using our appropriate FHIR API query.
This is distinctly different from earlier standards, such as CCDA,
where an entire clinical document must be
retrieved even though only a specific part of that document,
such as a patient's problem list, is of interest.
FHIRPath is a path-based navigation and extraction language, something like XPath.
XPath can be used to navigate through elements and attributes in an XML document.
FHIRPath does the same thing for FHIR.
For example, a simple FHIRPath script can navigate through and
retrieve specific sub-elements of a large FHIR bundle,
such as an entire patient record.
In other words, FHIRPath further extends
composibility to individual data types or even their values so
resources can be mined to more efficiently supported development
of specific capabilities in a FHIR app or for other purposes.
The technical details are available online,
but we can easily see how useful this could be through some examples.
To do that, we'll take advantage of David Hay's wonderful web tool, clinFHIR.
Using clinFHIR, as you can see here,
we create a new patient record based on
demographic data from the CCD of Josephine Vazquez,
a synthetic patient available to students in this course.
One of clinFHIR's many attractive features is the generation of
some sample data so that our new patient
begins with a reasonable facsimile of a medical record.
We've checked the generate samples box here to do that.
ClinFHIR indexes the resulting 72 FHIR resources by type,
as you can see here on the left.
The single patient resource has been selected and its contents are
displayed in a human-friendly tree view here on the right.
Note that the patient resource has been assigned the ID 299014.
A number that you know by now can be used to easily retrieve this resource or,
depending on the capabilities of an individual FHIR server,
just specify the other resources such as medications or
clinical observations are to be retrieved but only for this patient.
Of course, computer software would deal with this resource in XML or JSON.
It should be easy to see that the same data,
shown in the tree view on the right,
is also in the JSON on the left.
ClinFHIR's FHIRPath Expiration Tool makes it easy
to create a bundle containing our patients entire record,
as shown in the middle here.
This may be a simplistic representation of
a patient record but displayed in Microsoft Word,
this bundle occupies 96 pages and is 5401 words long.
We already know that we can use the FHIR API to retrieve a specified part of the bundle,
such as only the condition resources.
But suppose that we really only want to display the patient's medical problems,
that information is contained in those conditioned resources,
and it would certainly be passed through write some code to parse that out of them.
However, FHIRPath makes that much simpler,
as shown in the right of this graphic.
As you can see here, this script,
when run using clinFHIR's server side implementation of
the FHIRPath interpreter developed by Josh Mandel and Nikolai Russakoff,
produces exactly the text needed to display the patient's medical problems.
To give another example,
a FHIRPath's script could use the appropriate Lloyd code of
as shown just below the box where
the FHIRPath script that produced the list would be typed in.
I've intentionally obscured most of the script should you try writing it.
Capabilities such as these make app creation far easier and faster,
leading to more rapid innovation and more usable software tools.
For example, starting with this list of heart rate values,
it is a simple matter to create a graph of
Josephine's heart rate over time, as shown here.
If you think back to our discussion of VHRs,
you may remember that not all of them can do something as simple as produce this graph.
The capabilities operation in the whole system section retrieves
the server's capability statement resource
describing its current operational functionality.
As shown here, using
Graham Greeves interesting tabular presentation for human consumption,
clients connecting to a FHIR server can use the capabilities
interaction to check whether they are version and or feature compatible with the server.
Beyond this, FHIR provides a set of resources to represent and share
the adaptations made in a particular server in a computable fashion.
Adaptations might include restrictions such as
allowed values within a value set specified in the standard.
Alternatively, they might specify another value set that is more
expensive or that it is necessary in a special context.
For example, the value sets for the specification of ethnicity differ among countries.
Data elements can be required and extensions can be added.
This set of resources form the conformance module as shown here.
The conformance resources can be used in isolation but they are typically used in
the context of an Implementation Guide as shown in the center of this diagram.
Implementation Guides are documents published by a domain, institution,
or vendor that described how FHIR is
adapted to support a certain use case or set of use cases.
An Implementation Guide combines a set of conformance resources
and supporting narrative into a document to be used by implementors.
A good example of an Implementation Guide is the DAF,
Data Access Framework to the FHIR specification that specifies access to
patient data for EHR systems to meet
the requirements of meaningful use and related federal regulations.
Dr. John Halamka is
the Chief Information Officer of Beth Israel Deaconess Medical Center in Boston,
Chairman of the New England Health Care Exchange Network,
Co-Chair of ONC's HIT Standards Committee,
a full professor at Harvard Medical School,
a practicing emergency physician,
and an accomplished farmer.
In late 2014, he announced the Argonaut project,
a private collaboration in which each of
the participants agreed that all specifications and
artifacts developed would be openly available via an open content license.
Since the participants included many of
the largest health IT vendors and leading health care systems,
this was a very significant development.
The three initially proposed and now posted deliverables are,
FHIR Data Query Profiles,
a set of FHIR resources and accompanying profiles that enables
query/response of the discrete data elements
contained in the Meaningful Use Common Data Set.
FHIR Document Query Profile.
A FHIR resource and profile that enables
query/response of Cross-Enterprise Document Sharing XDS,
a specification for managing the sharing of
documents between healthcare provider organizations.
XDS is commonly used by health information exchanges to connect to EHRs.
Security Implementation Guide,
based on the SMART on FHIR OAuth 2 and OpenID Connect profiles.
These are the key tools for establishing
identity and access rights to data for SMART and FHIR apps.
We will discuss this in more detail in the next lesson.
Two newer deliverables are the Scheduling Implementation Guide.
This supports basic patient and provider
access to providers calendar and appointment requests,
including APIs and guidance for searching and publishing a provider schedule,
and requesting, canceling, or updating an appointment.
CDS Hooks Implementation Guide.
Argonaut is developing use cases,
providing guidance and publishing an implementation guide for deploying CDS Hooks.
Argonaut leverages the data access framework we mentioned earlier,
and it's compatible with prior interoperability efforts.
I took a Doctoral degree in what was then called,
Computer Science, in between med school and residency.
It was a hobby because no one could imagine why a doctor would want a computer.
So as I practiced in the academic environment for the next 25 or 30 years,
most of the interest came peripherally about the application of computers to health care.
I began my career in Medical Informatics full time about 20 years ago.
In today's world, we are burdened with
far too much information to make adequate decisions in a timely manner,
be accurate, up to date and appropriate for the patient.
We come to the decision process ill prepared to take care of our patients.
The technology now is able to provide us the kinds of support we need to reduce errors,
improve the care of patients and diminish skyrocketing cost.
HL7 began 31 years ago in a classroom
at the University of Pennsylvania with one goal in mind,
improving access to admission data.
Quickly, it evolved into clinical information and began a journey to try to enable
the sharing of data in a large ubiquitous environment that could
be seamless and yet deeply integrated with the way we care for patients.
Quickly, it was recognized that this is not simply a US centric process and
members of HL7 identify themselves all over the world.
And now we have members in 35 countries in every continent representing the,
sometimes local needs but often the global needs for care, public health,
research and the very core kinds of competencies that are fundamental for better health.
Six years ago, we began a program called Fresh Look.
What if we could start all over,
reinvent HL7 but careful to acknowledge
all the things we had learned about what we did right and what we had done not so right?
At that program, Graham Griff presented his vision for health care and operability,
which quickly was transformed into what we now envision in FHIR.
And although the adoption process was not immediate,
universally it was recognized that this shared many of the common elements that have made
commerce information exchange and the sharing of data
in public communication so simple and straightforward.
That technology was leveraged and made part of the fundamental elements of FHIR.
I think perhaps more importantly,
was a different focus for FHIR.
Unlike some of the earlier HL7 standards,
FHIR was really made an important part of the implementation community.
We didn't focus simply on the individuals
and stakeholder groups that needed to use our standards,
but on the people who would be the providers and end users of a product,
for whom, this has been the greatest leap of value.
I think the visionaries who developed FHIR,
realized this from the very start.
I think acknowledgement by a larger community,
like any other new idea,
required time and a great deal of effort.
Part of that was made simple by two fundamental processes.
One, we didn't charge for FHIR.
And secondly, we allowed a broad international community to contribute not only
to the development of the FHIR standard but the implementation of FHIR as a tool.
It transcended any other activity in its ease of use,
its global recognition and its adoption by a diverse community.
Not only is it about caregivers but also the research community,
the organizations that rely on population health.
And in the United States,
where we have multi payer systems,
the payer communities who now need clinical data more than ever,
are embracing the ease and ubiquity of a FHIR platform.
Some segments, some stakeholder groups and some individuals,
were far slower than others.
I can tell you that I was pleasantly
surprised by the diverse stakeholder groups,
who found FHIR to be useful.
I think in the communities that are not easily changed,
there is always a hurdle.
Change management is one of the great obstacles,
whether in the private sector or the public one.
And I think the access that HL7 provided to FHIR,
the ease of acceptance,
really accelerated the process in ways that I never anticipated.
I wrote in the HR in 1981.
It served one business case,
physicians in an academic medical center couldn't find the chart.
The paper charts were distributed in a host of different places.
The electronic medical record,
if you want to call what I produced,
simply allowed continuity so you could find out what happened the last week.
FHIR presents a host of opportunities because for me,
an electronic medical record,
is a lot more than simply a tool to document care.
It's an open resource for
the kind of clinical decision support that is so paramount as we transition,
from physicians who could imagine all the things they needed
to know in a few concepts.
We're now exploding with information,
not just about the clinical condition,
the therapies, the guidelines,
but also in the broad field of genomics and proteomics,
which will bring us concepts that are really beyond what humans can consume.
So the decision process has eased.
The sharing of information for
a continuous learning system is enabled because the delays in bringing
new ideas and new concepts to
health care from the research community are far too slow and far too expensive.
And so, FHIR presents a unique bridge to go
from one stakeholder group to another and the information moves rather seamlessly.
In the ensuing decade,
I expect the number of pieces of data that any clinician needs to make a decision,
will be beyond human reasoning.
FHIR will enable the kind of integration of diverse data.
We will have platforms that we had not imagined.
In fact, we have a program which is unique in my experience,
in which stakeholders who have produced FHIR apps, showcase this.
Our FHIR app round table,
is one of the most enjoyable moments in my year,
in which I get to see the kinds of
ideas that are brought to the fore that I had never imagined you could do with data.
And more importantly, the developers of these products have an opportunity to
collaborate and bring yet unique ideas to the fore with an ease,
that I don't think even they imagined.
And I suspect that in the coming decade,
HL7 will be transformed into a facilitator of that process.
Grahame Grieve. I'm an Australian.
I began my life as a bench scientist in a clinical laboratory.
I'm in a clinical research,
jumped ship to join a vendor and become a developer,
and eventually the CTO of the laboratory systems vendor.
Spent more and more of my time doing actual serving and interoperability.
Generally, got more involved in HL7.
Went at freelancing national expert in CDI adoption,
realized that all the passwords on were wrong,
went off in FHIR,
and accidentally ended up as a FHIR product director which is what I am now,
responsible for stewarding the FHIR community and the standard
towards maturity and towards making a real difference in the healthcare industry.
It's a combination of things.
First of all, it's the right idea at the right time.
The industry, the community is really ready for
a spec that uses web technology and web principles and that's what we had.
And also, we created open community that was
very dynamic and community-led. And we did that.
We're just learning from other people who had done the same thing in other communities.
And their willingness to copy the good ideas from wherever they come
from has created a community that is excited,
and that excitement both led onto,
in the end, a really formal standards processes.
Pretty compelling combination for people.
And that's seems to be doing it so far.
Yeah, and a lot of app processes are around finding
a balance between many competing points of view with those in particular.
And so, partly, it's about being really willing to get a feedback
because there's no perfect answer to choose your engagement.
And that's the beauty of actual serving as a formal standards process that backs it,
is that people know that it will become a standard and a call to engage.
And so we have a real advantage in terms of bringing together everyone who needs to
be here or not able to just go some project that we won't have to buy attention to.
That's got some problems but it does make it really easy to engage,
and the other part is an intuitive process to
try something for feedback, get some feedback,
try something slightly different and eventually,
you'll see the community
automatically congregate around a single solution at a single point.
And so initially, things go in and there's a lot of changes.
Everybody settles around the idea,
but you can see it automatically.
People stop complaining and start working with it,
because you've let everybody circle and come to agreement organically.
And we see that person is repeating a lot
and we seem to be on a workable path to a meaningful standard.
Instead, it's a kind of tricky because you can easily
impose a standard from above - top 10 standards process.
And if you do that, you'll often get a stand that everybody says they cannot conform to.
But nobody really actually will,
because it doesn't really do what they need.
And so, you have to let standards develop bottom-up.
But if you let standards develop bottom-up only,
who knows what you'll get.
And it's an art form of balancing that two.
Often compared to a slinky dog,
the dog with a big spring between the front in the back.
Like, the back and the front can go in different directions,
but only for a little while.
They tied together and I think it's the same very
much with top-down and bottom-up standards design.
Yeah. Look, I feel as though we're half way in that.
But we get new scopes brought to us all the
time and some more scopes that I never expected to take on.
And, some of them,
the resource gets adapted to new scopes and some of them split off or added in.
And so, we don't have a formal goal in terms of that and in terms of how big,
I think more in terms of community
and adoption size rather than how big is the specification.
And I've sort of thought
that the right ballpark figure of how big the community is is a trillion dollars.
I mean, that's how much money
is being spent in the space of health care interoperability and
systems and that so the system is bounded by FHIR that will connect three FHIR.
The money all goes elsewhere,
but if you change this,
if you took FHIR away and put something else in,
then that have to re-spend all the money because that bridge is on to
a different set of ideas over a 20-year period.
That's the kind of dollars you're talking about.
And it's a lot of money and that's why it's really
important to have good governance and formal standard governance
because that's the kind of money that people are choosing to
invest somewhere around the world.
You measure it in terms of percentage of the world GDP, in fact.
It's not spent on FHIR but it's spent in the space bounded by FHIR.
Yeah, I have been surprised.
So I thought, we've consistently been running ahead of where
we thought we'd be in terms of standards adoption.
And it's pleasing for us that the work that we put in is starting to have an impact.
We're certainly just starting out.
I see standards, this is like
a river at the headquarters and the water flows down through the river,
the standards process is
a 20-year time-frame and we're sort of five years into the 20-year time frame.
And we're still mainly focused at
the top end where we've got much more adoption we expected in that time.
And so, that bodes well
for our ability to create change in the health care system which is our real goal.
The increased availability of data increases
the interest in doing stuff with the shared data in signing setup shared processes.
And there's a lot of interest in that.
And I feel as though, the fact that you can get data,
creates the expectation and desire to share processes.
And sharing processes has always been our goal, sharing data.
So what you've got data,
it's about being able to build processes on top of that.
And also the fact that there are servers,
we've always in the specification allowed for writing data back in.
And there are systems that do that out there,
that creates a competition and
the perception that you should be able to if only you had done the work,
on the other hand, it's a lot of work.
You really need to re-conceive your job to open it up that much.
And so, it's in spite of the fact that everybody wants it to happen.
It's not just flick the switch and make it happen,
you've got to do a lot of engineering,
it means move your business rules around.
It's a big work.
And so it's taking some time for the vendors to get there.
And they're not there yet,
but they're thinking about it and working on them.
So it's already happening in a lot.
It's certainly true that there's
a wide spread perception that main focus is EMR tighter access.
And there's a degree of politics to that.
There's a lot of projects that are just doing the work,
they're not making a lot of noise about it.
So for instance, the VIJ have a FHIR base project for aggregating observational data,
from the data collection devices that they're wearing.
You don't hear a lot of noise about that,
but they're using that.
There's a certain amount of politics going on in the kind of projects we do hear about.
And also, there's other countries,
the politics focus is different because there are at different stage in
the last cycle and they had different historical practices in the past.
That have meant that the politics is playing out in different parts of the ecosystem.
And so, when I look at it, there's a lot of noise about one part of it.
It's kind of happening.
We haven't really added anything to the spec,
unless there are people using it.
And people are taking up and using my space,
is the specification I think is.
I always say that the amount of interoperability you need is n_times_2,
where n is the amount that you have.
And as you get more bang for your buck,
as we can monetize more interoperability exchanges,
people start looking to expand that because they start getting
benefit for the money they're spending and much more easily.
And so they start saying, "Well,
we'll pick off different functional areas and start working on those."
And we're going to see next year
some very large consumer initiatives around health data aggregation,
and collection, and leveraging, [inaudible] accessible data.
It certainly really starting to pick up now.
And so, that will just increase the impetus towards
leveraging data sharing in new context and as I said,
setting up first new patient care processes.
So I think that's more and the politics of
the EHR position that has led to a perception that it's about patient by patient access.
Well then, that is true that our focus is mainly being on very fine grained,
high availability access to the data,
very integrated between the two ends of the conversation.
And we're certainly having a lot of discussions
now about what it looks like to use the FHIR.
Symantec's is a interoperability base,
but to do so in the presence of very large amounts of data,
many gigabytes of data.
And that comes to fruition in that way now,
we're now working with ENRC to trawl what they're calling bulk data access,
which is pretty much are in feeding the big data systems.
I think that's going to be the role of FHIR's place is allowing
people working on big data [inaudible] and on PMI and other projects like that,
to access data on bulk,
and moving into big data analysis systems.
It remains to be seen how much direct involvement in
the big data side of things we can or should bring.
So, I've sort of seen FHIR's 15 year plan.
The first five years for initiating the community,
figuring out what FHIR was and what would make it successful.
The next five years we expect it to be a principal growth phase,
where we were building out the standard,
and then final five years,
you'd be consolidating the standard and building up solutions.
We've seen the adoption vices running ahead of that initial plan,
but it seems as if the standard process will follow that overall plan.
So, in five years time from now,
I want to be saying that the community is
a really significant factor in the overall healthy ecosystem.
The standard itself is mature and starting to move towards long term maintenance.
The community I'd like to see,
the community focusing on bringing home the processes that
we've imagine building on top of the availability of sharing of data in birth in,
as a free flowing liquid entity through the system.
And that consumers, whether they're governments who pay for
health care or private insurers who pay for health care or patients they get health care,
or they are getting value for money to an improved health care and improved outcomes.
And the one thing that I expect will be a big issue
in five years time is starting to really rethink clinical processes,
because we're in a new place.
And it's clear that clinical processes and the expectations of the relationship between
the consumer and the health care providing system need to change,
and we're in a position to support a different way of providing health care.
And that's going to be an interesting and at times, challenging discussion.
We have now completed our review of data and interoperability standards.
This is an immense area and I've only been able to skim
the surface in an effort to equip you with a working knowledge of the domain,
its approaches and technologies,
as well as the potential benefits and the challenges.
To explore further, use the many references to
external resources for this critically important plumbing.
For the health informatics tools and systems,
we will discuss later.
A universal health app platform to support
informatics-based innovations in care delivery,
no matter what the underlying EMR was
a long held dream of the Academic Health Informatics community.
In 2010, the Office of the National Coordinator of Health IT awarded
$15 million to the Boston Children's Hospital Computational Health Informatics Program,
and the Harvard Medical School Department of Biomedical Informatics
to create and initially develop just such an app platform.
The result was SMArt,
an acronym for Substitutable Medical Apps,
reusable technology, and open standards
based technology with a robust community of app developers.
A group of health care organizations joined
the smart advisory committee to support the effort through philanthropy,
strategic guidance, and deployment of the technology.
SMART development preceded FHIR,
but as FHIR became more significant,
the project shifted to the development of a layer that
builds on the FHIR API and resource definitions.
As we explained earlier,
FHIR provides a set of core data models but many FHIR fields and value sets
may not be constrained to support
specific requirements across varied regions and use cases.
To enable substitutable health apps as well as third party applications services,
SMART implies a set of profiles that provide developers with
expectations about the vocabularies they should use to represent medications,
problems, labs, and other clinical data.
As part of the Argonaut Project we discussed earlier,
the five largest EHR vendors either have a will bill SMART into their products.
The vendors, the SMART team,
and HL7 are working together to standardize the SMART API in HL7 specifications.
Clearly, third party apps must not access
protected health information without being registered into an EHR,
establishing trust in who is using those apps,
and respecting patient privacy choices.
To facilitate this, SMART provides login and data access
authorization models based on the openID Connect and OAuth 2.0 standards.
In this lesson, we will look at how SMART uses these technologies.
Through SMART Genomics and CDS Hooks,
the SMART Project is helping to find the next generation of FHIR base standards for
the clinical use of genomic data and the integration
of clinical decision support into provider workflows.
We will also discuss both of these efforts later.
To make it easier for developers to get started building apps,
the SMART Project offers a set of open source libraries for HTML5,
JavaScript, iOS, and Python.
To support running apps within the EHR's user interface,
SMART allows web apps to run inside browser widgets or inline frames.
It also supports native and mobile apps.
SMART also offers a free web-based API Sandbox that developers can use to test
their apps as well as a locally installable version
the developers can download and run on their own system.
Here is the public Sandbox that everyone has access to,
but you can create your own.
Note that you can install your app and test it
using sample patients, practitioners, and data.
Here for example, is some of the extensive set of
vital signs data that is available for testing.
You can also create patient and practitioner personas
and use them in launch scenarios to test your app.
As illustrated here with a patient,
there are sample personas of both types
available for use if you do not need to build your own.
Note here that you can quickly see what type and
quantity of FHIR resources exist for each patient.
SMART offers FRED, a web-based interactive FHIR
resource editor to help developers create sample data for their apps.
I suggest you try using FRED to build a FHIR resource of your choice.
Here you see that I even put some elements of a FHIR patient resource representing me.
When I click Export JSON,
I get this JSON that corresponds to what I've input.
SMART C3-PRO is a software library that integrates the SMART platform with research kit.
SMART's C3-PRO is a software library
that integrates the SMART platform with research kit.
Apple's open source framework to enable iOS apps to become tools for medical research.
Finally, the SMART site offers extensive documentation.
I strongly recommend you spend time there.
OAuth 2.0 Is a widely used authorization framework
that enables web and desktop applications,
as well as mobile devices to obtain specified
constrained access to user accounts on an HTTP service.
OAuth 2.0 defines four roles, resource owner,
resource server, authorization server which can be the same as the resource server,
client in our case the FHIR app.
The resource server host the protected information.
The authorization server verifies the identity of the prospective user of
that information and then issues access tokens to the application.
And OAuth 2.0 scope,
specifies the level of access such as read or write that the application is requesting.
In the case of SMART on FHIR,
the scope might specify what FHIR resources can be accessed for
a specified patient and how much of CRUD the app can perform on those resources.
In SMART on FHIR,
when a EHR user launches an app,
he gets a launch request notification,
the app asks for the permissions it needs using OAuth scopes such as patient/*.
read. In the case of a launch within an EHR charting session,
the scope patient/*.read refers to
the patient whose chart is in use at the time of the launch.
The term for this is in context and
this request only makes sense within a charting session.
The app does not yet know who that patient is when it requests the scope,
it learns that from the access token response where
the patient property will provide the FHIR patient resource ID.
These so called launch parameters are an extremely important capability of SMART on FHIR.
As you know, tools such as clinical decision support have
existed for decades but have not found wide use.
To coin a small pun,
providing this context literally allows the app to be smarter.
Avoiding work for its clinical user and
thereby increasing the attractiveness of using the app.
In the example we just discussed,
our hypothetical scope request contained a wildcard, the asterisk.
Through it, a client app is seeking permission to obtain
all available and future fire resources stored on the server for the current patient.
This raises the issue of patient privacy.
The authorization server asking a patient to authorize
a smart app requesting patient/*read,
should inform them that they are being asked to allow
the app access to all currently available and future
fire resources that might contain
potentially more sensitive data such as their genomic variations as we'll discuss later.
Of course, as we discussed when we looked at health vault,
giving the patient usable tools to select what they are willing to share is a challenge.
However, the granular nature of
fire resources could certainly facilitate the development of such a tool.
This would be particularly true if, as illustrated here,
in a medication request resource example from the fire site,
all applicable resources included the reason for orders and procedures.
If they did, then a patient might specify that they wish to share all information
related to a particular clinical problem
and the app could figure out what that information is.
At present, these cause and
effect relationships are not in all the applicable fire resources.
Even if they were,
this is not just an issue for the standard.
A complete solution would require vendor support of the idea in
the AMR and provide a willingness to take the time to indicate these relationships.
Alternately, this may well be another opportunity for machine learning
to infer relationships from the data recorded over many patient encounters.
The authorization server may not grant the level of access requested by the app.
For example, an app with the goal of obtaining read and write access to
our old friend the patients allergy intolerance resources,
request the clinical scope of
patient/AllergyIntolerance.* The authorization server
may respond in a variety of ways as shown here.
App designers should anticipate this.
And their apps should consider the permissions granted to
them and they may need to change their behavior accordingly.
As we just discussed, in many cases,
SMART apps launch within the context of
an existing EA chart charting session where the provider,
patient and encounter are clear.
In other contexts, SMART may need to use open ID connect,
a simple identity layer on top of the OAuth 2.0 Protocol.
It enable apps to verify the identity of the end user
based on the authentication performed by the authorization server,
and obtain basic profile information about the end user.
To use open ID connect,
the app asks for the open ID scope when it request authorization,
and it will have access to a user info endpoint that exposes
user information referred to an open ID as claims.
In SMART, these include the end user's name and
their unique national provider identifier, NPI.
A 10 digit number assigned by
CMS providers that uniquely identifies them across healthcare organizations.
A SMART app must be registered with an EHR's authorization service.
Before it can be run within that EHR and access data from it,
the registration technology is up to the EHR vendor,
although SMART recommends the OAuth 2 dynamic client registration protocol.
No matter how it registers at registration time,
it must register one or more fixed fully specified launch URL's and redirect URL's.
EHR's can offer SMART apps to
the provider in ways that greatly increase their likelihood of use.
In this example from Cerner,
the apps are in the same main menu that the physician uses for other charting activities.
This greatly facilitates the usability of
the apps by saving time through eliminating extra clicks.
Also note, the display of the apps information,
which is patient education in this case,
conveniently happens in the usual clinical data presentation area of the EHR screen.
Alternately, as shown here,
an app can launch standalone.
This is actually a design prototype done by a group of my students
for an app that supports epilepsy patients via their smartphones.
This kind of standalone patient facing app and
apps for providers launching within an EHR session,
are probably the most common use cases for fire.
In an EHR launch, as shown here,
SMART passes and opaque handle to the EHR context to the app as part of the launch_url.
The app later will include this context handle as
a scope parameter when it requests authorization to access resources.
Note again that the complete URL's of all apps approved for use by users of this EHR,
must be registered with EHR's authorization server.
As shown here, when an app is launched standalone from outside an EHR context,
it requests authorization to access a fire resource by redirecting it's
authorization request to the EHR's authorization server.
Based on predefined rules and possibly end user authorization,
the EHR authorization server either grants the request by
returning an authorization code to the app's redirect URL,
or denies the request.
The app then exchanges the authorization code for an access token,
which the app presents to the EHR's resource server to obtain the fire resources.
If a refreshed token comes along with the access token,
the app may use this to request a new access token with
the same scope once the original access token expires.
This has been just a basic discussion of SMART app authorization.
The important details are readily available on the excellent SMART on-fire site.
There are also numerous web tutorials about OAuth 2 and open ID connect.
Google provides an interactive OAuth 2 playground.
SMART supports developers with backend services to access FHIR resources
by requesting access tokens from OAuth to compliant authorization servers.
As with apps the backend service must be authorized in
advance and must run automatically without user interaction,
be able to protect a private key,
require access to a population of patients rather than a single patient.
Such a service might for example review
incoming laboratory results and generate clinical alerts when
specific trigger conditions exist or it might
maintain an external database of patient data for research purposes.
If you think back to our discussion of FHIR apps integrated into EHRs,
it should be clear that the decision to initiate the apps rest with the EHR user.
This in turn rests on the user recognizing that an app
exists that might be of benefit in a particular patient.
Clinicians are busy, so it is not hard to imagine that this might not happen.
Very much along the lines first explored by Arden,
the CBS Hook's initiative within SMART
provides a means of imbedding clinical logic within
the EHR to invoke decision support which might or might not be a full FHIR App.
Unlike with Arden, this occurs within
a clinician's workflow and because of FHIR there is no curly braces problem.
A hook is functionality provided by software,
for users of that software,
to have their own code called under certain circumstances.
Clinical examples of such circumstances might include,
opening a new patient record,
authoring a new prescription,
viewing pending orders for approval.
Under such circumstances, CDS Hooks can display cards to
provide useful information or offer apps to help make optimal clinical decisions.
There are three kinds of cards.
Information cards convey text.
Alternative suggestion cards provide an action different from the one contemplated.
App link cards suggest the use of an app or reference materials.
Here, I have used
the interactive CDS Hooks demonstration tool on their site to show how a hook,
inserted into the code for recording new prescriptions,
causes the display of a suggestion card.
This example explains the potential savings if
a generic equivalent replaces the brand name drug the provider input.
Visit the CDS Hooks site for more details.
Personalized or precision medicine is the concept of using
rich and potentially broad datasets about
an individual patient to guide optimal diagnosis and treatment decisions.
These datasets might supplement the traditional clinical record with behavioral,
environmental, socioeconomic and genomic information.
Behavioral data is largely the domain of MHealth,
a later topic in this course.
Genomic datasets are very large.
Current estimates of a single patient's genome are around
As a result, genomic data is unwieldy for direct use in patient care.
The goal of the SMART on FHIR genomics effort is to make
genomic data usable and useful in patient care.
Among other things, it is defining
a new FHIR sequence resource that contains the most clinically relevant data,
as shown in part here.
It is also developing SMART apps that can present that data to clinicians in useful ways.
Given the complexity of genomic data,
it should not be surprising that this is perhaps
the most complex FHIR resource yet specified.
A specification includes instructions,
such as are shown here,
that explain how to document single nucleotide polymorphisms,
SNP or SNPs, the most common type of genetic variation among people.
Each SNP represents a difference in a single DNA building block called a nucleotide.
For example, here the nucleotide thymine or T in
the observed sequence replaces the nucleotide guanine or G in the reference sequence.
Here you see how to document that substitution in the sequence resource.
Apps could access FHIR genomic resources from the HRs,
from genomic data repositories or specialized sequencing systems.
The key effort for a data provider is implementation of
a SMART on FHIR genomics data adapter which
creates a binding to convert between the standard SMART on
FHIR genomics format and the provider's native format.
KRAS is an oncogene that when mutated
has the potential to cause normal cells to become cancerous.
In this early example,
Vanderbilt School of Medicine's prototype SMART precision cancer medicine act
usefully presents genomic information in real time,
comparing a cancer patient's diagnosis specific detected
gene mutations to a comparable population of cancer patients.
It should be clear to you how the sequence resource we
just discussed would support an app such-
Yes. Ken Mandl, I direct a program at
Boston Children's Hospital called the Computational Health Informatics Program,
where we've got 23 faculty doing work in informatics across multiple dimensions.
One of those dimensions is SMART on FHIR.
Well, at that moment,
the adoption of electronic health records was
only about five percent in both inpatient and outpatient settings.
There was about to be first a 19 billion but
then a $48 billion federal incentive program
and around promoting the adoption of electronic health records.
The opportunity we thought was then
to dictate what the requirements of that program might be.
And we suggested that the requirements could be
reduced to really one very simple principle,
which is that the electronic medical records should be able to behave like iPhones,
and that they should be able to run apps,
and that those apps should be able to be added
to or deleted from the electronic medical record.
We call that the principle of substitutability and argued that
substitutability should be the driving force behind interoperability.
The opportunity was designed to produce a few important effects.
One was so that innovators could readily get their innovations to
the point of care in the same way that
app developers for the iPhone platform were able to do that.
It separated the innovators from
the electronic medical record companies and that
our vision of substitutability was that it would also be vendor independence.
So the app developer wouldn't even need
to know which electronic health record it was going to run on.
Now, the iPhone was only one year old at the time.
And when we wrote the article,
there were 10,000 apps developed for the iPhone.
When it was published three months later,
there were 50,000 apps in the iTunes App Store.
And so we caught this phenomenon at a hockey sticking moment,
and the world was just starting also to understand why
the iPod that they had now needed to make phone calls or,
alternatively, why their telephone needed to play music.
And people were starting to understand this App Store was actually
a really important part of this new technology.
So one is innovator to the point of care.
The other is end users so that they can actually select from
a market of applications as opposed to only what comes out of the box,
such as the end users can enjoy a truly competitive market to
produce the functionality that they want and to enable them to
customize that functionality if they want to produce apps within their organizations.
Yes. It's really, I think, a very happy story.
We began with a restful model of call-in resources across
an API and with
well-defined resources that represent only a subset of all possible types of health data,
the most useful subset to get started with.
And we used an RDF technology initially to define those resources,
and we were actually getting apps developed and developing our own apps.
But we started to see this very interesting FHIR community cohering.
And not only did we think it was interesting,
but we jumped in and decided to actually help create the FHIR standard and
to really promote it and to get behind the founders of FHIR.
Another nice aspect of it for SMART is that wall SMART
was attempting to define a universal standard for an API.
The SMART team had no aspirations to become a standards body.
So the fact that SMART had been ingested into HL7,
and that HL7 was going to not only further develop the standard
but also make it freely available was extremely attractive.
And it became very clear that one way that SMART could have longevity and
scale would be to rely on a standards body for the standards part of the project.
On the whole, the products on the market are
older software stacks that are monolithically designed and many of them are pre-Internet.
Now, they are, of course,
being updated all the time but the degree to which
the developers in the EMR companies could be truly nimble about
evolving the products and somewhat limited by their complexity.
So what SMART enables the ecosystem to produce
is essentially a facade that interoperates with the electronic medical record,
leaving it fully in place,
keep taking advantage of all its myriad capabilities but providing for
the clinician or for the patient a modern web-based user interface.
So what SMART does very specifically is it brings the full capabilities
of the worldwide web to the point of care connected to the electronic medical record.
So, now, you can do anything you can do on the web and
HTML5 with data mashups, data visualizations,
bringing in external data sources,
genomics for example or environmental data,
and do it in the context of the physician workflow.
It's a very good question.
SMART on FHIR apps can begin to play a role in bringing evidence to the point of care.
First of all, I think we're in a transition where we believe
that evidence comes from data at least as much as it comes from the medical literature.
So one way that evidence-based medicine has been
interpreted is the best use of the medical literature as applied to one's patient.
So SMART on FHIR can help with that aspect of
a traditionally defined evidence-based medicine
through its connections into decision support through
this CDS Hooks process or other ways to bring in guidelines
and interpreted medical literature into the decision making process of the physician.
But the other aspect that I think is more exciting even is
that decisions will be made on the basis of
insights that have been derived through advanced modeling and
deep learning or even derived on the fly from very large population data sets.
Interestingly, those data sets are created in part through electronic medical records,
collecting data from every visit.
But, also, data is important from other sources: social media, public health genomics.
And all of those forms of data can provide a new kind of evidence-based medicine,
a really data-driven form of evidence-based care.
And through the power of simply taking advantage
of all the innovations that have happened in the web
and the opportunity to bring data sources together to
have different computational processes interacting with each other,
to provide advanced data visualization,
we can begin to bring this new form of data
driven evidence right into the physician's workflow.
Absolutely. So SMART on FHIR actually is a project that
builds upon work we did around a patient-controlled health record,
in which there is a repository of data that
the patient controls with apps running on top.
The problem with patient-controlled health records in the past has been that they
haven't been easily fed by data from electronic medical records in other systems.
The data hasn't been interoperable.
So, patients haven't been empowered with their data and they
certainly haven't been empowered with apps running on their data.
Instead, what patients got over the last decade or so
was portals that are bolt ons to the electronic medical record.
And so those portals give patients a view into the electronic medical record data.
Generally, they don't take the data out with them,
but at least, they can see it.
The portals, therefore, have had somewhat limited functionality.
The opportunity now that's SMART on FHIR brings to the patient is two-fold.
One, it lets the patient actually take out their data and get a copy of it.
The right to do that is reinforced by what's called meaningful use stage three.
And it's also reinforced by now the 21st Century Cures Act, which is law.
So, the patient can get a copy of their data.
And secondly, the patient can connect apps just like
the provider apps to an electronic medical records system,
so that they can enjoy the same kinds of benefits, data visualization,
data mashups, computational processes,
serving their healthcare needs.
Well, it's very interesting.
There's an absolutely exploding field around data generated by sensors,
data generated by standard mobile devices, iPhones and androids,
and data developed by the same technologies and various wearable forms.
The ability to ingest those data into
the electronic medical record is one important area.
Electronic medical records are not particularly designed to do this,
so one intermediate layer where the data from the electronic medical record
and from this new generation of sensor technologies,
is in this SMART on FHIR layer.
On top of the electronic medical record,
it also provides a real opportunity to
deliver the right interpreted information from these sensors to the clinician.
Most clinicians will not be interested in raw data.
And so, the question that everyone's asking is,
"What's the best set of workflows to get those data
into a decision making process with the physician and the patient?"
I think SMART on FHIR apps provide at least an early solution to addressing that issue.
Well, I think one
of the most exciting opportunities to interface public health to the point of care,
is the tremendous population and representative
population data resources that public health has that can
form the decision making for an individual patient.
A patient's diagnosis, or laboratory data,
or symptoms, not in an epidemiological context,
is much less useful.
So for example, if a patient has a sore throat,
and we're trying to decide whether to test them for Strep,
there is a much higher chance that that test will be
positive if there is Strep going around in that person's area.
That could be readily derived from a population health,
or public health dataset.
That could guide our testing,
and rational testing, and treatment around Strep throat.
Reduction of false positives could save
literally hundreds of thousands of courses of antibiotics per year.
That's one example of how population data can inform individual care.
So it's a very nice research-related use of the SMART API,
such that a participant in the precision medicine initiative,
now known as the All of Us Initiative,
can request a copy of their data from their local health system by connecting
an app to the Smart API at that health system,
and direct a copy of those data to
go to the Precision Medicine Initiative or the All of Us Initiative.
It's essentially a way that operational liases data donation for research subjects in
a very large study seeking to recruit a million patients.
So, I think at the moment,
we have an incredible opportunity with SMART,
because it's been built into the electronic medical record products.
It's essentially been regulated that there be these APIs.
And even beyond regulated,
it's made it into the law.
So we're moving into a more modern era of
interaction and interoperability between medical systems.
Where I think we need a lot of emphasis now is to create a robust apps ecosystem,
and we need to focus on a few key areas to do that.
One is we need to make it much easier to develop apps.
I have a lot of folks come to me with great ideas.
But the recommendation is always, get some funding,
find an app developer,
try to develop an app with that developer,
and then figure out how to maintain it.
We need to be able to make app development into
a much more commodity process so that good ideas are very rapidly translated.
We also need to increase the level of expectation that scientific findings,
particularly around those that
are designed to have an impact on the medical care process,
are computable and can be operationalized.
So I would really like to see publications that are developing algorithms,
have accompanying apps with them that can be
plugged into and tested in the health care system right away.
All right. Thank you, Mark. Very pleased to be here.
With Josh Mandel.
Josh, can you introduce yourself briefly?
Sure. So I'm Josh Mandel.
I'm a physician and a software developer.
And since I graduated from medical school,
I've been working on various projects in healthcare informatics with the goal of
making it easier for developers to build
new functionality that integrates into the healthcare system.
Sure.
So when the history goes back for me to about 2010,
I was graduating from medical school,
and as a medical student,
I had been very interested in making the computers do
more for me and for my classmates and for clinicians and patients.
And I had learned about this field of medical informatics.
So on my way out of medical school,
I was really excited to join a team that was just coming
together at Harvard Medical School on this new research project called SMART,
which was funded by a grant from
the federal government with the goal of building an app platform,
so building a way for developers to connect to the data inside of healthcare systems,
and present apps that doctors and other clinicians and patients could
use to make sense of the data and the medical records.
And when we started this project in 2010,
we really started from scratch.
We said, "What would a modern REST API look like for working with healthcare data?
What are the kinds of data we care about?"
And we made a list: medications,
problems at labs and allergies and so forth.
And we started asking, "Okay.
Well, what are the detailed data models?
What are the attributes of each of
these data types that we'd want to be able to work with?"
And, early on, we hosted some sample data that we put together,
working with a number of partners.
We integrated into a couple of
open source electronic health records systems to
give developers a picture of what this would look like,
and we held a competition asking for folks to build apps and share their ideas.
And we got great feedback from the developer community saying,
"We wish we had this kind of interface in the real world,
inside of real healthcare systems."
At the same time, when we had conversations with some of the health IT vendors that make
big electronic health records that are in production at some
of the major hospitals and health care centers,
the feedback that we got was,
"We're really excited about this technology,
but we're not going to go and implement a whole new set of
capabilities just to align with this research project at Harvard.
What we really need is a set of standards that we can agree on as
an industry to support these apps but also to support other use cases as well."
So that was about when I started getting involved in the standards development process,
and got involved with the development of what was then the very early days of FHIR,
the vast healthcare interoperability resources standard.
Sure.
So, early in the project,
we discussed a number of ways to improve access for developers to clinical data.
And we settled on a relatively small scope to begin with,
which was focused on building apps that could integrate with EHR and
mostly have access to read data from inside of the systems.
So data liberation, exposing what was in
those EHR systems and making sure that apps
could take advantage of those data and present a user interface.
And we were able to make a lot of progress by keeping the scope pretty narrow.
So the kinds of things that were left out of scope from the beginning
were being able to write complex data back into the EHR,
being able to integrate deeply with a clinical workflow
by restricting where and when an app gets presented.
We left out of scope
how multiple apps might run at the same time and
interact with one another through sort of real-time communications.
We left that all out of scope and said,
"Can we just solve the problem of putting one app at a time inside
of one EHR at a time with a consistent interface?"
And the exciting thing is because we were able to keep the scope pretty narrow,
we really focused on things that could be done without a lot of new research efforts,
things that could be built into the production systems in the real world.
We started to see uptake of this technology from some of
the biggest health technology vendors so that
now if you go to the healthcare trade show
and you look at some of the big vendor systems,
they are announcing support for and now they have support rolled out in production for
these capabilities inside of their health records that clinicians
use and also inside of their patient portals that patients use.
So we're really starting to see it become a reality for
these apps to get access to data and to be able
to display innovative user interfaces and make
recommendations for clinicians and for patients as well.
So we're at the point right now where our narrow scope has become a reality,
and it's very exciting to think about what comes next,
how we can begin to tackle some of those issues that we
left farther on the development queue.
Yeah, so one of
the great things about having a way to integrate apps with
the EHR is that apps can do practically anything,
anything you set your mind to and anything you can
display inside a window for a user to see.
But one of the challenges with apps is that you
have to know which app to run and when to run it.
And so, for example, if we have an application that helps clinicians make sense of
the bilirubin levels in a newborn infant and provide decision guidance,
such a child who needs phototherapy or other therapy or this level's normal.
If a clinician doesn't think to run the app,
they're not going to benefit from the advice.
So one of the big problems that we set out to solve was how
to recommend exactly the right app to the right user at the right time,
and even to look at kinds of integration
that might be a little bit less than launching a whole app,
but just integrating a snippet of advice or recommendations into the clinical workflow.
So the CDS Hooks project is really about that.
It's about watching what a clinician does while they're working with
the electronic health records system all day long and instrumenting that interaction,
looking for specific points in the interaction,
like opening a new patient chart or prescribing any medication or reviewing a set
of orders or lab tests that a clinician might be about to order.
We look for the specific points in the workflow, and we say,
"We're going to provide a way for external services to
offer their advice inline at those points."
And the advice could be as simple as a little bit of text for the user to read,
or it could be as rich as a link for them to click to launch a SMART app from
right inside the context of
their electronic health records system and really do a much more detailed workflow,
where they can provide some more inputs and get some advice that they can act on.
Sure.
So the Sync for Science initiative,
Sync for Science is a project that is focused on specific use case.
It says, "How can we help patients who
might want to share their medical records with researchers?"
Because the truth is that if you're doing a research study,
it's very easy to ask questions to your research participants.
You can create a form and collect structured data by asking.
But there's a rich history in the medical record that can be
very hard to obtain in a structured way.
It can be hard to obtain quickly or
automatically and without a lot of barriers in the way.
So, today, oftentimes, the way that a researcher
might get access to a medical record would be
either on paper by asking for
a medical record request and getting a stack of paper printed out,
or they might work with a hospital to develop a custom technology.
They might have to sit down and write special queries against
the raw database and try to pull out the fields they care about.
And both of those things are very slow and very expensive.
So in the Sync for Science project,
we've said, "How can we automate this?
How can we help patients share their data with researchers
in a way that gives full control to the patients,
but when a patient wants to,
they can automatically approve that kind of access?"
And it's a project that we've been running through Harvard Medical School.
There's a small technical team that's been helping to
develop a specification and some guidelines,
but we've been working very closely with the electronic health record community.
So we've been working with Epic and Cerner and Allscripts and eClinicalWorks,
working with each of these vendors to make sure they can build this technology into
their own patient portal products so that if I am
a patient at a hospital or clinic that uses a patient portal from one of those vendors,
I have a consistent way that I can approve an app to access my data.
And the cool thing is that under the hood,
we're using all those same standards that we've been talking about.
We're using the SMART on FHIR API to do that approval process.
There's an OAuth workflow using a standard set of
specifications to let a patient give access when they want to.
And then we're using the FHIR resource definitions
to be able to fetch specific kinds of data
like medications or allergy lists or lab results or immunizations and on down the list.
So it's been a really exciting project to see this technology
go from a set of use cases on paper or on our website
to now being implemented inside of patient portals from some of
the biggest electronic health record vendors in the country.
It's been a very interesting course for me over the last seven years,
which is to say, when I started,
I was pretty naive about the pace of progress and
I thought that things might move faster.
And the longer that I stayed involved,
and the more that I saw what it took to
really enable change inside of these organizations,
the more I've been surprised in
a positive way by how much we've been able to achieve in this time.
So the biggest leap that I saw us make was from talking about
this work as a research project as a cool idea about what the future could look like.
And if I go back and I look at the slides that I was presenting in 2010, 2011,
but not as a reality.
And then if I look at what started to happen, 2013, 2014, 2015,
vendors started picking up this technology and saying,
"We can use this to solve real problems that our customers are asking for.
We can use this to extend the features that are electronic health records systems
have by really taking advantage of the wide market of app developers,
who have good ideas about how to work with clinical data."
So I would say that from where I sit right now,
I've been really positively surprised by
how quickly we've been able to make this progress.
And I think that a major factor in our progress has been keeping
the scope small enough to feel like it's not too far over the edge.
And so I'm talking to you right now from San Diego at
the end of a working group meeting
of the standards development organization, Health Level-7.
We've been here for a week,
working with folks across the world,
who are helping to define some of these health care standards.
And one of the big challenges working with a group like this is everyone is
really passionate and has
huge aspirations about what they'd like to accomplish in this space.
But there's always a very careful balancing act between what you would like to
see happen and what you can really make happen in a short time frame.
And I think a big factor in our success has been focusing on the sort
of short to medium term.
So predictions are so challenging.
When I think about the kinds of work that we've been doing,
it's been focused a lot on workflow.
It's been focused a lot on how do we put
the right app in front of the right user at the right time.
And I think that's incredibly important in today's install base,
where there's a certain way that EHRs look and feel,
and they have certain capabilities built in.
But, honestly, it's unrealistic to expect the base product to develop
these neat new sophisticated features in every possible direction.
So being able to open up that window and launch an app is really important.
I don't know if I'll predict,
but I'll say that I hope in 10 years,
this whole paradigm may be turned on its head,
which is to say, we won't necessarily be working with EHRs that look
and feel the way that today's systems do.
We may have very tailored systems that are focused
on the particular tasks that our user is trying to do,
and rather than launching an app from inside a system like that,
I think that the data will begin to become more of the central focus of the platform.
We're almost seeing an inversion of the control
so that rather than the EHR being the central focus,
the data will become the central focus,
and we'll be able to construct the kinds of workflows we need around those data.
That's a really abstract concept,
but to draw that home maybe a little bit better,
I would say that I hope in that time frame,
what we'll have is individual systems that
know how to take care of patients with specific diseases, for example,
and provide a really tailored workflow and experience for making
the right choices and incorporating patient preferences and
feedback from patients into that kind of workflow.
Thank you very much. It's been a pleasure.
Sure. I spent the beginning of my career
working on mobile and communications technologies
both in the government and venture capital
investing in emerging communications technology.
And transition from there to healthcare have an M.D.
and a PhD in Pharmacology from Emory and did my clinical training in OB GYN.
And decided to leave clinical medicine and focus again on innovation.
But now and the health care sector
and did some work in venture capital before starting RIMIDI.
I was working with a venture capital group that was talking to
Fortune 500 companies about what drives their health care cost.
And some of the expected usual suspects,
they're Cancer, Pre-term birth.
But I was really surprised that chronic diseases like Diabetes were top
five health care cost for all of these corporations.
And you know, I had the C level suite from companies like Delta
talking to me about Diabetes which is a clinician didn't make any sense to me.
You know we know how to manage those diseases.
How can we do such a poor job.
And when I looked into it really decided it was an execution problem.
We weren't using data effectively to
manage the disease in the way that we should be able to.
So RIMIDI's product is a software platform that
focuses on the whole spectrum of what's needed in diabetes management.
From patient self-management to
population management to clinical analytics for providers.
So we share data across that spectrum patient
generated health data that comes from sensors and devices
and wearables as well as
the electronic medical record data that we pull from the EMR systems.
And then we perform the analytics on that data to give the right insights and
actions to those end users.
Sure, so a couple of problems we're addressing there one is there are
these general population health tools that have been implemented to really help define
populations in cohorts of patients within
a system and to help that system understand where their pain points are.
But defining population health doesn't solve the problem.
Someone put it to me last week.
It doesn't change the clinical workflow to know what the problem is in your population.
So remedies really digging into that.
So our predictive analytics both help the health system know
how to prioritize and triage the patients with a particular health condition.
So they know where to spend their time.
But then at the individual patient level,
we let them see the anticipated impact of treatment decisions.
So, were short circuiting this trial and error process of handing a patient
a new prescription waiting six months for them to come back and
see what happened and then iterating on that decision again.
It were allowing all of that iteration on screen in front of
the clinician so they can make
a much more targeted decision about patient treatments right there.
Exactly. Yeah, so on screen you can interact with
that patient data set and look at
the anticipated outcome of treatment decisions you want to make.
Yes, so as a physician or as
a nurse practitioner or
other mid-level care provider who are a lot of the clinicians who we work with,
I'm able to visualize the most likely glucose profile
with this patient based on the data that this patient's spend monitoring at home.
So RIMIDI is connected in to their Bluetooth enabled or cellular enabled device.
We're connected to technologies like health kit and other data aggregators.
And then, we do the modeling to show here on the screen,
what the most likely glucose values are at each point during the day.
And those are represented by these colored dots.
And now as I interact with the medications that the patient is
taking and for instance increase the amount of insulin that they're taking.
You'll see that the whole graph shifts in response to that intervention.
And so I can visualize the impact of that,
not only on their blood glucose but on
their hemoglobin A1C which is a long term measure of glucose control.
And that's quite important to the patient because we're helping
that patient also connect the dots between,
what I'm telling them today as their clinician
and what in my mind the anticipated outcome is.
And if we can help patients understand that
really understand what the goal of their therapy is.
We can also impact things
like adherence and engagement.
Sure, I think the friction
between a small company like ours that's innovative and a big
company like Cerner is always going to be speed.
So we can do things and
in you know on a dime and they can't and that's just their reality.
We were one of the first companies to come into the marketplace and so they were a lot of
processes still being put in place in terms of the agreements and the legal side of it,
that you know held it up longer than we wish it had.
But we understand that they need to standardize.
That's the goal of these marketplaces.
There's really a standard process for companies like RIMIDI.
What's been exciting has been to help them drive what some of that process
looks like and the fire resources they had available when we started.
I think greatly expanded and we've been able to have input on
that and help them understand how to
improve on the workflow that they supported
initially to make that better and better for their end users.
You know I think the biggest challenge right now is
it's always been market timing for us of you know.
First we need the platform companies to get on board and then we need enough of
their clients to be ready and actually be interested in deploying fire.
And that's finally happening this year,
I think 2017 will be the year where fire will become a reality
in the marketplace not just for early adopters but for the general market.
Part of that is you know driven by meaningful use
three requirements and the deadline coming up in January,
where a lot of the companies are leveraging fire to fulfill some of those requirements.
We're now leveraging what we've done with Cerner and with Athena
and we're building that out across other fire platforms
with the great hope that there will be minimal customization that needs to happen as long
as everybody is complying with the spec.
It's early to know that.
It's early to know at the individual customer sites.
How consistent fire resources will be as far as availability.
And will that differ from health system
to health system in terms of what they're allowing.
And then authentication is always the pain points.
I should have said that earlier that the fire integration and
exchanging of discrete data points is pretty simple.
The requirements around authentication not just
with the EMR company but with the individual clients is
definitely the heavier lift.
So, the response has been really terrific of having our capabilities
embedded in the EMR and I often say to
people I'd like for physicians to not even know we exist.
I'd like for them to think wow look what a fantastic feature Cerner has added.
And, so we're responding to that great feedback and saying okay,
how can we do this with other disease states?
We're rolling out a congestive heart failure capability
shortly and will continue to expand that across other chronic disease states.
Most of us can think back to a key role a
teacher played in shaping our world view or career.
In my case, one such person was Dr. Hiram Curry,
a general practitioner who retrained in Neurology and then founded
the first academic family medicine department
where I worked in one of the first ambulatory E.H.R. systems.
He taught me many things but one in particular is relevant to this topic.
He used to caution his residents that they would see patients for a few minutes
every so often and think that what they did
in those brief encounters would make all the difference.
He was fond of saying that what the patients did
between those encounters would actually make that difference.
You know that chronic disease accounts for most health care costs.
You also know that a root cause is often behavioral with poor diet and
lack of sufficient physical activity being key health determinants.
You also know that once patients get chronic disease,
their compliance with the prescribed treatments is a key driver of the outcome.
In the past, patients were often asked to maintain logs of diet,
activities or treatment compliance.
Today of course, inhealth technologies such as smartphone apps and the plethora of
wearable devices provide an entirely new approach
to the maintenance of health and the management of disease.
This domain of Health Informatics,
now often called mHealth,
seeks to use data from mobile apps,
standalone or wearable devices and other sensors to understand health and health stays
to inform health care actions and to change our behavior
in order to prevent disease onset.
It also uses the data to promote behavior change once disease develops such as
medication inherence and increasingly to
provide clinical treatment such as virtual physician visits,
disease management or cognitive behavioral therapy.
Does AM Health actually improve outcomes or lower costs?
A 2015 article, in the Journal of Medical Internet Research,
focused on AM Health as a tool to increase adherence in crying disease management.
The authors found 107 papers that met their criteria.
Of these, 41 more randomized clinical trials that measured the effects of
AM Health on disease specific clinical outcomes in conditions such as diabetes,
or chronic cardiovascular, or lung diseases.
around 40% reported significant improvements.
Based on this, the authors say quote,
"There is potential for AM Health tools to better
facilitate adherence to chronic disease management,
but the evidence supporting its current effectiveness is mixed."
You can see here,
in this graphic from that article that text messaging,
SMS, was the most commonly used tool in the primary platform.
It can facilitate patient provider communication,
medication reminders, and data collection and exchange,
on disease specific measurements.
As well as deliver patient education and motivation.
It has the advantage you're working on virtually all cell phones.
This can be particularly important in developing countries where
lower cost phones may be more common.
The next most common technology with smartphone apps,
often use to help diabetes patients remember to check symptoms,
maintain a food diary,
or connect to educators in real-time.
Next, where standalone wireless or Bluetooth compatible devices are those such as
a blood glucose meter that are connected to a phone for
automatic transfer of data for review by a healthcare provider.
In some systems, measurements that fall outside of the target range, trigger alerts.
Another issue is AM Health data quality.
A study in December,
evaluated 137 patient facing AM Health apps that were highly rated by consumers,
and recommended by experts,
and that targeted high-need,
high-cost populations based on a long list of medical conditions.
The authors found that quote,
"Consumers ratings were poor indications of apps clinical utility or usability,
and that most apps did not respond appropriately
when a user entered potentially dangerous health information."
End quote. They further found that, quote,
"very few apps focused on providing guidance based on
user entered information or support through social networks,
or on rewarding behavior change.
Functionality is likely to be useful to relatively more engaged patients."
The authors also note that quote,
"data privacy and security will continue to be
major concerns in the dissemination of AM Health apps."
End quote. This is an interesting,
but unfortunately not yet openly available study.
Another aspect of AM Health data quality is
the ability of patients to properly operate in-home devices.
They may incorrectly wear blood pressure cuffs.
Patients may hold an item,
steadying themselves against a wall or other object,
or wear substantially different clothing as they weigh themselves.
These issues clearly point to the need for careful training,
and devices that to the extent possible,
can detect such situations and coax patients to use proper technique.
Here in the U.S, The Food and Drug Administration or FDA,
is responsible for regulating medical devices.
The details are complex,
but the level of FDA oversight generally increases with
the perceived patient risk presented by the device.
Devices that perform the same function ha already approved predicate devices,
and do not introduce new risks or generally subject to minimal regulations.
Novel devices must go through a far more complex,
expensive, and time consuming process.
What about medical apps?
Given finite resources and the scale of app development,
it was clear that the FDA had to draw a line
to determine which apps it would even consider.
In February 2015, the agency announced plans
to only review mobile medical apps that interpret data,
and act like medical devices.
The agency says it will only regulate apps that present
a greater risk to patients if they do not work as intended,
or that cause smartphones or other mobile platforms to have
impact on the functionality or performance of traditional medical devices.
More specifically, the agency does not intend to regulate apps that help patients
self-manage their disease or condition without providing specific treatment suggestions.
Provide patients with simple tools to organize and track their health information.
Provide easy access and information related to health conditions or treatments.
Help patients document, show or
communicate potential medical conditions to health care providers.
Automate simple tasks for health care providers,
or enable patients or providers interact with
personal health records or electronic health record systems.
The FDA will also not oversee
the mobile devices such as smartphones and tablets which can run medical apps.
To a large degree,
this decision leaves quality control in the hands of app developers,
providers, and their patients.
We will now look at an example of mHealth that the FDA does regulate.
As shown here, a live course Kardia mobile device detects the electrocardiogram or
ECG heart trace and sends it to
the company's smartphone app using
inaudible ultrasonic signals after requesting access to the microphone.
The company says this communications approach reduces
battery consumption by around 92% versus Bluetooth,
and provides much higher data resolution.
However, it does require the device to be no more than a foot away from the phone.
A number of journal articles report on success in using
the AliveCor device and other competing devices to screen for atrial fibrillation,
the most common cardiac arrhythmia and one that can lead to
strokes if the condition is not identified and properly treated.
The company says it is working on an ECG band device for Apple's watch.
This interesting brief video from a live course founder,
suggest the company's future direction and
the growing importance of analytics in healthcare,
the topic of a later lesson.
AliveCor got started because of the invention
of a really brilliant doctor, Dr. Dave Albert.
His latest invention was a small device that is about the size of a stick of gum.
And this extraordinary device works with
your smartphone and allows you to analyze the EKG of your heart,
not a heart rate, not like you might get with a Fitbit or with a sports watch.
But the actual electrical rhythm of your heart which
is incredibly important to diagnose some of the more serious heart conditions.
Most people don't realize that heart disease is
the number one killer of men and women worldwide.
In fact, last year about 18 million people died from heart disease.
What's next for AliveCor is probably the most exciting part.
We are working on some extraordinary technologies using deep learning,
artificial intelligence that analyze the morphology of your personal EKG,
your heart, and detect things that previously were not available to human eyes.
The machines can see things about your health that were previously
undiscovered whether that be potassium levels or other measures of physiology.
We're just getting started on unlocking the secrets of your heart.
Unsurprisingly, interoperability of medical devices is a challenge,
both within and outside of hospitals.
A 2012, Association for the Advancement of Medical Instruments,
AAMI survey of 1,900 US hospitals,
found that interoperability issues were first and
second on the list of medical device challenges.
Specifically, they were integrating
medical devices and systems into the hospital's network,
which was cited by 72% of respondents.,
and integrating device data into EHRs,
which was cited by 65% of respondents.
When we looked at Health For you saw a plethora of devices used by patients,
each of them typically has its own proprietary data formats.
So Health For provided value by bringing that data together in one record,
along with other data collected from EHRs or documented by the patient.
In the past the vice data was often available only
via a portal maintained by its manufacturer.
And there might have been a charge to use it.
Continua Health Alliance founded in 2006,
is an international non-profit open industry group
of nearly 240 healthcare organizations and vendors.
Its goal is to establish mHealth interoperability in three major categories,
chronic disease management, aging independently,
and health and physical fitness.
Personal Connected Health Alliance is a non-profit organization
formed by the huge Healthcare Information and Management Systems Society HIMSS,
Continua, and the mHealth summit to bring together stakeholders to quote
realize the full potential of personal connected health end quote.
It now publishes and promotes the global adoption of
continuous open mHealth interoperability framework.
Human API and Validic are two interesting companies that have each developed
an interoperability platform for mHealth data from a wide variety of sources,
aimed at both patient care and wellness.
Both offer rest APIs to access their normalized data in JSON formats.
I have posted links to their sites where you can see how this works.
Note, that the results may come back in a JSON format,
but not yet in an industry standard format.
Open mHealth is a new nonprofit organization that promotes
greater access to mobile health data through an open standard and associated tools.
Similarly to FHIR, the open mHealth standard uses rest APIs
to access data package according to Json based Schemas.
Essentially, the equivalent of FHIR resources,
but with important differences because of the special challenges of mHealth data.
Here's an example of part of the open mHealth schema for blood glucose.
In FHIR, this would be an observation resource.
I have placed a part of one of those adjacent to it.
I used smart and FHIR's frame tool to create the sample resource.
The important point is that things included in Open mHealth but not in FHIR.
I've highlighted those in red here.
First, you see that the Open mHealth glucose reading can occur over time.
In this case, a four month period.
In clinical practice, it would be a point reading
usually when the patient is in the physician's office.
So, FHIR does not anticipate a situation like this.
As we said, mHealth data has special challenges.
And this illustrates one of them, volume.
A diabetes patient might document their blood glucose daily.
They see their physician every four months.
Does that physician want to see all 120 data points?
Almost certainly not.
So Open mHealth is indicated here might provide an average for the four month period.
For blood pressure, this might be the maximum and minimum over some time period.
Another mHealth challenge is data context,
when and how was data collected.
This should be clear in a physician's office,
but it may not be when the patient is at home.
Here, the Schema provides contextual information
showing that the patient takes their glucose reading upon waking and before eating.
Physicians usually do something similar when patients visit their office.
Calculated metrics illustrate another challenge,
the accuracy of mHealth data.
Step counts is a good example.
Fitbit provides a discussion of
their step count calculation approach that says in part quote,
"Fitbit trackers uses a 3-axis accelerometer to understand your motions.
By analyzing acceleration data,
our trackers provide detailed information about frequency, duration,
intensity and patterns of movement to determine your steps taken,
distance traveled, calories burn and sleep quality."
Of course, another device might receive different input from its sensors,
and might do the calculations somewhat differently.
To test the second point,
I have long had two activity tracking apps on my phone.
The numbers seem to vary by around 1 percent,
and the app with a higher number is not consistent.
My two apps are on the same phone,
so they presumably receive the same data from it.
This admittedly nonscientific comparison by
CNBC shows far greater differences in step counts
among nine wearable devices where
both a sensing technology and the calculation might be different.
I provide a link to an article from
The Journal of Personalized Medicine if you want
more details about the accuracy of mHealth data.
To better understand the rich possibilities of the standard and the in-house space,
I strongly suggest you spend time studying the Open mHealth schema library.
You can also further explore
the somewhat different perspectives of Open mHealth and FHIR.
Earlier, I mentioned that in addition to its schemas,
OpenAM Health provides useful tools.
One of these might be of particular interest to students of this course.
It allows users to specify a dataset they want generated using YAML,
a data serialization language designed to be
both human-readable and computationally powerful.
This example asks for body weights over
a particular date range and with specified starting and end values,
standard deviation, and minimum and maximum values.
OpenAM Health also provides a library of
visualization tools to use once the data is generated.
This example, plots both minutes of physical activity
and step counts and is scrollable to vary the time period covered.
Earlier, I mentioned Human API and Validic,
two companies that offer
their own proprietary platforms for integrating AM health data from multiple sources.
OpenAM Health has developed Shimmer,
an open source tool to pull health data from popular third-party APIs,
like Runkeeper and Fitbit,
and convert it into an OpenAM Health-compliant format.
The tool is of obvious benefit to app developers since,
somewhat similarly to FHIR,
it allows them to develop independently of the underlying data source.
Currently, the number of data sources is small compared to the commercial platforms,
but OpenAM Health says it is working to add more.
It also offers Pulse to map HL7 messages from EHRs into OpenAM Health's schema.
Apple's HealthKit demonstrates the growing importance of AM Health.
HealthKit stores data from iPhone and Apple Watch apps and from
some devices in an encrypted database called the HealthKit store.
The data is only accessible via the health app,
through which users can view, add, delete,
and otherwise manage all of their health and fitness data.
Importantly, as shown here,
they can control fine grained permissions for the sharing of each data type.
Users must explicitly grant each app permission
to read from and write data to the HealthKit store.
Users can grant or deny permission separately for each type of data.
For example, a user can allow an app to read their step count,
but prevent it from reading their blood glucose level.
To prevent possible information leaks,
an app does not know about denials and from the app's point of view,
data for which it lacks read permission does not exist.
Once an app has been granted permission to access data in the store,
it can use OpenAM Health's Granola tool to store it on a remote server for analysis or
backup or to serialize the data which is
only stored in the HealthKit store for a limited period of time.
Granola maps and validates the HealthKit API to OpenAM Health's HealthKit JSON schemas.
Here's an example of that for step_count data from HealthKit
converted by Granola into OpenAM Health compliant JSON.
I'm Gary Clifford, I'm the interim chair of biomedical informatics at
Emory School of Medicine.
I think it's a lot of things to a lot of different people.
My own thinking is that it's where biomedical engineering meets information theory.
It's all about how do we push information around and it can be anything from
genetics through to mHealth.
I mean, you can see where we're going.
We're going to the cloud infrastructures, distributed computing,
the volume of digital data and the velocity of
digital data is just increasing exponentially and
anybody not working in the digital domain is stuck firmly in the 1970s, 1980s.
So we're either going to go backwards or we're going to go forwards.
And I think we have to go forwards, don't we?
That's the place we need to be investing.
What excites me about it
is people are generating these data and they're generating
them on an enormous scale in a very natural way.
It's a natural instrument that we interact with and it
has all the qualities that we need in a device for capturing data.
It has this suite of senses,
it has direct connections to the Internet,
it identifies the individual very specifically,
which is one of our biggest problems in medicine,
is knowing whose data belongs to who.
And it has enormous computational power on it.
I remember when we first started looking at
using phones in medicine and thinking about its potential.
You could see where it was going and you could be frustrated by the current systems,
the very early smartphones,
but you could see where the computational power is going.
Now the phone in my pocket is about
five or six times as powerful as the PC that I wrote my PhD thesis on.
So, I'm eternally excited
about the idea of this distributed computing power that we have in
our pockets and the ability for it to push data into the cloud for us
to continually track the behaviors and the healthcare,
the health of an individual.
Unlike a medical device
that you put on an individual,
a phone isn't FDA approved for medicine.
So it's difficult to use it in any validated sense.
And the reason for that is very important.
The reason is that it's a heterogeneous collection of different platforms,
it's not one device.
When you have a medical device and you put it through FDA approval,
they certify that this particular device,
running this piece of embedded software will produce the following results,
and therefore it's safe under
these conditions and it should be used for the following types of medicine.
Now, we're talking about using
these enormous heterogeneous hardware platforms
running constantly evolving software and operating systems.
The idea that you could ever come up with
a close predictable software system that the FDA would approve is a long, long way off.
So what you have is this idea that either you have to tailor it to an individual,
or you have to aggregate across large populations.
At least that's where we are at the moment with mHealth.
So, I suppose the goal at the end of the rainbow that we're chasing is
how do you provide quality healthcare information from this type of platform?
I think there's two really good examples at the moment.
There's two areas where I feel mHealth has great potential.
One is in low to middle income countries where it's sort of a tabula rasa.
We have no digital health care system or very little and
it's often a highly distributed non-centralized health care system.
So having the ability to mediate data
personally is going to be an enormous leap frog effect in health care, potentially.
So, we have a project down in Guatemala at the moment.
I just came back yesterday,
in fact we're wrapping up an RCT down there, Randomized Control Trial,
looking at the potential to use a smartphone by illiterate lay midwives.
So these are essentially women who
move from village to village looking for, by word of mouth,
for pregnant mothers and offering them help in the move through pregnancy to childbirth.
We've taken a group of 50 midwives working with an NGO.
Of course you have to work with a local partner who
already delivers a standard of health care,
and we've provided training for a smartphone
with a low cost $17 ultrasound device that plugs into the smartphone,
and a blood pressure cuff.
They screen the women monthly and they're looking for preeclampsia, high blood pressure.
They're looking for abnormalities in
the heart rate variability that are indicative of interuterine growth restriction.
This is actually a machine learning algorithm that we developed to identify our UGR,
interuterine growth restriction and also to refer
the patient on in the event that any emergencies occur.
The app is built as a series of culturally appropriate pictograms.
So we work with an anthropologist who just turns out to be my wife,
who has helped us design
the culturally appropriate interface for the largely Kaqchikel speaking,
this is an indigenous Mayan language,
Kaqchikel speaking group of midwives and all of the support system,
all the help files are spoken in Kaqchikel and all the data is recorded in Kaqchikel.
There's no written language actually for this,
which makes IAB approval for it quite difficult,
but it's a fun system to build because you're basically
building a decision support system for an illiterate group.
The intervention comparison, so the other arm of the intervention
is simply the same pictograms printed on
a piece of card and then laminated so that it's waterproof,
and then we train another group of midwives to use,or
traditional birth attendants to use
that laminated cardboard as a decision support system.
So it directly testing is a technology based on a smartphone that
connects a decision support system straight through to a health care system.
More efficacious than a dumb phone or feature phone with the number
programmed into it and a cardboard with the same decision support mechanism in there.
I can't tell you the results of that,
because we're only just wrapping up the RCT at the moment,
but the informal numbers show that there's been a significant impact on the population.
The question of whether you can take people
with very little exposure to a smartphone system,
although they do use quite complex phones themselves,
and use that in a healthcare setting,
there are strong indications that that's entirely possible and in fairly large numbers.
So that's a pretty exciting one.
We have an enormous potential there.
We're connecting the phone directly through to an electronic medical record system,
which is an open source system.
The entire thing is built on open source technology
and the price point is extremely low for the entire system.
So that's got me really excited.
You know the idea that we can transform health care by providing these enablers,
but there's another layer to it that's really exciting I think.
When you take a smartphone system.
You don't just have to give information to a user,
you're capturing information from them at the same time.
So, these lay midwives have lots of
local cultural knowledge about
how receptive the mothers are going to be to certain treatments,
and even down to the points of different colors mean different things in medicine,
and there are hot colors and cold colors,
and some illnesses or medical conditions are hot and some are cold.
And if you use the wrong color,
then it no longer becomes trusted.
So, having the right cultural approach to something is very important,
and we can capture this information back from the midwives at the same time because they
can create logs of what does and doesn't work as they're moving through this process.
So it's a continual system that we built with the midwives.
We learnt from them,
we adapted to their own cultural practices,
and they became an inclusive part of the construction of this.
And so, I think that's where we're going with mHealth.
It's not this didactic patriarchal western medicine where we just say,
here's the drug, here's the app.
Now you give me your information back and I will give you the cure.
I think it's going to become an organic system where we're feeding information back,
and we are learning from the user.
It's also got the potential to create
a distributed system that allows users to pass information between each other.
So now you could have different midwives having social conversations through
the phone and exchanging
information about- I'm not saying we're doing this at the moment,
but this is the next step I think.
They can interface with each other,
exchange information from a support network,
and we can capture this information at the same time and
work out what's working, what's not working,
and even ask each other to diagnose problems when we don't have
the bandwidth for the centralized doctor
or nurse to provide the clinical information they need.
So I think there's an evolution to mHealth that is coming that is
somewhere between distributed computing and crowd sourcing that is going to
allow us to harness
the local knowledge of individuals and the wisdom of the crowd if you like.
Sure, this is just as exciting to me actually,
and it's a home grown project in that it's a
U.S. based project in Atlanta primarily,
but we're expanding it to the southeast.
We last year we got funding from the NSF to
realize a project that we've been hatching for a couple of years now.
About two years ago,
Dr. Herman Taylor is the head of the cardiovascular research institute at
Morehouse School of Medicine came to me and said that he wanted to expand and build
an e-cohort of
African American pre CBD cardiovascular disease subjects.
And he had run previous to this the Jackson heart study which is
the largest cardiovascular study of African American subjects anywhere in the world.
And this had been ongoing for 20 or so years,
looking at the evolution of cardiovascular disease.
And one of the things they had done as part of this
was to bring people from the community
in and train them in concepts around cardiovascular disease,
and they became part of the study group that was studying the population as well.
And this is as you probably know,
a difficult thing to do in disadvantaged communities in the United States.
So you know the more disadvantaged you are,
the more marginalized you are as a community,
the more likely you are to have health issues.
And in the United States as in many places,
these communities have often been unfairly experimented on.
You know we have the- that's a very modern euphemism for what's going on in the past.
So if you look at things like Tuskegee and
many other abhorrent things that have occurred in
the past where the establishment has experimented on disadvantaged populations,
you can see that there's an enormous distrust of
these populations for people like myself or anybody who
represents some figure role authority to
come in and ask people to give up their data and become part of a study.
So we we had talked about how we would do this with eHealth and mHealth in
a new population primarily looking at younger African Americans in Atlanta.
And we talked about how we could build an app ecosystem,
and an open source infrastructure that would not only
be available to the communities that we are hoping to monitor,
but we would actively involve them in learning how to
program and how to become part of the project to
empower them to be able to produce code for
themselves which would increase their economic situation.
They would also learn about health care at the same time,
so they would improve their understanding of their own bodies and their own healthcare,
and they would also be empowered to be
a part of an open source community and
an open source project and give back to their own communities.
So the idea was to bring these communities in and make them part of this project.
And we're just at the point now where we realize we've got the funding for this,
and we're working with the communities.
We've been to multiple community coalitions
to look at how we would sensitively recruit people into this.
And this weekend actually,
we're running an idea on why we're bringing in hundreds of
local potential participants in this to work with us on ideating around the app,
what they want it to look like.
We're actually collecting what they want the app to do.
We're collecting information on what geographic location,
activity, sleep movements, what restaurants they visit,
what pollution they're being exposed to.
There's no end of what you can pull from somebody's cell phone.
But the question is, will somebody give us this information?
And there's a cyber security issue around this.
How does somebody even trust you when you know pretty much.
The question isn't will I get hacked?
It is what will I do when I get hacked?
That's the question nowadays around security.
So, how do you get somebody to trust them to allow you to use this kind of system.
So, we're building this with the communities,
we're going to train them how to,
and we already are training them how to code on
this platform and become part of it to understand the language that we're coding in,
and what information we're actually asking people to give
us in order to do this kind of longitudinal study in cardiovascular disease.
So, this is something that's really exciting to me,
that it's a new way of doing research.
I think it takes participatory research right to its limit.
We actually want people to take the platform,
take ownership of it,
build companies out of it,
and change their health and economic status as a result of it.
That's pretty ambitious, but I think we have a great team around it,
and I'm excited to see where we can take it.
So I'm Felipe Lobelo,
I'm a preventive medicine doctor and I work at the Emory School Public Health,
the Hubert Department of Global Health and I direct
the Exercise Medicine Research Center.
The mission really is to evaluate the implementation of the Exercises Medicine in
Global Initiative which in a nutshell is
trying to make physical activity part of health care.
Really, when you think about
main risk factors for chronic disease and mortality around the world,
inactivity has been sort of overlooked.
And what we're trying to do here is to make sure
that physicians and healthcare systems assess
patients physical activity and provide
some recommendations or counseling to help them improve physical activity.
And as a result, improve your health.
Absolutely, so we see mHealth and patient
generated data as really
critical to the implementation of the Exercise Medicine Initiative.
For the last few years,
some healthcare systems have started implementing
physical activity questions in their electronic medical records,
but as many of you know,
there's a lot of action around using
wearable devices to objectively measure people's physical activity level.
And some health systems are starting to
pilot test implementation of these data to guide clinical counseling.
Now, these are really early stages in this period and there's a lot of questions.
We typically refer to this as the Wild Wild West of mHelp because issues around validity,
and privacy, and interpretation of the data,
and interoperability are really at the cross of making this routine care.
Yes, there's a number of initiatives and groups that are actively
working to solve some of these issues and to improve not only the quality of the data,
but also the use of it.
So in terms of the quality and the standardization of different devices,
there's a number of projects going on that are trying to essentially assess,
no the mean error,
which devices are more accurate than others.
There's also different use cases depending on
the clinical population you may want to choose one device over the other.
There's really no central repository of these data or these recommendations,
but the American College Sports Medicine,
the CTA standards section,
the American Heart Association and others are
actively working to solve some of those issues.
At the end of the day like any other measurement in clinical care,
in medicine, is not going to be perfect,
there's going to be some error.
But we think that at least the process needs to be streamlined and so,
critical aspects around data standardization need to be in place.
Yes, so I was lucky enough to connect with a group of brilliant students that had
a passion for this area and also the knowledge and the
expertise to at least start to solve some of these problems.
So, one of the issues that we have is that,
there is sort of bring your own approach to patient generated data.
In some cases, a clinician may want to prescribe if he will,
a certain device to assess activity,
but for the most part,
this is a consumer oriented industry and patients are going to have
a device and they want to have that data provide some deep,
taking into account with clinical counseling,
so the main aspect of the project the students worked on,
was to try to integrate different sources of
data from different devices into the electronic medical record.
And also, make sure that
the critical useful aspects of
the data are being presented to the clinician in a simple way.
Because as you know,
these devices collect a lot of data.
There's a lot of noise and you really want
the meaningful use aspect of this to become what gets integrated into FHIR,
so that was the main objective of that project.
Yes. So essentially, the students were able to capture the data on the back end of
a few wearable devices that we identified as being
accurate and appropriate for
these different use cases and in lifestyle medicine and counseling.
And then, we made sure that the data was
transformed in a way that was connected to public health guidelines.
Typically, these devices collect steps but
the recommendations from the CDC and
other public health organizations are not really around steps,
are around minutes of physical activity per week.
So, we made a transformation of the students work on transforming
that data from different metric steps into minutes of
moderate to vigorous physical activity and draw a line
or set the standard for what is the appropriate weekly dose,
if you will, recommended by
public health organizations and make sure that that visualization aspect of
the data was clear as we intend to migrate this data into electronic medical records.
So here you can see that once the data is
being capture from the back end of the wearable device that we selected,
then it needs to be transformed from the metric
that the device uses into minutes of physical activity per week.
And then, you have weekly,
daily data being captured.
And then, you have to combine the daily data into a weekly metric.
Because, the volume of activity per week is the recommended public health guideline.
So, when you combine weekly data into,
or daily data into a weekly standard of
then you can see a line that essentially helps a clinician identify if for that week,
that patient met the recommended dose of activity.
In addition to the total dose of activity per week,
you also have the intensity of activity.
So again, the recommendation is for 150 minutes of moderate,
or vigorous exercise, or physical activity.
And in essence, vigorous minutes count twice.
So, plus part of this project,
the metrics need to be adjusted so that
minutes of moderate intensity activity are combined.
And you can see here in a different color,
with minutes of vigorous intensity activity in order
to come up with the recommended public health metrics.
So, using different visualization aspects, colors,
a threshold line that helps the clinician
identify what's a dose and whether that patient is meeting that dose or not.
Should be able to simplify the process of
interpreting that data in leading into the counseling,
that the clinician can provide to that patient.
My pleasure Mark and thanks for inviting me to work with this class and your students.
It's a great opportunity to combine different expertise
and issues around the interoperability
of mobile health and looking forward to working in more of these projects.
So, I'm Jim Rehg. I'm a professor of
Computer Science at the School of Interactive Computing at Georgia Tech.
And I work in computer vision and machine learning,
and I've got an interest in human behavior.
Sure.
So, the goal of behavioral imaging is to be able to measure,
analyze and understand human behavior using sensors and machine learning.
And the idea is to go from current qualitative understanding of behavior based on
human observation and ratings to really be able to objectively
measure behaviors as they're being produced in the real world environment.
And this involves a lot of sensors and a lot
of analytic methods to analyze the data produced by
the sensors and ultimately build models of behavior.
Sure.
So, for example,
one of the things that we can do recently that's become feasible and
realistic is to allow people to wear
cameras as part of going about their daily activities.
And we see this in a variety of settings with sports enthusiast.
And we're beginning to see this more and more in other settings,
social settings and so forth.
And so we have an effort where we're using individuals that are caring for children with
developmental conditions and those individuals
can wear a pair of glasses that contain a camera,
and that wearable camera allows us to see in the video what the child is doing as far as
how they're expressing themselves socially and
any lack of social interaction or social expression.
And we've got some technology for quantifying
a particular element of their social interaction which is looks to the eyes.
So eye contact is a critical part of social interaction.
And with this technology, we can actually measure quantitatively how
frequently and for how long will children look to the eyes of their caregiver,
and that becomes a quantitative marker or
measure for a child's social behaviors as they evolve
over time through development.
Right. So definitely, there's a lot of interest around understanding how to get
behavioral measures which really speak to
an individual's daily life experiences into the care process.
If you think about mental health and in general,
there's a lot of difficulty in getting beyond the self-report,
where you ask a patient,
what have you been experiencing? What are your issues?
And so, we do think that these new sensor-derived measures could
become a way to allow a care provider to get a richer,
more fine-grained picture of how
a patient's state of mental health might be evolving in time,
getting better or getting worse.
And so then, there's this question about how that data could get
into the point of care through a system like FHIR,
which would essentially mean a need to understand what those specific sensing modalities,
how they're characterized, and then how they would fit into other more,
let's say, electronic health records types of information.
Yeah.
So I think part of the challenge there is to think about
the granularity of the data and the levels at
which you might want to access the data and expose the data.
So you think about a very fine-grain level
which might literally mean specific bouts of eye contact in
the context in which they were produced which might be useful for someone really trying
to understand in great detail a child's behavior in a particular setting.
You could also think about a summary score,
a measure of social interaction skill
that could be derived from a variety of measures not just eye contact,
and that could then become more of
a summary statistic that might be reported in a different way.
So, I think having a sense of what are the levels of granularity of the data and then
defining APIs that allow people to access those different levels in appropriate ways,
that would be the way to move forward.
But I think, we're still quite far at this point from understanding exactly how
these sensors will fit into care in specific cases like autism or mental health.
And then it's another step I think to get that into something like FHIR.
Sure, sure. So I think,
if you think about measurements of behavior and
how they might play out from the patient's point of view,
then there's at least two dimensions you can consider.
So one is a kind of opportunity for reflection.
So you have a summary of your behavior.
Let's say there's a behavioral goal that you have.
Maybe you're trying to quit smoking, for example.
So then you might have a case where there's
behavioral measures being obtained not just with glasses and cameras,
but with wearable sensors as well.
And you might imagine distilling from those measures.
Summary is a little interesting,
and piece of information that an individual might not be aware of that
might help them better understand how their behaviors affect their health outcomes.
So that could be reflected to the individual in a course granularity.
The other thing you might think about are actually mobile interventions.
So the ability to take a data item that you've obtained in the field during
someone's daily life and then use that to
assess their risk for some undesirable health outcome.
And in that case, you could think about
immediately acting on that information and thinking about
how you might intervene or provide that person with some supports in real time,
in the field that might then help them maintain
their health-related behaviors or prevent unwanted behaviors.
So both of those reflection and intervention could be supported.
Right.
So, behavioral imaging really started out with a kind of analogy to medical imaging.
So we would look at behaviors.
Particularly, we're looking initially at children with autism and
very complex behaviors around a childhood development disorders.
And we made the analogy that we want to move from a qualitative characterization of
children's behavior that currently is the state of
the art to a data-driven, very quantitative assessment,
and we made the analogy to medical imaging that succeeded in
taking qualitative states of disease and risk,
and really quantifying more precisely the patterns
of disease progression and the factors that influence them.
And so, that led us to this notion of
behavior as a construct
that you could image and you can model, and you can understand it.
And then in parallel with that,
there's been this community of folks in
mHealth which have been focused on the mobile environment,
how to get out into the real world and understand what's happening in real life.
And so, I see these as two threads that are converging,
and I think this notion of imaging is valuable as
a perspective as well as this notion of mobile health.
So we see, behavioral imaging is sitting inside
this larger umbrella of mobile health which embraces many different aspects of
mobile health-related behavior and really focusing on
the behavioral components specifically.
Absolutely, and I think
the challenge there is really to understand how context should be quantified,
and how it can be reported back.
You obviously can't. The physician doesn't
want to relive a person's life, their patients lives.
You have to give them some distilled,
essential pieces of information.
And that's really the challenge we face, I think,
is to take all the data that's available in the contextual space
and distill it down to a small set of things that are really informative and valuable.
And that, I think, is the research enterprise
we have ahead of us for the next several years.
So there is a number
of activities that are happening right now that are building toward the near future.
One effort is around building infrastructure.
So we're currently working with some collaborators at other universities in Hershey,
Memphis and other places through some NIH grants.
We're trying to build out a kind of infrastructure
for collecting a variety of different signals and
organizing them and extracting information from them and then
showing the ability to intervene in the field.
So I think we'll have some evidence over
the next couple of years of the ability to support
real-time sensor-triggered interventions that might be
the basis for a real change in health outcomes for certain conditions.
Looking ahead, I think what you really want to look to is progress on two fronts.
One is increasing standardization and
understanding around which signals are really valuable,
what is in fact the most effective way to collect them and
analyze them and get information from them,
and really moving toward standards for some of
these mobile health signals that will ultimately be of value.
And the second direction I think is really the integration of
these modalities with other capabilities for understanding health-related factors.
So integration of genomics data, for example.
So patient of genomic risk that sets them up for certain outcomes.
We're now having increasing the ability to do sequencing and understand
those states of risk well in advance of any diagnosis.
So that's a piece of information that we are currently not really
integrating with mobile health data but I think it's really important to go that route.
And then another thing you might think about is understanding a person's environment.
So drawing from other what they sometimes call digital traces,
other examples that give a context,
whether it's your social media or whether it's other aspects of your SES and so forth,
that could play a role in providing context for health outcomes.
So I think the next step is really to pull these different disparate sources of
information together and then make progress on the sensing front.
We also, by the way,
need battery life to increase and we need the sensors to get smaller.
So the things that are happening now need to continue to happen to pull
all these things together.
My pleasure.
In this lesson, we will shift our attention to public and population health.
Unlike the clinical setting,
where the focus is traditionally on
individual patients after they become sick or injured,
public and population health focus on groups of patients or the public at large.
These can be as small as
a local neighborhood or as big as an entire country or region of the world.
We will begin this lesson with the discussion of
public health and then discuss population health.
In a landmark report,
the Institute of Medicine define public health as,
"What we as a society do collectively to
assure the conditions in which people can be healthy."
Note the emphasis on collective action.
This is a recognition that complex social factors have a powerful influence on
our health and that we require
disparate data sources to understand
the impact of many determinants of health and disease.
Also keep in mind that the World Health Organization,
a globally recognized public health organization defines health as,
"The state of complete physical, mental,
and social well-being and not merely the absence of disease or infirmity."
From an informatics perspective,
many aspects of public health are similar to population health in that both aggregate,
analyze, and report on data as shown here.
Public health takes a broad view of the factors that influence health,
where you live and work,
the social norms of your culture,
the types of health care you have access to,
your exposure to diseases and stressors in your environment,
among other influences, to create this broad view.
Public health uses disparate data sources to
fulfill its core functions and essential services.
Traditional health care is oriented around treating disease.
Once that occurs, public health professionals try
to detect and prevent problems from happening or recurring.
The Centers for Disease Control and Prevention, CDC,
is the federal agency charged with protecting and improving public health,
but it generally does not collect surveillance information directly.
Rather, the US public health surveillance system relies on
established partnerships with more than 3,000 local agencies.
CDC works through these agencies to collect,
analyze and share data that address
the many factors and determinants of health and disease.
Since the key mission in public health is data aggregation and reporting,
inter-operability is obviously of great importance.
This is particularly true here in the US,
given the large number of reporting agencies in this country.
Globally, ministries of health are
the key agencies responsible for tracking cases of human illness.
Other important partners are community organizations,
the health care delivery systems,
schools, businesses, the transportation sector,
the media and other government agencies.
Data from public health surveillance
inform policies and direct decisions about resources for
services that promote healthy lifestyles and control the spread of infectious diseases.
Another major aspect of public health is promoting health care,
equity, quality, and accessibility.
Given the importance of inter-operability,
FIHR could potentially facilitate data aggregation and as we will see in what follows.
Public health experts increasingly see FIHR as an important health informatics tool.
CDC describes its mission as protecting America from
health safety and security threats wherever they originate.
We will now learn more about the CDC and
its mission and how informatics plays a key role in public health.
Thanks Dr. Granstein for having me and I'm happy to join.
I'm Chelsey Richards at CDC.
I'm the Deputy Director for Public Health Scientific Services,
and I also direct the Office of Public Health Scientific Services.
Sure. So I am a physician.
I'm an internal medicine physician and geriatric physician.
I started my professional life after medical school and residency in a medical school,
running a division of general medicine and seeing patients.
I saw about 70 patients a week.
And I think after several years of this,
I noticed that patients from rural Georgia were coming in with health problems,
were they had never had any preventive service for that, or any screening.
And it led me to thinking more about there ought to be ways to intervene beyond
just the intervention at an individual level which I did as a clinician,
but more at a population or community level,
and that's what brought me with an interest into public health.
I went and got additional schooling,
a Master's in public health.
And then, came to CDC as an Epidemic Intelligence Service officer,
which a lot of people at CDC come in.
And for that two year fellowship, we went,
we got sent all over the place to investigate disease outbreaks.
I went to Los Angeles.
I went to South America,
I went to Japan, I went to Taiwan.
In really investigating sort of an emerging problem,
being able to quickly identify what the causes were and intervene.
And that was very fulfilling and has really been why I've stayed
in public health the last 20 years.
Well, CDC is a federal agency.
It's located in Atlanta. It's the only federal agency
that's headquartered out of the Washington D.C. area.
We have about 15000 employees and a large budget.
And we have staff in every state in the U.S. and 60 countries.
And our mission is, to protect the safety,
health safety of Americans and globally.
And also, to promote prevention and health promotion.
Well, public health surveillance,
is the foundation of everything we do in public health.
And really what it is, is collecting data,
health data, to understand the burden,
the trends and what interventions really impact on health.
It's key to our preparedness as a nation to prevent health safety adverse events.
It's also key for understanding trends like obesity and other chronic diseases and what
interventions help us ameliorate these chronic diseases.
So public health surveillance,
as we were saying, is the foundation.
That data is the foundation of what we do in public health,
to know when to act,
where to act, what to do.
And most of our data in public health surveillance comes from the health care system.
And historically and traditionally,
that's been often a paper process,
where a doctor has to fill out a form by hand and
then maybe send it by mail or fax to a health department.
And then, a health department takes that and has to put it into a database to analyze it.
We're moving rapidly with electronic health records to an all electronic environment.
And I think the exciting thing for public health is that,
the speed with which we can get data now,
allows us to take much quicker action to prevent disease outbreaks,
or to address in local communities specific pockets
of health problems or health conditions or diseases.
So I think, electronic health records and the ability to move data in
a digital format very fluidly between local clinicians,
hospitals, their local health departments,
their state health departments and CDC,
it's going to revolutionize the way public health can really protect
and support health promotion.
So, what this diagram really illustrates is the interconnectedness between health care,
public health, and many of the social factors that influence health.
And CDC and state and local health departments sit in that interface,
between the clinical system and the social,
what we call the social determinants of health.
And I think, what inner informatics and electronic health records
have the opportunity to give us,
is much better data moving between these various parts of the system.
So for example,
a huge public health problem we have in this country is the control of blood pressure.
We have about a third of the country has high blood pressure and
really controlling blood pressure is going to be so
critical to decrease deaths from heart disease and stroke.
Well, there's a clinical portion to that,
which is a doctor being able to recognize high blood pressure,
being able to prescribe medications for a patient to
take those medications and get blood pressure under control.
And that's information and data that's generated in the clinical system.
And health departments are very interested in that.
But we also know that things like,
access to good food, income, housing,
occupation, work, there are a lot of social factors that influence
on a person's ability to have normal blood pressure.
And having more data which has been lacking for public health and for clinical medicine,
more data about that,
is going to help us understand,
where interventions in those social determinants
might have an impact on a particular help problem like high blood pressure.
Likewise, we understand, that for clinicians and for health departments for example,
with high blood pressure,
there was a medication that has to be prescribed
and we have to ensure that people are taking those medications.
And so, some of those data streams from pharmacies and from
other sources and increasingly from wearables that people,
devices that people wear that would monitor blood pressure.
As that data becomes available to the health care system and
public health it enables both of us to be able to
do more to get people to normal blood pressure.
So that's just one example of a health problem that is going to be
impacted dramatically by this movement of data,
from the various sectors I've discussed.
Yes. So, public health,
the foundation of public health is data and
surveillance data and analytics have been critical for
us to advance our understanding of health and to intervene and improve health.
Epidemiology has been sort of the bedrock science within public health.
And traditional epidemiology looks for data to support causality of disease and then,
where trends of disease are going.
I think we have lacked in public health and in clinical medicine,
the ability to look at data in a big data context and really
be able to integrate all these various streams of data just mentioned.
And so, I think we're just beginning to learn in public health,
sort of the types of tools that are going to be needed,
in order to turn these vast amounts of data into knowledge that we can use.
And one thing that's critical to understand about public health and
the work that CDC does is that,
the work we do around data and analytics is not just to generate knowledge,
it's not just research.
But it's really data for action.
And we really have to take action at a local level,
at a regional level, state or national level or global level,
on the data analytics that we use.
So, as we become more comfortable with the big data analytic tools,
I think it's going to enable,
unleash a whole set of opportunities for us to
take better action when it needs to be more precise,
or bigger action globally, to really improve health.
One challenge that I'm concerned about is, signal to noise.
And so, when we think about big data analytics for example,
finding a signal in those big data may be
an important finding for us to be able to intervene early.
But what if it signals not quite right?
What if it's an association with a health problem,
but it's really not causing the problem?
And so, a lot of our work in epidemiology and surveillance is really not only
looking for associations between a signal and a disease,
or an outcome, but ensuring to
some extent that that signals really related in a real way,
because we're going to take action on that.
And so, that signal to noise problem is I think a real one.
I think, there are tools within
data analytics that will allow us to understand that better.
Machine learning, and other approaches
we're going to have to become more comfortable with,
to really harness the value there,
but that problem is going to still be one we're going to have to deal with.
I think another big issue that's relevant to your class and to the students,
who are taking these courses, is the workforce.
Most of our workforce and public health have been trained on
very traditional epidemiologic and other data analytical approaches.
We need a new fresh workforce that's going to have the tools
and experience with some of the newer tools of bigger data analytics.
And I think, how we bring people into public health is something I think about every day.
One thing that separates us from maybe the private sector,
we don't have maybe some of the incomes,
but we have a mission that is really compelling.
Because everyday, when we come in to work,
we're trying to save lives.
We're trying to prevent disability.
We're trying to promote health.
We're impacting not only people in our community,
but people all over the world.
And so, people who come to public health and really love it,
are there for that mission.
I think, one of the things that has been striking
with fire is the good enough syndrome, I would say.
We have in public health a tradition of wanting to get things just perfect,
before we're comfortable with the way collect data.
And that delays our ability to get the data we need to take action.
And so, what's nice about fire in the modular concepts that are embedded in fire is,
we can get going. We can get data.
And as we learn more about a condition,
and many of our health conditions or disease outbreaks or epidemics are evolving,
so we're learning all the time.
We can improve that standard with other modular pieces and get more refined data,
but we don't have to delay our ability to get the data before we have it perfect.
So, the perfect is often the enemy of the good.
Let me try that again. The perfect is often the enemy of the good for us.
And I think fire fits into a model,
where we really need rapid data that we can analyze and act on.
So, I think that's a fantastic question,
because I've talked mostly about data,
but the other side of public health is this action that I keep talking about.
And I think apps offer us an opportunity to not only
harness the data that's there to tell us something about health or disease or epidemics,
but to immediately act.
To be able to send information back,
and tools back to that clinician to take action in the office.
To send it to public health.
To have information that can be from a local health department,
or a state health department.
Refine and into the hands of a clinician to be able to
counsel a patient on a health behavior issue.
So I think, apps really are an important part of the future for intervention,
which is again key to what we do. Great, thank you very much.
Sure, I've been at CDC for a little over 20 years.
I started in the Epidemic Intelligence Service Program,
and I've really spent my career at CDC working on surveillance issues.
As you probably know,
public health surveillance is really the cornerstone of the work we do.
We need good data in order to make decisions about preventing diseases,
controlling diseases, interventions, et cetera.
So, I've really enjoyed working on surveillance issues,
and today we're going to talk to you about one of our big national programs.
I started with CDC as a public health advisor for a short period of time,
but I end up redirecting my career at the state level.
I worked mainly with Georgia and Virginia,
and then with a organization called
the National Association of County and City Health Officials,
before I returned to CDC.
And most of my career has been in surveillance as well.
Well, syndromic surveillance has been around for a long time,
but it really got its start after 9/11 and the anthrax attacks.
And the purpose at that time was to use emergency data,
data from emergency departments,
to look for those first instances of a bioterrorism attack.
That was really the reason for setting up these systems.
But now, the use cases for syndromic surveillance has really grown.
It's used for a number of different things.
It's used to track infectious disease trends like the flu every year.
It's used to monitor mass gatherings,
because there could be events happening at mass gatherings,
whether health related or otherwise.
It's used to look at the impact of man-made and natural disasters, hurricanes.
And it's used to look at the impact of extreme weather events,
such as heat events or cold events.
So the use cases for Syndromic surveillance have really broadened over time.
Sure, Michael, why don't you talk about that.
Okay. Well, Florida has done really good work in this area,
and their system that they have locally is really the precursor,
the system that we have established nationally.
So, the hurricane Wilma came by,
they used it to monitor things like prescription drug,
or carbon monoxide, and things like that that
would help them respond better to the event.
We mentioned emergency department data,
but Florida is a great example where they're using
their systems to pull in all different kinds of data.
Poison data, emergency medical services data, et cetera.
They're really one of the premier programs around the country.
One of the things I wanted to mention about the importance of it is,
it's really about the timeliness of the data.
It's also about the ability to see things that you would not otherwise have reported.
So, for example, with the oil spill,
there is no code for oil spill,
but you might want to know whether health effect's related to the oil spill.
And because you get every record,
you can sort through what may be happening.
Yeah, I think it's important for people to realize that
syndromic surveillance is not about case finding.
We do a lot of surveillance at CDC and across public health.
It's about finding specific cases of infectious diseases or other types of things.
Syndromic surveillance is really prediagnostic.
It's all that information that's collected in an ED visit such as chief complaint,
triage notes, et cetera.
And we use different types of tools,
such as natural language processing,
to really dig through that very rich data,
to get a feel for what might be happening in a community.
Sure. So, we work off of currently the HL7251 standard,
and we have, over the last few years,
developed a standard messaging guide that would help
facilities determine both which admit,
discharge, and transfer messages to send,
and what parts of those messages should be sent.
And so, that actually helps organize the data in
a way that we understand what's coming from their system,
and they understand what they're sending,
in the same kind of language.
And then once we take those data in,
unfortunately, within HL7, there's lots of wiggle rooms,
so a lot of times we do some integration of our own,
where we're accounting for differences in whether you used
an OBX segment or whether you had it in a proper place, and things like that.
Once we kind of organize the data,
then we pass it off to applications that are prepared and ready to read those things.
Correct.
And I should add that the meaningful use program,
which I'm sure most people are familiar with,
has really been a boost for Syndromic surveillance.
This has really been the carrot that has encouraged
clinical care to share their data with Public Health,
both at the state and local level, and then eventually,
at CDC as well.
Sure. It's developed by the Johns Hopkins Applied Physics Lab,
and it's been in development since late 90s.
They worked first with the DoD under a ditcher project,
and there was a lot of
feedback from the public health practitioner community over the last 10 to 15 years that
has really helped them develop the application to do the types of things
that an epidemiologist at a state or local level wants it to do.
It's actually based on Microsoft SQL server in general,
and there is a lot of different DTS Packages and things that move data back and forth,
and transform data within,
they do some things to try to get the system to react quickly.
One of the things that makes ESSENCE different is,
you can do ad hoc queries on large text blocks,
which most systems won't let you do,
because it's pretty intensive.
They, of course, end up using cubes,
and using ways to narrow the focus down of your query,
so that you're within a reasonable amount of data.
But, at our level,
we've really been pushing the limits of that,
because the national size of things is quite large.
So, we're actually learning and redeveloping with
Johns Hopkins as we push the limits of that system.
I think we're up to about two and a half million messages per day,
and we keep having to increase our server size.
So, we really need to think about database management for the future,
and how we're going to deal with all this big data.
Well, there's different ways to measure that,
and I guess I would say that,
we're ordering 45 terabytes of space for the best,
or set of data.
But remember that HL7 messages come several,
it depends on the iteration or the implementation of the EHR.
You can get up to you know,
from 2 to 30 different messages per visit.
So, part of the problem is culling all that down and getting it organized.
But we have, after you do all that,
I think are around 300,000 visits a day that are coming through the system.
So when a patient goes to an ED,
we don't get a nice record that includes everything that happened to them at the ED.
Every time they have an encounter with someone,
whether it's an examination or a test,
all of those messages or records come separately.
So, we have the challenge of concatenating those records into a meaningful patient visit,
that can then be pulled into the analytic tools for analysis.
We have about 54% of all of the EDs
based on an AJ survey that we use to sort of determine the denominator.
And we have on the order of about 65% of all ED visits,
mostly on the eastern half of the United States.
But we continue to on-board the sort of western Afghanistan.
And I think it's important to clarify that
syndromic surveillance is most valuable at the local level,
because that's where public health takes action.
So most of the states in the country,
and many of the large local health departments,
New York City and others,
have their own syndromic surveillance programs
that are used across the health department.
And they're the ones that monitor the data on a daily basis,
and take action based on what they're seeing.
At CDC, we have the biosense platform that
receives data from the state and local health departments,
either a copy of the data or the data sent to us.
So, we don't really review the data and act on what we're seeing,
that happens at the local level.
But we have national and regional views that
can be shared and people are comparing their data with that,
we can bring states together when we see things happening across the country.
At different levels of public health,
whether it's local, state or federal,
you have different use cases for the data.
I think the heroin example would be great,
because that's a very timely issue now.
Sure.
Syndromic surveillance is becoming
the surveillance tool for opioid overdoses in the country,
because there's really no other source of data for this.
Right. So, we worked with our Injury Prevention Center to really understand what's
the best way to characterize
the heroin overdose activity
within the text blocks that we get, within the ICD codes that we get.
Remember that, though we get very
complete reporting for chief complaints and triage notes often,
we don't always get complete reporting with ICD codes.
So we do kind of a mix,
and they've been really honing in on how to best characterize what's happening.
And then, there's a visualization where you can see the percent of ED visits,
and you can see the trend line over time of
the heroin overdose activity for a couple of different sites.
And this the type of thing that will do,
either in conjunction with a CC program like injury,
where we're helping the folks in the field determine the best way to capture the topic,
and we can also look like Polysed
National or HHS regional trends and help to understand where do we need to put resources.
Is it worse in one area over another?
So, I think another important thing to understand
about syndromic surveillance is when you get this data,
what we do initially,
is to bin the data into syndrome category.
So, there might be an influenza-like syndrome,
there may be a heroin syndrome,
there's more than a dozen or 25 different syndromes.
So we work with the states,
the local and state health departments on those syndrome definitions,
because those are the definitions that are applied when you're analyzing the data,
so that you can really see what's happening.
And these syndromes change on a very frequent basis as new drugs or illicit drugs,
would come on the market in a particular community.
They can add some of that terminology to the syndrome definition,
so they make sure they're picking up what's being pulled out
of the emergency departments.
Thank you, Mark.
Yes, I'm Paula Braun.
I'm an entrepreneur in residence with
the National Center for Health Statistics at
the Centers for Disease Control and Prevention.
I'm Ryan Hoffman. I am a PhD student
in Biomedical Engineering in Dr. May Kwong's lab at Georgia Tech.
Yes. So, the clinical decision support tool that we're developing,
is specifically designed to help
physicians collect more complete and accurate information on
death certificates and to send that information to the state where the death occurred.
And what makes death reporting challenging is that,
the clinician is required to make a decision
about the sequence of events that led to death.
Typically, it's somewhat more clear to understand the immediate cause of death,
but to provide enough information on the death certificate
to ascertain the underlying cause,
can be quite of challenge.
However, there's ample information in
some circumstances in the electronic medical record.
And so, the tool that we've developed is designed specifically to try to fetch
that data and to put it in a easily interpretable display so that way,
the clinician isn't combing through
multiple tabs and spending a lot of time trying to figure out,
what is this patient's health history?
And it goes a step further where it's not just
about displaying information that's in the medical record,
but ultimately connecting to an external analytical engine that applies
more advanced analytics to return recommendations
about probable sequences of events that may have led to death.
Absolutely. So here you can see the main interface,
the main screen of our cause of death reporting prototype app.
The main feature of the app is this timeline right here in the middle.
We wanted to be able to show not just the immediate proximate causes of death,
but also add some context for the clinician.
The whole point of this app was to let us bring in all the information possible,
give the clinician the clearest picture that we could.
So, what we've done with this timeline is,
we've used a kind of logarithmic scaling so that we can show
the immediate causes and the deeper patient history all in one glance.
All of the conditions on this timeline were pulled out of the medical record using FHIR
and we filtered them based on a list of valid reportable mortality conditions,
try to limit the noise and make this just as useful as we can.
So beneath the main timeline where you see the extracted conditions laid out,
there are also these orange timelines.
What these are, are the results of the analytic system that Paula was talking about.
What they are, are the proposals for possible causal pathways which
might link these conditions into a chain of events that could possibly lead to death.
When the clinician needs to change,
modify, or add any causes of death,
we have an area down at the bottom of the screen that's designed to
resemble the death certificate that they are already familiar with.
Here, they can change any of the condition names,
correct any of the timeline issues,
and add new conditions if they need to.
These controls down here,
then allow the clinician to save this data
back to the medical record and complete the process.
Certainly. One of the first data sets that the students analyzed was an ontology which
is a list of known causal pathways that CDC provided to the students.
And these relationships were developed by
the National Center for Health Statistics and
other statistical agencies across the country and
they're commonly used as part of the automated coding system for trying to
assign an international classification of disease code
to underlying causes of death and contributing causes of death.
That data set is important because the space that it traverses is quite large.
And so, the challenge of mapping out the network and
trying to understand how you can move from one node on the network to another,
was quite computationally extensive.
Another data set that we're analyzing,
is the public use data set.
So the National Center for Health Statistics aggregates information
from death certificates that are collected across the country.
And what we have there is,
we have an ICD-10 coded representation of
what the physicians wrote on the death certificates.
So we've begun to apply various causal modeling actually.
So we have the information that
physicians actually put on death certificates and what we're beginning to do there,
is to look at what are the associations that most commonly occur.
And from that, we're beginning to get a much more nuanced understanding of,
what are the proper associations that
physicians are reporting on death certificates and where are
the areas where physicians may be putting things
in a sequence that's not actually ideologically sound.
And so, it's been very much
a learning process for us to be able to look at our data in this way.
And the third and perhaps the most exciting source of data that we're
analyzing in the process of building this analytical engine is that,
we've partnered with two of our states and they've provided
link data between the hospital discharge record and the death certificate record.
And this is where the students are really beginning to apply
deep learning methods to not only uncover associations,
but ultimately, causal pathways that then could be fed
back to the physician at the time that the physician is certifying the death certificate.
So in designing the prototype application,
the two most important data sets to me,
were the ontology containing all of
the valid causal relations between possible causes of death,
and the NCHS multiple causes of death data.
The public data that Paula was talking.
We use the ontology to filter down the conditions that we show in
the timeline to limit noise and make the interface more useful to the clinician.
We use sequential pattern mining algorithms to identify
common temporal links between causes of death in the public causes of death data.
And that was what we used in the prototype application,
to propose possible linkages between one cause of death and another.
Basically, to try and give the clinician a sense of how
these might tie together in a likely way.
And what's so exciting about the modularity of FHIR is that,
the app that Ryan is developing and the team is developing,
we could start with a simple analytical engine and
exchange it as the understanding becomes more evolved.
And over time, we're hoping that we'll have more people
that are contributing to these analytical engines so that way,
we can provide the physician the most and the best information at
the time that they're certifying the death.
Absolutely. So we designed the application to use SMART on FHIR.
It's a very traditional client based SMART on FHIR Javascript app,
that connects to the HR,
pulls these conditions out,
and does the filtering and display activities that I've talked about.
But, we also have it designed so that it can modularly be integrated with
additional outside servers to
provide additional services and additional functionality to the app.
Most interesting, are connections to the O-Methylisourea which we're using to
prototype code crosswalk to
try and make everything a little bit more compatible with our rule mining system,
and the actual rule mining analytics system.
We used a relatively simple,
sequential pattern mining technique for the initial prototype application,
but that is designed to be completely modular.
We want to be able to iterate on those algorithms over time,
improve them with use.
Well, Ryan and the team are taking the next step which is to
work with one of
the major electronic medical record vendors
on their SMART on FHIR app platform that they're offering.
And we have jurisdictions across the country that are
excited and lining up to test out the first phase of it.
That first part, will most likely not incorporate the analytical engine just so we
can learn the environment and get
some real world feedback before doing further development.
Thank you.
Dr. Aly Goodman, I'm a pediatrician and epidemiologist at CDC
in the division of Nutrition and Physical Activity and Obesity.
I'm a Senior Researcher for healthcare services.
And I'm Paula Braun.
I'm an entrepreneur in residence with CDC and the National Center for Health Statistics.
The public health challenge that we're addressing is pediatric obesity.
One in three US children are living with overweight or obesity,
both of which have major health consequences,
both for children and adults.
These consequences can be costly,
they can cause significant disability as children age.
And though, we've made some progress in public health in
terms of leveling off the prevalence or how many children have obesity,
we have a long way to go.
We still have approximately 12 million children in the US living with obesity,
four million of whom have severe obesity.
And with that, will come a lifetime of difficulties associated with that.
So, the challenge particularly in our area and in what I work in,
which is really at the intersection of healthcare and public health is,
how do we help clinicians and health service providers to
improve the uptake of evidence-based practices for child obesity?
And so, that includes screening,
which is a relatively simple process of weighing
and measuring a child's height at
every well-child check that most children get at least annually,
and then calculating their body mass index,
and plotting that on a CDC or World Health Organization growth chart,
to determine the child's percentile.
And by doing that, we can determine whether a child has a healthy weight,
is overweight, or has obesity.
And so, in public health,
we always say the first step is screening.
We have to determine how many kids have a problem.
And then clinically speaking,
if you don't determine,
you don't figure out that there is a problem,
then you can't possibly find a solution or help the child forward.
The second issue, of course,
is then preventing or treating a child's issues related to healthy weight.
And our best evidence suggests that,
when clinicians do some brief counseling on nutrition and physical activity,
determine whether a family is actually ready to make some changes,
and if they are,
offering or referring them to
a intensive pediatric weight management program, that's really multi-disciplinary,
it's family-oriented and typically occurs in the community and delivers
at least 25 hours of services over a six-month period.
So, all of those different clinical factors
can be assisted by an electronic health record
that supports the clinician in
making the right decisions such that you can best help the family.
In addition, the electronic health record can support program evaluation.
So let's say that a clinic health care system,
even a community system,
decides to do a variety of different activities to try to
help children or families living with overweight or obesity,
the data that are contained on a child's height, weight,
and body mass index in an electronic health record already are extraordinarily valuable.
So that you can look before the intervention and after the intervention and determine if
there's been any changes in the child or family's weight status.,
You can look at different behaviors,
all sorts of things.
And then lastly, electronic health records are poised to
really assist us in public health with something called surveillance,
which is the determining of how many people in a population have a particular disease.
And so, in the case of pediatric obesity,
we have national level data,
but we don't have a very good state or community level data in order to
provide feedback to public health programs, interventionalists, et cetera.
And that's where again,
because all these children are being seen,
their body mass index is being calculated,
is being plotted on this growth charts,
all those data are sitting in electronic health records.
And they could really assist us in public health and to really
move the needle in terms of improving child obesity.
Yes, it really just
started with a conversation between Dr. Goodman and myself.
Part of my role at CDC is to work with different people in
the agency and get them to experiment with and hopefully adopt these newer technologies.
And it was very apparent that the work that we were doing in
mortality could be applied across other sectors,
particularly around public health surveillance.
As I was showing Aly the SMART on FHIR app that had already been
developed to address aspects of pediatric obesity,
and we thought that,
that was just such a great place to start.
And because the code was publicly available,
we were able to extend it and adapt to this use case.
And so, it was more than just what happens in a clinical setting.
It was a recognition that childhood obesity is
really something that takes an entire community approach to address.
And, we imagine a world where
all of the interoperability challenges had already been solved.
What information would we want to provide to whom?
And what would they do with that information?
And over the course of the semester,
the project really took on a life of its own and it continued to evolve.
I think we called it the dream, right?
So, what's the dream which was connecting patients and providers?
And then having excellent care coordination that
then connected providers to communities, community resources,
public health and then having bi-directional flow between all of those entities
in order to sort of maximize what you're doing as a community,
in order to get better effect,
which has been shown in lots of studies to be the best way to address
child obesity in a community and for specific children as well.
The apps evolved over time. It was pretty interesting.
The first semester, we divided it up into four apps.
One that faced towards a patient,
another towards the provider,
a third towards a care coordinator,
who was really interfacing with community resources.
And then lastly, an analytics app that could
do some of the work that we discussed before,
regarding looking at different numbers and so looking at
prevalence of obesity by all kinds of different cut points,
something we do a lot in epidemiology and public health.
So that's how it started.
And then, I had met some providers at
Children's Healthcare of Atlanta and they're Strong for Life program,
which works on pediatric obesity in the Atlanta area.
And they had a project that they were doing with Georgia WIC,
the women's and children's program which
provides supplemental nutrition assistance to women and children under age five.
And, what they were doing was trying to connect pediatric primary care providers and
the WIC nutritionists and facilitate
communication through the electronic health records of both of those providers,
to see if improve communication could lead to
improvements in a child or family's nutritional status.
And so, we worked with them and started modifying
several of the apps that we had created for that use case,
which is a little bit different than the first one.
And then from there, we went on
to the next team of students really wanted to work on privacy and security,
and particularly on that patient facing app,
that base towards families,
where they could interface then or carefully work closely with their provider team.
And then, the last most recent iteration was,
how can we integrate breastfeeding information.
Breastfeeding is really important for women and children.
We know that it is an important intervention for children's and women's health.
And, we also know that it can be
associated with healthier weight over a child's lifetime,
actually and for the mother, too, over time.
And so, integrating that information into the apps created just another,
it wasn't really a change in the use case, I guess,
was more like an addition as to how can we integrate other information.
Sure. Here, we see the original patient-facing app.
It gathers information from the family directly and
the child's healthy habits information.
So specifically, in this screen,
what you see is a picture of fruits and vegetables.
We're asking the family about how many times per day the child eats fruits or vegetables.
And you can see on the bottom that the family can pick from one of five options.
So, those options and that question itself have been tested in
numerous clinical trials and different studies and shown to be
a relatively effective measure of looking at that very important information.
So, it helps the family not only reflect
on how they're doing in terms of fruits and vegetables,
but also that information is really critical to the provider,
because when they start discussing nutrition,
they know where the family starting from.
The next app is the provider-facing app
which is the one that was largely based on information or coding,
and the app that was built by Boston Children's as their growth-chart app.
But we were able to add some additional features that are helpful for
clinicians as they're tracking growth including extra data points.
Third, we have the care-coordinator app.
We were really impressed with this one.
The concept was that when a provider clicked on a button and sort of said,
"Please refer this family to community resources," the app could take
the information from the electronic health record on the patient or families address,
and then map community resources that were nearby their home.
And so, in this app,
you can see they developed a map that could show
the family where a variety of resources to support
healthy eating and active living were relative to where the family lives.
So here, you see nutrition support resources including the Tower Grove Farmer's Market,
and different markets, and community supported agriculture spot.
In addition, this app allowed secure messaging
between community resources and the provider.
Because as a provider,
very often when we refer families to community resources,
it's sort of a black box.
We make the referral, but then we have no idea
whether they've gotten there, what happens there.
And we try to ask families and find out how things are going.
Very often, the visits that we have with families as clinicians are very short.
It's very difficult to get all the information.
So, it's quite helpful to have that information ahead of time,
be able to look at it before you walk in to see the family.
And so, here you can see this combined inbox that
allows a care coordinator to see, "Oh, look.
This family went to the Farmer's Market.
They completed a questionnaire for the doctor.
They actually did get to the YMCA and scheduled an appointment."
And so, picking up as a clinician from that information and moving forward with
the family is just a much more efficient way
of providing prevention and treatment options.
Lastly, you see here a screenshot of the analytics app.
And the concept here is that it's taking information on some sort of population,
whether that's the population of patients that the physicians sees,
or within a practice group,
or even larger health-care system.
And it's combining that information on lots of kids,
and then slicing and dicing it in all different ways.
And so here, we've got some charts on blood pressure amongst the population, weight,
and BMI, and you can display that in different formats.
FHIR was an essential part of this project,
especially in thinking about potential scalability issues.
FHIR presents a common way of fetching information from the electronic health record.
It also provides through,
the SMART on FHIR platform,
the ability to add functionality to electronic medical records that didn't exist before.
Aly spent a lot of time talking about
the Boston Children's app that we modified for this project.
But the other apps also could be SMART on FHIR projects.
So, the patient-facing app,
the care-coordinator pacing app.
And FHIR provided the lingua franca,
that just allowed everything to be able to communicate with one another and ensure that
the information went where it needed to go and that people
had it at their fingertips when they were making critical decisions.
Well, this is an exciting project that has evolved.
And as I understand, it will continue to evolve
in future variations in the class.
So, thank you both for taking the time to come here today and talk about it.
Thank you.
Thank you.
Anything else?
I think we got plenty.
Do we want future iterations?
You had said you wanted that but do you not?
We can do it.
Do you have a sense of where it's going at?
Since we're sitting here.
Yeah, we might as well do it.
So, that would be?
That would be Aly.
Yeah.
So Aliy, this project has gone through several iterations.
I understand you have still more for the future.
Can you tell us a bit about that?
Sure. We're really excited to keep developing these technologies.
We actually got to showcase some of these recently at the Hymns 2017 Conference.
And we were flabbergasted quite frankly by their response,
and how excited clinician's,
public health professionals, and health-care executives were,
to actually see clinical apps that were dealing with a very prevalent problem,
solving so many issues regarding communication,
clinical decision support, analytics,
population health, all of that.
And so based on that excitement,
we are next going to hopefully partner with some academic researchers who
really are absolute experts in the field of
clinical decision supports for pediatric obesity.
And these are clinical decisions supports that have been
tested in multiple research studies.
It have shown to be effective.
So, we're going to go back to our apps,
go back to our code,
and sort of re-adapt and reinvent those
clinical decision supports to be in line with what these researchers are working on,
with the hope that
the researchers will be able to actually
implement them in real clinics with real families,
and test whether those supports through the apps actually lead to a change in behaviors,
or weight status for children, or their families.
I'm glad we asked that question.
Yup.
Now I think we're done.
Okay. That's all that you get condensed to 10 minutes.
Sure. My name is Carmen Clelland and I do go by nickname of Skip,
so that's fine for Skip.
I started my career within the India Health Service and
spent 20 plus years within clinical functions,
with India Health Service, and then also
administrative services within the India Health Service.
Later, past three years,
I've been working at the CDC.
During this period of time though,
I've always had an interest in medication adherence,
the issues of medication here,
and what it means to a patient level, provider level,
public level as far as,
how can we identify ways to help provide solutions to
medication adherence and why is
such an important issue to address overall as a public health issue?
Sure. The apps that we we're looking at because of
the overall greater focus on public health medication adherence.
Now, when I talk about that,
what I'm trying to explore is,
how can we use public health data along, or just regular,
even Big Data, along with the information that we would get from potentially,
a patient medical record through an EHR,
an aggregate data form for physicians,
for pharmacists, for patients,
for public health professionals,
in order to drive a change in dynamic,
and how people view medication adherence?
The goal was as if we were to identify how medication adherence is within a county,
or a census tract,
or in a case,
one of the areas that we were thinking of was a tribal tract,
and be able to say,
in this part of the city,
or this part of the reservation,
or this part in rural America,
or this part in a county,
that you know that your adherence rate on a certain medication is 60%.
Well, how can we identify that in order to
drive medication prescribing patterns, maybe drive education,
maybe drive other factors that might be involved,
even to planning of cities,
or planning of rural areas,
and making sure that we address it on a more public health role issue,
looking at population health,
then being able to help improve that patient's ability,
to have all the things they need in order to have better medication adherence practices.
That was the goal of this and it sounds kind of lofty.
One of the things I worked with the two teams,
and it's interesting because the interaction between the two teams was different too.
One was very engaged,
the other team was slightly engaged,
although they didn't need that subject matter expertise,
being a clinical pharmacist all those years,
I was able to provide that to that team with some information,
and then follow up and so I met with them maybe just a couple of times.
The other team though was more engaged,
they wanted to have some more input about what medication here it was,
why was it this issue?
Why did they think that FHIR technology
and being able to develop strategies to help support that technology in use.
A population health data could help solve this issue.
I went through with that team,
my thinking on this,
and why I thought this could be a way to look at it.
They were very much engaged,
and ended up developing
a nice framework concept that would lead to a proof of concept at some point,
in order to say, "Can we develop these applications using FHIR Technology,
Big Data, insurance claim information potentially Medicare claim, Medicare claim data?
All those things that can be accessible,
and then using it to be able to use it as a population tool to help prescribers,
pharmacists, patients, and then public health professionals
that develop the right strategies to improve medication adherence."
Because, if we make just overall group strategy of doing medication adherence,
it may not apply to the person in inner city versus the person in the rural,
versus the person on a reservation,
versus the person living wherever they are,
and having better aggregate data in
those population areas that we want to really focus on,
will help drive better prescribing patterns from physicians,
better counseling from pharmacists,
better ability to take the medications from the patients,
and better public health campaigns from the public health practitioners.
That is the strategy on that.
The framework that the one team developed,
was called the Medication Adherence Support System Conceptual Architecture.
And what the goal of that,
was to look at it from that perspective,
of not only just always focusing on that patient perspective,
but looking to say,
"Who are all the people that need to interact with that?"
And then how does that interaction need to coordinate together,
to be able to drive the data into the interface,
and then being able to regurgitate it out in a way that is meaningful to that physician,
still meaningful to the patient,
meaningful to the pharmacist meaningful to all,
to the public health practitioner,
and supporting the overall goal of,
"I want that patient to be healthy,
I want to be able to take the medication and we know if they take their medication,
chances are they will have mostly success with whatever chronic disease,
or other issues that they're working to deal with."
And so, that was how that architecture was set up.
As you look at the architecture that they developed,
it really is strategic in nature,
where you can actually focus on various elements of this concept architecture,
and continue to develop,
we may be one module over here,
and another module later,
in order to some point,
in five years maybe,
have the full architecture put together,
that would then you could go out and use to be able to help
drive public health medication adherence,
and then eventually, affecting as a population strategy.
That's how the architecture was developed and it's very detailed
in how they came up with that conceptual architecture.
What the team did,
that did the conceptual architecture,
they also worked on initial component of an app,
which is the Patient Facing App.
And probably for most of the apps that we see,
that's probably the easiest because it just requires patient data input,
as far as, "Did they take the medication?
What time of day did they take it?," those types of things.
There's a multitude of those out on the market.
That was the first strategy that both teams actually
ended up creating examples of their apps,
and doing that, and what that would look like.
Both of them had some good components to it with regards to,
when they miss doses, what was that,
or what was the cause of missed doses?
One of the things that I cautioned them on that is,
when you're talking about the patients,
there's this whole fatigue issue
of being overwhelmed by always having to put stuff into a program,
or having to hit a buzzer or something to that,
where eventually you start phasing it out,
and it just becomes background noise.
And how do we use that strategy in the future to help prevent these things?
Where you get your key information into those patients facing apps,
and then being able to retrieve that out at the other end,
so that way, the physicians,
and the pharmacists, and the public health people,
can have access to that information,
clean of course, so that way it doesn't identify patients at a patient level,
but enough, where they can say,
"In this urban area,
in Atlanta, medications in ward
six is only taking hypertensive medications 40% of the time.
Why is in Ward 6 that is creating this as an overall thing?"
That way we would want to explore and then you'd be able to say,
"Now I can do it, because I have the data.
I can go to my city planner,
I can go to the pharmacist,
I can go detail physicians,
and let them know this is a strategy that they can do."
And so that's how the architecture was set up to do,
to be able to support that,
and make it into something that's workable,
usable, and eventually in the end,
be something that can make an impact.
I think the next step,
it needs to go in a couple of different phases.
Clearly, there's work done initially on the patient phase,
but it's not complete as the way these were.
I can't remember how many weeks the sessions were
so they had limit time with their team together.
There's still need to work on that patient app.
There needs to be development on how to build in the FHIR Technology,
bringing in the FHIR Technology,
along with Big Data to incorporate,
so you can start seeing conceptually,
how Big Data impacts decision-making at a county, census tract,
tribal tract, other population modalities of how you to
identify groups of people and then bring that into an application.
Because I think that's when you'll start seeing how you can drive this information.
There's plenty of patient apps out
there that you might be able to get some information from,
and I'm sure there's a lot of people,
skilled and looking at it from that perspective since that's
the most common way people would use to help say,
"I can help improve adherence."
But then driving in this other point,
so I think the next phase for me,
and what we're looking at with this,
is to drive that population health data
gathering along with access to some sort of patient records system,
that includes claims data, those types of things.
That would be able to make this a more comprehensive look at medication adherence.
Then with that, look at that population health part of it,
and then saying, "How can we affect health equity because of what we're using?"
Now with data making decisions versus
the anecdotal information you tend to get from patients, "I'll take this",
or the late dose,
"I'm going to start taking this a week for my doctor's appointments,
so that way doesn't look like I'm not," or other things.
And it's not necessarily all the patients fault,
it's just the way our system is set up,
to not necessarily look at medication adherence as an issue,
it's more or less,
the chronic disease issue.
But if you're spending hundreds of billions dollars a year on medications,
and there's a lot of that being wasted,
then we're looking at also something that can have
an impact on our health care of our system overall,
as well as our public health systems overall too.
So that's the next strategy on this. Thank you.
Yes, absolutely. Thank you very much Dr. Bronstein for having me here and for
allowing me to mentor your students during the spring 2017 semester.
So, I am a full time employee and
graduate student at the UT Health School of Public Health, Brownsville Regional Campus.
So Brownsville is down at the US-Mexico border.
It's the farthest tip in Texas.
I've been there for about three years
and I've been working in health informatics for about four years.
So I graduated from the UT Austin Health Informatics Program,
they have a certificate program in Austin,
before coming to this job.
And I worked with our local regional health information exchange,
the Rio Grande Valley Health Information Exchange,
to connect to clinics and hospitals in the region,
and also work on an initiative called Project Diabetes and Obesity Control
which is a project from the UT system to basically
integrate data from data sources other than electronic health records so that we
can bring care to outside the four walls of the clinic.
Absolutely.
I'm really interested in
this concept of bringing data outside of
the clinical environment to the clinical environment.
Go for it.
Earlier in the course, I introduced them to the term real world data.
Real world data.
Okay, perfect.
That's probably the new term.
Okay, great.
You might regarding this term. So let's do that.
Okay, perfect. Perfect.
Should I ask the question earlier?
Yeah.
So, can you prompt me again? Sorry.
What was the project and why is it important?
I am very interested in the concept of
real world data and bringing in real world data
into the clinical environment so that practitioners and patients,
too, can be empowered with this data to make decisions about their health.
I'm specifically interested in the nutrition domain.
The project I proposed was to create a FHIR application to visualize
results from a nutrition algorithm that takes components from purchases.
It takes the physical items that were purchased from a grocery store,
scores them from zero to 100,
and comes up with an aggregate score,
displaying that alongside of data from electronic health records for
providers and for patients.
Right. Exactly. It's an approximation of their eating habits.
There's another algorithm out there called the Healthy Eating Index and that can
be used to identify the nutrient quality of the food supply or of an individual's diet.
And it's always approximating their diet.
You never know if what they bought is what they're actually going to consume.
But you can come close to assume that if this is the food that's in their house,
that's their food supply, that's probably what they're going to be eating.
And also, it's probably closely correlated with the personal choices they make.
If they buy vegetables from the grocery store,
they're probably eating healthy outside of the grocery environment.
But if they buy just meat and sugar,
that's probably what they're eating outside the grocery store as well.
But there's some studies.
I think, there was a study in 2012 that sampled,
I think it was a smaller area.
They identified, 60-80 percent of
people's food consumption comes from the grocery store and convenience stores.
We can make a pretty sure assumption
that the food that people are buying are what they're eating.
Absolutely.
There are a few nutrition algorithms that currently exist.
There's definitely a need for additional nutrition algorithms.
The one that I mentioned,
the Healthy Eating Index,
is actually far away from being implementable in a real world setting,
to actually use the data from purchases to approximate a healthy eating index score.
There are a few,
so Healthy Eating Index is one.
There's also a front-of-package labeling system called
Nouvelle which was developed by faculty at the Yale School of Public Health.
And they don't allow you, actually,
to aggregate the scores from the individual products that are purchased.
And then a third that we decided to use for our project is NutriSavings.
So they claim 85 percent market share in the US.
And one of their partners is Wal-Mart.
That probably accounts for most of the 85% market share.
But what NutriSavings does is they work with
employer-based insurance programs to score people's purchases,
the covered participants' purchases,
and they provide that information to the covered entity and also to the consumers.
We worked with them to get a sample data spec
and built sample data to populate our application.
The goals of the semester were to basically
create a mock application
that demonstrates the ability to combine these two data sources,
electronic health records and the purchasing data, nutrition algorithms,
in hopes that grocery stores will see this,
the potential of use of this real world data,
and would be more willing to share their data.
That's one thing that NutriSavings is kind of crippled with right now.
And I actually personally asked some retailers but they're reluctant
to share their data outside of the four walls of their facilities.
But we can look at the application now.
I think it would be good to show you the back end of our system
and how we imagine a clinic
working with a local grocery store to enable this application.
in this diagram, it's a bit complicated but I hope I can talk through it well,
we have data providers on the left.
These are electronic health records who are in
the area and these are clinics that have electronic health records.
And then, we have a grocery store partner and an imagined interchange or
some database that can take in the data
from the electronic health records and from grocery stores.
Ideally, this will be a FHIR compliant server that has
some other storage means for the grocery data or even,
I guess, the software application could query NutriSavings and get the data in real time.
We basically designed this for a local model.
We have a partner that is providing us with an interchange.
We wanted to implement this project after the spring.
This is why we have in this way.
And then we have Georgia Institute of Technology here
designing the front-end applications that we query for our compliant server.
Here, if a clinic is interested in becoming involved,
to get an absolute match to not have
to use a patient matching over them which we could absolutely use,
we would have the provider give the patient a NutriSavings,
calls it an employee ID because they usually work with employer-based insurance programs,
to track the patient.
And typically, NutriSavings works with rewards cards
to track people across grocery stores.
And the participant would take the rewards card to the grocery store and scan it at
a participating grocery store which would identify them across
the electronic health record and with
a grocery store and would allow that data to be shared with NutriSavings.
And NutriSavings currently generates
three types of data so they can provide a trip score for individual grocery trips,
items received at those trips,
and then also a monthly summary for that participant.
We thought it would be good to
allow the provider to see all these different types of granularity.
But also see a monthly score at the high level.
I'll show you the front-end application now.
The front-end application, we have Jane Smith here.
We decided to make this as simple as possible
for this could be a registered dietitian or a provider.
During our spring project,
we interviewed two register dietitians and two M.D.s for the project.
And then, we also had some consultation from a consulting firm.
And this just basically shows a tiled view of
different relevant clinical items from FHIR resources, from the EMR.
We have like a respiratory rate, hemoglobin A1C, glucose,
HDL, LDL, BMI and the actual nutrition score.
We could integrate additional metrics as needed.
But these were some that the registered dietitian thought were
important for further practice.
We have a high level of view here where
the provider can see all of these different tiles,
and if they click into one,
we're clicking into the nutrition score,
they get a graph view that shows the monthly summary for the patient over time.
And if the provider were to click into any of these month points,
they could see the trip summaries over time as well.
This was a very simple tool.
We wanted to do a minimal viable product but
some things that we think could be incorporated are like a notes function,
a goal setting function.
Unfortunately with this, we don't have a very high level of granularity.
We're only seeing the monthly score and the individual scores.
This nutrition index just shows the nutrient density of different items purchased.
Somebody, for example, somebody could
just buy apples for an entire month and their score would be 100, right?
The scale is from one to 100.
But just eating apples is not enough to fulfill all of your nutritional requirements.
I think there's a huge need to get
more granular data from grocery stores and actually like working with NutriSavings,
they weren't able to share
that granular data and they're only able to share these nutrition scores,
these aggregate nutrition scores.
I think it's absolutely necessary that we get more granular data both so that we can
develop additional algorithms that are more granular,
and so that we could actually provide clinical decision support.
I think, I love the CDS Hooks Initiative that's going on right now.
I think would be great if we could build some CDS Hooks that are relevant
to nutrition and we need access to that granular data.
I'm hoping that as we build more of these applications,
we can use this to show grocery stores that
there's utility for this data and hoping that if we build it,
they'll come and they'll give it to us.
I think that's a good overview of the software application.
We began this course with a discussion of the critical problem of chronic disease.
We learned that it accounts for most US health care costs and that
the design of our health care system is not well suited to chronic disease management.
To correct this, we discussed the need for new care models,
better design for the management of these diseases.
We also discussed the critical role that patient behaviors
play in the development of chronic disease and in its successful management.
Finally, provider reimbursements in
the new care and payment models we discussed earlier in
the course are usually based on care quality and clinical outcome metrics.
In the next segment,
we will see that Population Health began in response to the need of
providers to understand and improve their performance against these metrics.
Like public health, it is an important use case for
interoperability since individual providers in some network or
system that is contracted to deliver
cost effective outcomes will usually have different EHR's.
Finally, we will also learn that like virtually all other domains of Health Informatics,
population health is increasingly employing
analytic technologies to predict and proactively manage clinical results.
Thank you, it's an honor to be here.
My name is Mason Beard,
and I run Product Strategy and Marketing for Philips,
and specifically, the Population Health Management Business.
And I am Philip Burgher,
and I am the director of Software Development for Data Platforms.
All right, so briefly, it's going to be
a little bit of challenge, but I'll do my best.
So in 2005, I helped start a company with my brother-in-law,
who is an internal medicine physician,
and the company was Wellcentive.
It was purchased by Philips about a year ago.
And back then, we started our first population health management focused-business.
And I know from this course,
you've been learning about switching from pay for procedure, volume-based billing, etc.
to more of a quality-based pay for performance healthcare delivery model.
And in 2005, we learned that there was a commercial plan,
Blue Cross Blue Shield of Michigan, that was paying on quality.
The other thing that we quickly learned is that
health systems are very confusing organizations.
So it's made up of certain doctor relationships,
some are employed, some are affiliated,
that means the affiliated using a ton of different EHRs.
So at first, we realized that nobody is really solving this problem,
nobody's focused on helping doctors prove their quality,
and the people that were doing it before us, the payers,
it created a lot of static,
because the data quality issues,
and there was not a lot of trust in that data.
And so, we saw a business opportunity,
first identifying the problem, then creating the solution.
From 2005 onto today,
if you think about what's happened to move from fee for service
to quality from the ACA to ACOs,
every acronym under the sun,
we've continued to grow as basically organizations
switch from fee for service-minded billing and tracking,
to more around quality.
That's actually really easy,
I don't know why anybody else can't do it.
No, it's been very challenging.
I've been in this game for over a decade now,
and the term that we've been
using for a long time when it comes to the state of the data,
when it comes to health care is the Wild Wild West,
and that is still very true.
There's been lots of talk and movement at a policy level about
getting everybody on to a same standard when it comes to formats or coding systems.
But the truth of the matter is that as of today,
And so, it's really still quite the challenge.
You have to kind of build a foundation of the house or the pyramid,
or whatever structure you want to talk about to make it possible to
do all of the population health analytics that everybody is talking about these days.
So kind of the first step is just getting the data.
There are political and technical challenges there.
You have to be flexible,
that's been our philosophy.
Once you have the data,
you have to make sure that it's high quality,
and there's all sorts of very deep rabbit holes that we can go into there.
And then finally, once you have all that,
and everything's kind of in one place,
and scrubbed, and consistent,
then you can start really doing the cool stuff,
which is the measurements,
the machine learning, where you can really start improving health care.
One of my favorite quotes is,
"If you can't measure it, you can't improve it."
We're to the point where we can measure it,
and everybody's trying to figure out how you can improve it.
Yes, the data aggregation is definitely the what,
and the mechanism, but the why is payment reform.
They're being paid differently.
It's not a volume-based business anymore.
And everything that you do as risk is shifted.
And I know you've learned about this in
your course that payers are shifting risk to the providers.
So the one dollar that they could spend,
they're looking at making sure that they have high quality,
health care delivery, and watching the cost.
So we really think about it.
And I have some slide here to show you that
we think about the problems we're trying to solve now is four.
They have a quality problem,
so they're looking at the quality of the services they deliver,
because that's how the payment is going be tied to. They have a revenue problem.
They have, as we say,
a foot in two canoes.
They have to have a fee for service foot in that canoe,
and they're slowly putting their weight into
a value-based care canoe as bundle payments come around,
MIPS, macro reporting requirements,
ACO contracts, risk-bearing contracts, etc.
They're learning to basically shift the revenue.
They also have a market issue.
Patients are becoming consumers.
They're not patients anymore, they are customers,
and they're used to shopping on Amazon and looking for the best value they can.
So you have to think about that,
those patients in your area as a market,
and how to continue to grow that market.
And the last piece is access.
Right now, if you look at traditional healthcare delivery,
patients are receiving care in the wrong place.
And what I mean by that is the most expensive place.
So they're looking at solving those problems from an access perspective,
not going to the ER, but maybe talking
to a care manager or being routed back to a primary care office.
It's a lot cheaper, better patient satisfaction,
and many times higher quality.
I wish there was an easy button, right?
And I guess you wish there was an easy button as well,
on the tech side.
That's true.
There is no switch that says we're going to do population health management now,
insert two keys in the basement of hospital and turn it, right?
So if you look at the graph I have up here,
is we look at this as a transformation.
Your every health system in the United States is on a journey,
and essentially, they're moving from left to right.
So if you look here at the bottom of this graph,
we've got different payment models going from the far left, you have fee for service.
Moving all the way as risk is shifting to those health care organizations,
you're moving to the far right.
As you grow in this model,
and as you transform,
there are certain competencies that you have to
master before going to the next stage, if you will.
So just quickly, if you're on the left -side of this model,
you have a understanding problem.
You need to aggregate the data,
baseline your performance of clinical and financial measures,
and just understand where kind of due north is.
When you move over to the right hand side of the model,
you're going to start to do.
And we feel like the first thing that you're going to
start to do to affect the population,
is going to be care navigation.
You want to start steering patients to a higher quality,
lower cost center, not the ER, but the PCP office.
Maybe deploying telehealth or mHealth.
The last stage of this is going to be more activation.
And I'm sure, in this course,
you've learned about patient engagement,
ways that you can basically empower patients to take control of their health.
We feel like that that comes after an understanding of the data,
after you've started to master some of these navigation techniques,
and then you can get into deep, deep engagement.
So it's a deep topic, steerage.
So healthcare systems want to make sure that patients stay in network.
And health care plans have things called narrow networks,
essentially define which doctors you need to see.
When I talk about access and navigation,
I'm saying that you're going to the right doctor,
but you're also going to the right care center.
So many problems health care systems have is over utilization of ER,
and it's an access problem, right?
So you've learned in this course about PCMH models,
where they have extended hours,
weekend hours, you can actually go to your primary care.
That's because it's higher quality and lower cost.
So access and navigating patients
is a whole domain that fits into population health management.
That is that first step in doing,
once you get the data, and have that understanding.
And I think ER utilization is a great example of kind of
a low-hanging fruit when it comes to population health,
because the data requirements for that are pretty simple.
If you can get an ADTV from your hospital network,
most hospitals can do a push notification
for when a patient presents themselves in the ER,
integrate the longitudinal chart, all of a sudden,
you have an event that you can queue to kick off the rest of that process.
What's really cool that we're seeing more and
more of in the industry is that's a very reactive process.
How do you become more proactive?
How do you keep them out of the ER in the first place?
And that's where you get things like social determinants of health,
machine learning, clustering of patients.
Risk stratification.
Risk stratification. When you
ask about the how and how you actually start to move the needle,
there's a very interesting corollary of
the maturity from the network governance point of view,
and the data implication as well.
Yes.
Sure. Yes, our machine learning is very tightly
integrated with our data quality philosophy as well in
that the machine learning is kind of shoring up at
a programmatic level the poor data quality that we see in a lot of charts.
One of the main challenges with identifying your high risk patients
is how do you do that at scale with that data,
and that's where machine learning can help a lot.
So, we've applied algorithms that look for data that is missing
from one chart because it's similar to
this chart and this chart has a confirmed diagnosis.
We're using social determinants of health to try and figure out
whether there's a corollary between this population and that population.
So are you sure this patient isn't diabetic?
Things like that nature.
And I think what's important in what Philip's saying is,
is if you think kind of back to that model of maturity and transformation,
what Philip's talking about is getting very proactive.
When you're doing predictive analytics and predicting who's at risk for
a hospital stay where one of those lower level skills after you aggregate the data is,
okay, we get an ADT feed from the hospital that a patient was admitted,
now let's signal a care manager to call in to make sure they get connected.
That's kind of after the fact, right?
So, what Philip is talking about is the next step and it's definitely a higher level of
maturity on their ability because they've gotten from reactive to proactive,
and they're doing that because they're at risk for these patients and the cost.
Yes, and you think about the earlier you can detect the problem,
the less expensive it is.
Absolutely.
And so, before the ER,
there is the doctor visit.
And if you really want to get out there a little bit before there's the doctor visit,
there's the data that can be collected outside of the office
where mHealth comes in.
Yes, I think both of us can.
But yes, it's really an interesting evolution where we went
from payers using claims data to basically determine quality,
to now we were talking about EHR data,
HIT data in general.
This is a new era, so we're bringing in social data.
One of the things that we like to quote is that your zip code is probably
the most important data point for determining your health and your risk score.
The other thing that we've learned over the years is
that credit score can be extremely powerful in determining medication adherence.
So if somebody that has a higher credit score,
they're going to be more apt to follow doctor's orders and to be managing
their medications as prescribed.
Sure, it's a great question.
There's a lot of talk around FHIR but the reality of the situation is
that we don't see a whole lot of it in the real world.
And I think the nature of that is just that the use case of FHIR,
it was designed for taking care of a patient one at a time, small data sets.
And when you're talking about data at the population level,
the mechanisms involved in FHIR just don't really scale that well,
specifically the query retrieve method of interoperability.
If you think about it from a agnostic aggregators point of view,
there's no event for us to reach out and pull down information.
That's kind of like a giant game of Marco Polo to figure
out where the patient is presented out in the community and let's go get that data.
So from creating the longitudinal chart,
we don't see a whole lot of traction there.
However, where we do see a lot of hope is kind of on the flip side.
Once we've gotten the data any which way we can,
we've done all the analytics,
we've created the quality artifacts,
a challenge that we've had is workflow.
The people who need to see that data are in the EMR.
They will have one tool,
there's been problems galore with adopting those tools and they're like,
"I've finally got my EMR to the point where it's usable.
Don't make me use something else."
Totally understandable.
And that's where we think FHIR can help a lot because it's
a standard way to get data back into their workflow.
We've actually had a lot of
conversations internally and with the standards organizations about,
this is what we see is the population that use case for FHIR.
So, if I could, I just want to throw one thing in here and maybe it's
just to provoke some thoughts for the members here in this class is,
this use case is very encounter-based.
I have a patient that I know needs to be in front of a doctor and I'm going to optimize
that visit leveraging a different technology that pulls in longitudinal data.
What happens when that encounter or we blur the lines of an encounter,
what is Telehealth? What is mHealth?
What is continuous monitoring?
Right? So, the use case that Philip just laid out there is real.
That's what we're tackling today.
But when you think about where healthcare is going,
that line of an encounter,
that activity is going to blur.
And that's kind of the next frontier that we're going to have to tackle.
The patient engagement piece,
the patient activation piece,
getting them more in charge of their health and
interactive with technologies is absolutely the next frontier.
I think that it's pretty ahead of the market when you think about that right now,
because I personally feel that we are trying to engage
physicians right now into a new world and they're still
grumpy about their fee for service revenue being
cut and they're trying to learn a new way of doing business.
But absolutely, the next chapter is engaging
patients and if FHIR is supporting this type of protocols,
that's absolutely where it needs to go.
Yes, that's a great point because when it comes to consumers,
everybody has a smartphone and everybody knows how to
use an application and that is what FHIR is designed for.
I get that question a lot because people, I think,
generally think of Philips as an industrial company but we've been in
healthcare since 1918 and have been very innovative.
And I look at kind of the old world of hospital
systems being the center of the universe and Philips has had a lot of hardware,
CT scanners, MRI scanners,
patient monitoring systems that are inside the hospital.
But where Philips really is growing is in
the health tech and getting outside of
that hospital from a patient engagement perspective,
from home Telehealth to mobile apps to wellness.
And then from a Wellcentive perspective,
we give context to that.
So Philips has a big footprint and a big footprint means a lot of
data that really goes outside of just a hospital and with now,
Wellcentive, we apply context to that data for value-based care.
And the other thing,
and Philip touched on this when we were talking about FHIR,
is there is a DNA to HIT systems and,
not to go down that road,
but EMR's have a certain DNA.
They were built to schedule and bill in a fee-for-service world.
Philips plus Wellcentive is,
I will call, an agnostic aggregator.
They can sit across the health system,
across many EMR's and pull that data.
There's a lot of power in being the agnostic aggregator
and helping these use cases out where there's a lot of limitations
if you kind of come from that episodic DNA, if you will.
Thank you. It's a pleasure.
Yes. Thanks very much.
My name is Rahul Basole.
I'm a professor in the School of Interactive Computing at Georgia Tech.
I also lead the Initiative on Enterprise Transformation at Georgia Tech,
where we study large complex enterprise systems.
My particular research area is on visual analytics and visualization and I've applied it
to many problems in healthcare.
Sure.
So it turns out that process mining is actually
a relatively old field in many other domains and health care.
Manufacturing certainly is one of those domains,
where you've had very detailed process charts on how
widgets and products actually move across the manufacturing belt.
In healthcare actually, we have a complete different process situation.
It's much more complex.
In fact, when you go into an healthcare enterprise,
it's very unlikely that you see very detailed process maps.
The Children's Healthcare of Atlanta Project actually is
a result of some of the other efforts that we've had before,
where we realized that scaling,
process mining and analysis jobs is really difficult.
In the old days, you would walk around with a clipboard and observe how people did work.
And incredibly time consuming, resource intensive.
In some cases it might take three to six months to
actually get things really accurately done.
With Children's Healthcare of Atlanta,
our goal was to reverse engineer data that already existed in electronic health records,
maybe in claims data,
to understand how processes actually happen, how they get done.
Perhaps understand how these processes fit together and understand variations in care.
Absolutely. So as I mentioned,
my research area is visual analytics and visualization.
So, really exposing the processes is really critical.
And so, what you're seeing here is a screenshot of a tool that
we've developed that visualizes these complex care processes.
On the left hand side,
you'll see a panel where you can filter
through various aspects of the patient population.
So you can focus down on elements of interest.
And you're seeing a graph and network modeling approach to understand how care happens.
The nodes represent activities and events.
And, the edges represent whether they co-occurred,
and when they actually happen after each other.
It's been a fascinating process,
because we actually discovered variations in care by population characteristics,
as well as by physician characteristics.
And the goal was really to discover processes,
identify variations and hopefully also enhance these processes.
One byproduct of this was also to understand conformance to the processes.
Many physicians have guidelines on how care should be done.
And our visualizations really revealed what happened and what didn't happen.
Yes.
So process mining,
you want to look at a population.
But sometimes that population is just too large and
there's just too much variation that happens within that.
So you want to hone down, filter down the ideas.
And so, given the advent of fhir and the ability to have access to digital data now,
we wanted to figure out how we could build a population health analysis tool.
Based on the ideas of visualization and analytics,
that could dynamically explore different patient characteristics,
by different population characteristics.
So ultimately, we built a tool called fhirplug,
which leverages the fire standard.
And, as you recall,
fhir really was not designed to look at all an entire population.
It was built really to look at one record at a time.
So fhirplug is a tool that aggregates
this information and allows you to really filter through multiple facets of that data.
So let's take a look at fhirplug here.
It's a web-based visualization tool.
What do you see on the left hand panel and ability to load your data set,
your fhir enabled data set.
And then, you can focus down on specific aspects that you want to look
for certain search criteria, a condition perhaps.
And once you've load that in,
you see five tabs at the top which actually reveals to you that it's an overview.
It's about process characteristics,
about patient demographics, as well as develops clinical elements.
And each of these tabs is fully coordinated.
That's very powerful in visualization,
when you coordinate multiple views to get a triangulated perspective on the data.
We're using across filtering mechanisms.
So, as you are filtering through one of the charts,
you can actually see what,
how it response in the other ones.
We've enabled multiple visualization charts within this,
including scatter plot and heat maps.
And this really allows the decision maker
or the clinician or also quality managers to look at their patient population.
Well, there is a lot of enhancements that we can obviously do to fhirplug.
Fhirplug right now, we tested it out on some synthetic large,
synthetic data sets, as well as in practice as well.
But we realize there's a lot of nuances,
because healthcare data is very messy.
As you scale up, there might be some issues that we
might discover that fhirplug cannot handle.
Scalability is certainly always an issue in software development.
And so the next steps will be,
to test it out with multiple healthcare sites,
test out scalability and see where that goes. Thank you.
This lesson does not provide details on how to do analytics.
Rather we will explore
the specialized infrastructures and tools that support research on,
an exploration of, health data at scale.
Generally this involves aggregating
at least the clinical part of that data from a large number of
digital health records.This introduces
the interoperability issues we've been discussing throughout the course.
Advanced analysis of these big health data sets offers the promise of more precise,
personalized care and the use of
predictive tools to anticipate and treat clinical problems much
earlier than was possible in the past.This
analysis must overcome many typical problems and limitations of the HR data.
Despite the challenges we are clearly heading into a new era of medicine and health care.
This lesson provides you with at least a feel for what that might be like.
The world is awash in data.
It is growing at exponential rates.
People have coined the term big data,
to refer to this phenomenon,
but often can't agree on what it means.
What separates big data from everything else?
Cesar Hidalgo at MIT Media Lab,
says that to qualify for this distinction,
data must be big in size, resolution and scope.
To re-frame this idea,
in a way that is directly relevant to transforming health care delivery systems,
data must represent many patients and providers.
It must do so in detail,
and as we will now discuss,
it must be combined with other data to give the real world context,
within which patients live and get sick,
care is delivered, and the delivery system operates.
Real world data is a relatively new term
encompassing data derived from a number of sources shown
here that affect clinical outcomes in
a heterogeneous patient population in real world settings.
Earlier in his interview,
John Duke use the term observational data and
it is essentially a synonym for real world data.
We also refer to this kind of data in our discussions of public and population health.
So, their impact goes far beyond individual patient care.
The hope is that analysis of this
richer and broader data set will generate meaningful insights into
unmet needs and interventional strategies with
greater clinical and economic impact on patients and health care systems.
There are of course as shown here new challenges
introduced when the range and scope of data sources expands.
Understand the potential value of real world data.
I suggest you read a short but interesting and insightful article by
a trio of researchers at Harvard's Center for biomedical informatics.
This diagram from it
organizes potential health data sets along different dimensions of bigness.
The authors point out that while electronic health records provide depth by including
multiple sources of data such as images and
clinical notes about individual patient encounters,
claims data provide longitudinally,
a less clinically detail but more continuous view of
a patient's medical history over an extended time period.
Medical data may be episodic and
incomplete if a patient receives care from multiple providers.
Typically, there's only one payer for a time period so that payers
claims from within that period should be a more complete record of care delivered.
On the other hand,
claims data lacks clinical detail.
A request for payment for a lab test order would be in a claim
but the results would not be included as they usually are in any H.R.
As a result, the authors of this paper say,
"linking data adds value when they help fill in the gaps.
With this in mind, it becomes easier to see how nontraditional sources of
biomedical data outside of the healthcare system fit into the picture.
Social media, credit card purchases,
census records and numerous other types of data despite varying degrees of quality,
can help assemble a holistic view of a patient and in particular
shed light on social and environmental factors that may be influencing them."
Obtaining and aggregating health data presents many domain specific challenges.
Think back to earlier in the course when we discussed
HIPAA and the protection of patient privacy as
well as obtaining patient permissions for the use of
their data unless it is fully de-Identified.
However, depending on the use case,
fool the identification can substantially reduce the value of the data.
Where genomic data is involved,
the identification may not be feasible if that data is to have any research value.
Even with patient permissions,
all the interoperability issues we discussed
earlier can be impediments to aggregating data for research.
These include the reluctance of hospitals and
other sources of clinical data to lose control of it.
Without semantic interoperability, and it is still rare,
data from multiple sources must often be normalized
to a standard model to be useful for analysis.
Earlier, John Duke discussed
the Federated Research Model and the use of
the Observational Medical Outcomes Partnership,
OMOP, data model across a research network to solve many of these issues.
We will talk with John about the tools to analyze data that is in the OMOP model.
Health care is a diverse and rich field for research and analytics.
We will now consider a few examples to explore that diversity.
The historic gold standard for developing new medical knowledge,
is the controlled clinical trial.
You have two equivalent,
randomly selected patient groups,
alternate therapies are a new therapy and
a placebo and see which group does better over time.
These are difficult to do.
Finding and recruiting the right patients is hard.
These trials take a long time and they're expensive.
However, if the question is whether a new treatment works
better than current treatments in actual human patients,
there's currently not a good alternative approach.
Next, we will consider the problem of early diagnosis of the disease.
Congestive heart failure occurs when
the heart muscle does not pump blood as well as it should.
It affects 5.7 million people in
the United States and there are over 200,000 new cases each year.
A 2013 paper, calculates that
the total direct cost of heart failure is from 60 to $150 billion annually.
According to a review article in Mayo Clinical Proceedings,
quote "No single test can be used to establish the clinical diagnosis of heart failure.
Instead, history and physical examination findings showing
signs and symptoms of congestion and are in Organ hypoperfusion,
are used to make the diagnosis.
Imaging studies documenting systolic or diastolic dysfunction
and Byer markers, are helpful adjuncts.
Thus, the diagnosis of congestive heart failure may require many types of clinical data.
A point you should remember when I interviewed Dr. Jimeng Sun in the next segment.
Providing help for this problem comes from predictive analytics,
his area of research.
Finally, a different question,
what is the optimal treatment strategy among
already known and available options for a given group of patients?
As opposed to the classic research questions determining optimal treatment,
will require many alternative experiments.
That is, trying every possible treatment strategy on groups of similar patients.
These types of questions are best addressed through
modeling and simulation using digital health data.
There are a number of techniques for doing this.
Again, this is not an analytics lesson,
but we will be interviewing researchers who do this kind of
work to get a high level view of it in healthcare.
Sure, thanks Mark.
My name is Jimeng Sun.
I'm Associate Professor at the College Computing in
the School of Computational Science and Engineering.
And prior to Georgia Tech,
I was a research staff member at IBM T.J. Watson Research Center for six years.
Sure.
So, EHR data really
has many challenges if you want to build analytics model using those data.
So number one is the messiness and unreliable information in those data sources.
So oftentimes, some information about patient are
not recorded and they're only recorded during the visit,
which are very sparsely scattered over time.
So, we don't know what actually happened in between two different visit.
So, a lot of the information are not in the data.
And whenever they are in the data,
they're not all accurate.
Some diagnosis could show up but that doesn't mean the patient have the disease.
They may just come in for screening but the code still show up for billing purpose.
So, you can't really trust the data a lot.
Sorry, you can't really trust the data all the time,
so you have to really leverage many other different way to figure out those information
is reliable or not.
Sure. So, for EHR data,
it has many different sources.
Such as, in the structure field,
you have diagnosis code, medication, lab results.
Then you have unstructured field.
Those are clinical notes,
often times are dictated or entered by clinicians or nurses directly.
So, many people actually think that unstructured clinical notes
consists of most reliable information that clinicians put in,
and all the other information such as
diagnosis code and other things are derived from there.
I mean, unstructured data itself is very messy.
Again, it's not really a well drafted article that people can read and understand,
it consists a lot of acronyms and the sentences are very short.
It's really those unstructured data serve as a note for
the clinicians themselves so next time the patient comes
back they can remember what happened in the previous visit.
So, how can we extract useful information directly from that noisy,
unstructured form, it's very challenging.
So, the way we do it is leveraging two source of information.
One is, there are a lot of medical oncology
that researchers have built up over the years.
So, that tells us what different spelling of the word
means and acronyms means in the clinical documents.
So, we use oncology to help us to extract a lot of clinical concepts directly,
so that we can map those very diverse set of mentions
of clinical concept into a consistent concept ID.
Then the second way we're dealing with unstructured information is,
leveraging the core occurrences of all those mentions.
When two medical concepts co-occur in a clinical document,
especially if they are very close by in the same sentence or same paragraph,
oftentimes they are related.
So, we leverage that co-occurancy information to help us to derive the relationship
of those medical concepts.
Sure. So, as you probably have described in your previous class.
I mean CHF is very important condition and many things can lead to heart failures,
and it's very challenging to predict the onset of heart failure earlier.
And the way we're approaching that is,
we integrate all source of information about patients from their EHR,
then construct diverse set of features that characterize the patient representation.
Then use those features and trying to correlate those features to the outcome,
which is whether the patient has a CHF or not.
And then build a predictive model,
leveraging all those different diverse set of features.
So, this is a standard predictive model pipeline.
It has two different phases,
the customization phase and the standardization phase.
So, the customization phase involves extracting features from raw data.
In this case, the raw data can come from structure EHR such as diagnosis, medical, sorry,
the structured data can come from diagnosis code,
medications, and lab results and unstructured EHR are usually those clinical notes.
And there's two different ways to extract features,
either you directly map those structured variables into features,
or you have to do some natural under
processing from the unstructured data to extract that features.
Once you have those features,
you can put all of them together,
then the downstream modeling is pretty much standard.
And you take all those features,
and trying to figure out which one are predictive to your final target, for example,
if you want to predict onset of heart failures,
only the features that are relevant for predicting heart failure will be included.
So, the feature selections that will remove most of the irrelevant features.
Finally, you have a classification model
to map the relevant feature to the outcome to make the final prediction.
The performance of the predictive model usually come from the quality of the features.
If the feature are predictive,
then the model will be good.
So, here's just one example showing the impact of different type of features.
And the Y-axis is the performance score in terms of area under the curve,
so, the higher the better.
And the X-axis is the number of feature you included in your model.
So, we start with a set of domain,
or we start with knowledge driven feature.
Those are the features such as co-morbidities that are relevant to heart failure.
And, you can see if you only include those features,
the performance is about 60%,
slightly above 60% of accuracy.
And then after that,
if you used a data driven features,
such as the feature selection asset,
then trying to find
all the relevant features that potentially predictive to heart failure,
you can see a huge jump in terms of performance from about 0.62-0.7 or above.
And more features you included,
it become more predictive.
Sure. So, in the past, or even now,
it's pretty standard to follow the process of taking the data,
then based on your domain knowledge and your understanding of the data,
to construct a set of features that are really meaningful to a domain experts probably,
then trying to figure out a way to correlate those features to the final outcome.
In this case, heart failure or no heart failure.
But the challenge for those approach is,
you have to understand what features are relevant
to begin with in order to extract those from data.
But the challenge is,
for heart failure for example, in that setting,
not all the predictive features are known to the clinician or to the domain expert.
So, it's very hard to manually create all those features.
And the new approach we're taking,
we're using deep newer network or
deep learning approach that directly model the raw data,
that as long you know EHR data,
those events sequences, both structured data and unstructured data.
And the algorithm, those deep learning models,
will automatically extract and construct a feature and then correlate that with outcomes.
So, we don't have to provide those feature in an ad hoc basis.
Now, the algorithm can figure out those features by themselves. Thank you.
Now that you've met Dr. Sun,
we will discuss one of his projects in more detail.
I appreciate his permission to use the graphics.
Children with complex chronic conditions accounted for
These admissions used around 25% of the pediatric hospital days,
accounted for some 40% of pediatric hospital charges,
caused over 40% of pediatric deaths,
and used 75% or more of technology assistance procedures.
Given the seriousness, and cost of care for these children,
understanding them and predicting changes in their condition is of great interest.
Here's an analytic pipeline for doing that.
First, we will focus on the feature construction phase.
Clinical classifications software CCS,
is a tool for clustering patient diagnoses and
procedures into a manageable number of clinically meaningful categories.
Here you see mapping the many ICD and CPT codes from EHR records to CCS.
As you see here 73 of
the CCS features have sufficient predictive power to be included in the final model.
Various approaches to prediction are tried,
and two random forest and gradient boost decision tree
produce the best results as you see here.
Random forest depends on the random selection of
both data and independent variables to create many decision trees.
The output is the mode or mean prediction of the individual trees.
Gradient boosting is a machine learning technique that produces a prediction model using
regression on an ensemble of weak prediction models, typically decision trees.
The graph is a Receiver Operating Characteristic (ROC) curve,
where each point represents
a sensitivity specificity pair corresponding to a particular decision threshold.
The area under the curve auc,
is equal to the probability that
a classifier will rank a randomly chosen positive instance,
higher than a randomly chosen negative one.
Informatics for integrating biology and the bedside, i2b2,
is an NIH funded effort based at Partners Healthcare System in Boston.
Its mission is to enable clinical investigators to conduct
research using state of the art genomics and biomedical informatics.
i2b2 supports complex clinical research environments.
But it provides an easily understood database schema that can be used to create
a data warehouse where
large clinical abstracts from an enterprise EHR can be stored for future analysis.
This is important because the database schema of
commercial enterprise EHR can be dauntingly complex,
proprietary and not necessarily designed well to support ad hoc queries.
As shown here, i2b2 implementations are comprised of cells
that communicate via web services and in aggregate form in i2b2 hive.
The role of most of these cells should be clear from their names.
Custom cells can be added to the hive and there is
an organized i2b2 users group to share information
and applications and to create the potential for
research collaboration and federated queries across institutions.
Here, you see the addition of a fire cell to support smart and fhir apps running against
the data in the i2b2 instance. All right, just keep going.
The National Institutes of Health Clinical and translational science awards program CTSA,
seeks to facilitate that translation of research into clinical practice.
Harvard Medical School has created SHRIN,
the shared health research informatics network.
A web based software network,
SHRIN links the respective I2B2 instances of five of
Harvard's CTSA partner hospitals for the sharing of aggregated counts of patients.
Meaning selected inclusion and exclusion criteria for demographics,
diagnoses, medications and lab tests.
The goal is for SHRIN to enable population based research,
assessment of potential clinical trial cohorts and
hypothesis formation for follow up study by combining the H.R.
assets across the hospital systems.
The department of biomedical informatics at
Harvard Medical School is working with health care centers across the
U.S. to develop the scalable collaborative infrastructure for
learning health system S C I L H S, pronounced Schils.
Each site will install a software suite comprised of
I2B2 creating a federated query and response system using SHRIN,
the smart platform, the Indivio PHR and
the redcap research electronic data capture tool used to survey patients online.
There is of course,
great interest in and potential for genomics research.
Earlier, we mentioned personalized or precision medicine as a major goal for health care.
While social, environmental and other factors
clearly affect the development and course of disease,
genomic variations are a major determinant
of each person's health and response to treatments.
There are at least two major challenges that informatics,
supplied to large genomic data sets can help solve.
Many genomic variations are rare,
so aggregating data from multiple centers is important.
It's often necessary to correlate these variations with clinical data,
to understand their ramifications.
It's worth repeating that last point.
We do not yet understand the ramifications of most genomic variations.
By linking clinical data where the phenotypic expression
of genomic variations is stored with the genomic data,
the hope is that we can understand these relationships.
Genomic research networks may overcome these challenges.
For example, three major pediatric health systems
recently formed the Genomics Research and Innovation Network, GRIN.
Because each alone may have only a handful of patients with a particular rare disease,
to help better understand the clinical ramifications of gene variations,
GRIN seeks to create a broad database of annotated genomic and clinical data.
It will add RNA proteomics and
metabolomic data to an existing shared library of genomic sequencing data.
The network also wants to connect
the genomic data with imaging results and electronic health records.
The initial focus is on early childhood obesity,
growth disorders, short stature, and epilepsy.
The epilepsy project explores epileptic encephalopathy,
a process where epileptic activity impairs overall brain function,
including cognitive function, language and behavior.
As you can see here,
in data from online mundanely inheritance in man holmium,
a number of genes may have an association with this condition.
Once exome sequencing is completed,
the data is to be stored in a joint shared cloud environment,
combined with extracted phenotypic data from
the electronic medical records of the three centers,
in an effort to better elucidate and understand these relationships.
Sure. I'm Jason Zutty.
I'm a research engineer at
the Georgia Tech Research Institute in the Electro-Optical Systems Lab,
and we are working today on a SMART protocol for appendicitis,
which is a data-driven approach to guiding a patient through
their post-operative care to get them the best outcomes in the shortest length of stay.
Correct.
There have been several traditional protocols implemented.
They've been kind of expert guided so doctors will sit around the room and
kind of decide the key decision points in a patient's care.
Our approach is to be data-driven and patient-specific so
you'll be guided through care similar to patients,
most similar to you.
So, if anyone had good results,
it'll kind of guide yours and the protocol will continue to
evolve as more data is taken in the hospital setting.
Purpose of the SMART protocol
is to standardize care so we're looking for
a disease or surgery that affects as many children as possible,
and is fairly regular and easy to standardize.
So appendicitis affects over 80,000 children a year,
and we've been working with Children's Healthcare of Atlanta,
which has a data set of roughly 1,200 appendectomies performed every year.
So that's a good big data area to look at and it's a fairly standard thing to care for.
Yes.
We're looking at complicated appendicitis or perforated appendicitis,
which occurs in about 40 percent of
the appendicitis surgeries that are happening at CHOA.
We're looking at this in particular because they have a much higher rate of
negative outcomes and a longer hospital stay,
which are both opportunities for quality improvement,
improving the negative outcomes,
and reducing the length of stay.
The reason that this is the case is because we find that wound in infection, sorry,
wound infection and abscess rates occur at about 5-25 percent
depending on the patient and readmission rates are approaching 15 percent,
for perforated appendicitis care.
And we find that there's lots of variation that can be standardized,
from the use of diagnostic imaging,
to laboratory tests all the way to which kinds of catheters are used,
in all sorts of components of their care.
So the goal is to standardize those,
and get the patient out as fast as possible without,
well while reducing the risk of readmission rates.
So the data sources we're using are approximately, or exactly,
we're using six years of data from CHOA,
From 2009-2014, that have been collected and disseminated to us directly from CHOA.
It comes from two different locations,
which is Egleston and Scottish Rite,
two CHOA campuses in Atlanta.
And we have more than 120 what we call features,
collected from pre-intra and post-operative care.
From that data set,
we're trying to identify the negative outcomes,
which we have defined to be an occurrence of a UTI,
sepsis, deep organ space SSI,
superficial SSI or pneumonia.
Whether or not if a follow up procedure was performed,
which we call a re-operation,
if the patient returned to the emergency room after discharge,
which is also call a return to the system,
and if the patient was readmitted to the hospital,
which is your readmission.
From our entire cohort,
we had about 6,000 appendectomy cases which
which we used a metric of how long they stay in the hospital to identify that,
which was greater than two days,
which is a standard approach.
And of the 3000 cases that were perforated,
we had 705 examples of negative outcomes for the perforated cases.
We are using machine learning.
There's a reason where there's a little story here,
which is we started with the idea of being able to find all these key decision points,
in their care protocol.
But the problem is, the resolution of our data.
You don't have necessarily the points we need.
What we want to be able to do is
say when their daily temperature reaches a certain amount
or falls below you know when they haven't had a fever for
a day and they're tolerating a good diet and all,
and you know we've come up with some metrics discharge.
Otherwise, keep them another day.
If their white blood cell count falls below this, order this test.
Unfortunately, we don't have the kind of AB testing or
the resolution and the daily data to be able to identify key points yet.
They've started collecting that.
In the meantime, the key part of the SMART protocols can be able to kind of
predict whether or not they're going to
have a negative outcome or what their length of stay is going to be.
So, along that vein,
we started doing machine learning.
The other thing that kind of plays into this is
that we have to present it to the user directly so machine learning,
we have 120 features collected and we can achieve some pretty good statistics using that.
My research, in particular,
is in the automated algorithm design,
which is combining machine learning techniques together using
genetic programming to design all sorts of algorithms pipelines that would
help minimize the false negatives and
false positives and try and get our best kind of area under the curve that we can.
But we can't ask 120 questions to the patient by presenting them with
an iPad so we need something that runs fast in
between each question and kind of prioritizes
the questions so we get the best resolution in to
our data without overburdening the particular patient or overgeneralizing the model.
We can't run a machine learner in between each question to try and find
the next question and things like that so we have to be kind of
fast, and we have a lot of data.
Instead, we built a collaborative filtering kind of approach or a filtering model,
which basically goes through and correlates
each feature with whether or not they had a negative outcome,
and the most predictive variables are presented as
the next question and each time the data is filtered down.
So that's the approach we took.
The results have been pretty good so far,
in terms of the first cut.
There's plenty of room for improvement.
The data is split by years into training data and validation data.
We used four years for training data,
which were 2009, 2010, 2012,
and 2013 and our validation data was 2011 and 2014.
The way we did this was we had the validation data kind of enumerated so each patient in
the validation data set kind of would have walked through
the predictive model that sits on top of the training data.
We found that we had a very very low false positive rate,
which corresponds to a 97 percent specificity,
but on the flip side of that we had a pretty low sensitivity,
or a high false negative rate of about 75 percent.
We think this is mainly due to the fact that we kind of lumped
all the negative outcomes together for this first pass,
which we did because we needed to have a kind of
good cohort of what is a negative outcome.
If we split up any particular vector at this point,
so we're looking at just re-admissions,
if we're looking at just signs of infection or sepsis,
we found that we didn't have as many negative cases.
You need the kind of the predictive power behind it to do
a good predictive model so we lumped it all together.
As we continue to collect more data,
we think that these statistics are going to improve.
The positive predictive value or
precision was about 58 percent so that your confidence in your prediction.
So when you say it's going to be a negative outcome,
you're about 60 percent sure,
which is better than a coin toss.
We also had a very strong negative predictive value,
so when we say that it's not going to be a negative outcome,
we're 88 percent sure that.
This resulted in a model of an overall accuracy of 87 percent.
We definitely want to get
the app that we've developed so far in the hands of clinicians
and families to kind of get some feedback as to how is the interface for it,
are the predictions it's giving useful,
is the information it's conveying useful as the quality of those predictions?
We also want to continue to collect more data,
especially some timers all data so get some daily ideas
of how well patients are tolerating meals,
what the daily maximum temperature is to find if they've become afebrile,
which means that their fever has cleared and things like that,
which would be helpful in designing the SMART protocol.
We also want to explore alternatives to the filtering model or ways to improve it,
may be balancing the correlations between the negative outcomes and the length of stay,
and things of that nature.
We're also kind of looking at this point for extramural funding.
Sure.
The first part of that is the filtering model that we have behind it.
The filtering model is going to be
basically trying to minimize the number of questions presented to the user and it
does that by asking questions based on which features are
most correlated towards negative outcomes for a particular patient.
As you go through,
if the question has a numeric answer it's going to
basically throw out half the data set which is furthest away from
the current patient and maintains
the cohort patients that are most similar to your answer.
If the question is a non-numeric answer,
it's going to down select down to the answers that match from the cohort.
At any given time, it's going to basically display the statistics
for the remaining data and how it splits up
based on the future choices that the patient will make.
Here's an example of our initial three questions that are presented to the user.
These have been shown to have some predictive power but they're also deemed
necessary by the medical staff so they're expertly
guided questions as data that we need to collect.
We prompt with three questions at the beginning,
which is how many years old is the patient,
how long have they been in the hospital,
and what type of appendectomy did they have,
being laparoscopic or open?
Once they ans- answer those questions,
the data will be filtered and
the most predictive feature will be identified in the question.
Discriminating that feature will then be asked and so if we carry on like this,
eventually we'll get something along the lines.
What we see here, where
we've gone through several questions at this point in our current question is,
what antibiotic were they given prior to their surgery?
Here, we can see on the top there
current kind of cohort based on all the questions that have answered so far,
how many patients are similar to them,
still in the data set,
what's their average length of stay,
and what's their probability of a negative outcome?
Then we also show right below that kind of the confidence intervals.
These are the bounds on a 95 percent confidence interval.
The opacity here indicates the tightness of
that confidence interval so the tighter the confidence interval
the darker the shade of the particular cell,
while the color is indicating the performance
of a particular choice relative to where you are now.
You can see here for example that meropenem
has a much higher percentage of negative outcomes so that is going to be
a more orange warning sign than
the cool blue that indicates everything is getting better or about the same.
Here, you can see all the different choices that you can
input and how they kind of affect the data behind it.
You're welcome. Thanks for having me.
Sure. So, the OHDSI tools were really designed to bring together the set
of most common tool kits that people would use for doing observational clinical research.
So, if you wanted to ask a question of a health data set,
what OHDSI has done is brought together in one package,
which we call ATLAS, a set of tools to understand your population,
to understand individual cohorts within that population,
and to be able to explore those pre-clinical research questions.
It's actually a nice compliment between FHIR and in OHDSI.
In that, FHIR typically is that the individual patient level pulling data down.
Where OHDSI really typically looks things at a population level or at a cohort level.
So, they're very complementary in fact.
Sure, absolutely.
So, indeed ATLAS does roll together all of
these different components that are part of doing observational research.
So, as you can see here,
there's an initial piece which is around data set exploration.
And if you look here,
and you click through to the individual dataset explorer,
you can pick a dataset of interest,
you can look graphically at the populations,
you can look at how many people are taking different medications,
how many people have different conditions on their list.
So, that's a key part of understanding,
"What do I have to begin with?
What does my population look like?"
But if I want to go to the next level and build a particular cohort,
which you would do if you were going to ask a question.
For example, how many patients over 50 with diabetes are taking Metformin.
Well, if you want to define,
"What do I mean by patients with diabetes?"
And to do that, we use the cohort builder tool over here.
And by clicking through the cohort builder,
you have an option you can see to graphically create and select a series of
different conditions that are relevant to diabetes.
You can select medications that are relevant to diabetes and laboratories,
and those are all defined in this way here.
You pick a concept set.
That concept set is then created by a vocabulary explorer.
The vocabulary explorer says, "Let me look at
Metformin medications or other diabetes drugs.
Let me look at ICD 9 codes that mean diabetes and then go up to the parent level,
that can include SNOMED concepts,
ICD 10 concepts, and so forth."
And you roll those into concept sets.
So, the way that this vocabulary explorer complements
the cohort builder is to allow you to create your little bundles of,
when I say diabetes here's what I mean in terms of codes.
By doing this, we can then run these population level estimation analysis,
which is that final piece of ATLAS, where you can say,
"I want people who have diabetes and have taken metformin and I want
people who have diabetes and have taken other medications such as sulfonylureas,
and I can look at the outcomes."
And that can be looking at, for example, myocardial infarction.
So by creating these three cohorts are what we call a treatment cohort,
what we call a comparator cohort,
and our outcome cohort,
we can then automatically run through
the ATLAS tool a very sophisticated analysis which is rigorous and
actually publishable almost directly from the code that's run
in the ATLAS tool.
Exactly. And so one of
the major initiatives that we're taking on this year here at Georgia Tech,
in collaboration with our colleagues at Stanford
is building a formalized Fino type library.
Where people can review what were
the conditions that were considered in designing a given phenotype.
What was the performance in terms of the precision and recall of a given cohort.
And provide additional information,
so that if someone wants to reuse this cohort in their own environment,
what they can expect in terms of its performance.
We also encourage people who do run studies to upload their own findings.
As far as how well did this definition do in my local system,
and it then allows us to produce better and better cohorts to share with the rest
of the OHDSI community.
It's a really exciting time.
I think for OHDSI as a community that has
now grown well beyond its roots looking just at drug safety,
into where with people considering studies around genomics and around value based care,
certainly looking at population health at large.
We've even had a number of people say,
"We want to look at clinical trials themselves using OHDSI,
" which is interesting given
the original ideas around observational research and clinical trials being separate.
The other big piece though, is with FHIR,
we're now seeing a easier pathway to go from EMR data of all stripes,
and from all different systems into an OHMOP common data model.
That GT on FHIR or OHMOP on FHIR project done here at Georgia Tech,
allows people to very rapidly implement a conversion from
FHIR into OHMOP and take advantage of all the tools that OHMOP has.
At the same time, if someone builds
a predictive model using advanced machine learning methods,
many of which have been developed here at Georgia Tech,
or extensively refined here at Georgia Tech,
those predictive models can then be run through
an EMR system to actually do a prediction for individual patient.
So, the connection between clinical decision support and
large scale analytics has really been
enabled by this combination of FHIR and OHDSI together.
So, it's a great time to be working on this,
and I think it's only going to grow in the years ahead.
Thanks very.
My name is Shamim Nemati.
I'm an assistant professor of
biomedical informatics here at the Emory School of Medicine.
Prior to coming to Emory,
I was a Ph.D. student at MIT where I worked on
developing algorithms for early prediction of success using the MIMIC database,
which is the world's largest critical care public data set available.
This data set was developed over a period of 10 years using
the data from the Beth Israel Deaconess Hospital Critical Care Center.
And my intention was to build predictive analytic algorithms that can catch
sepsis ahead of time.
So sepsis is related to
blood infection and is the number one killer of people in the ICU.
Every year around 750,000 people they
die in the intensive care unit due to consequences of sepsis,
with the annual cost of over 20 billion dollars.
If you want to break it down it turns out regular individuals who go to
ICU they may stay there for 45 hours or so,
versus for septic patients they may stay in the ICU for over 110 hours.
So this added length of a stay in the ICU is one of
the causes for increase in costs associated with sepsis.
I developed these algorithms at MIT using the MIMIC database and when I came to Emory,
I wanted to validate these algorithms using the Emory data.
So I went to the clinical data warehouse here at Emory,
that is a database that is built on
Emory patients and I asked the question, "do you have the data?"
And they said, "yes."
So I got the data and I right away noticed that the data format is very
different from the data that I had previously from the MIMIC database.
So I spent the next nine months cleaning up the data
and put it in the right format for my algorithms to use.
Right away I realized that,
that would not be practical in general.
Then I decided to build a similar algorithms for real time data and I
realized that I had to do the same thing with the epic and [inaudible] electronic medical records.
That's when I started talking to
the Georgia Tech team and I described my problem to them and we
together we decided to build
a FHIR based sepsis prediction algorithm and that was the beginning of our collaboration.
Yes.
So the app is called sepsis watch and it was built in
association with the Georgia Tech CS44O students during their spring semester of 2017.
Let me actually show it to you.
So the idea of this app is to build
a predictive analytic algorithm for early prediction of sepsis.
However the problem that we have,
is that for data elements to end up in
their patients electronic medical record for us to use it,
a clinician should order these labs to begin with.
Let's focus on an example lets say lactate.
It turns out lactate is important for prediction of sepsis.
But if a clinician doesn't order
the lactate test then you don't have the lab test to make the prediction.
So the first part of this application was to create
visualization for clinicians for most important lab values,
as well as one a step ahead prediction for the labs.
If the lab value in the future is larger,
higher than a critical value,
then the clinician may decide to order a new lab test or decide to
use the lab test value in the context of a predictive analytic algorithm.
If you know that the patient is at risk for sepsis,
using these lab values we can project ahead and we can make a prediction of our sepsis.
Sure.
So here is where FHIR actually is very, very important.
So the first step was to reformat data to make it in a FHIR compatible format.
This allows us to use the same algorithms that we developed for the
Emory data and the sepsis data to apply it to the data that we get here.
With the help of FHIR,
we map the data elements to a set of meta data that are also
known as the fire resources.These fire resources they become the input,
our predictive analytic algorithm for prediction of sepsis.
Once this step is taken care of as a next step we use the FHIR,
a sort of FHIR platform to create visualizations for the clinicians.
So in this case the visualizations involved explain
the current and future values of the labs as well as
risk values for prediction of our prediction of sepsis.
One of the nice thing about working with the students was that some of them they were
very good on the back end and front
end developments with the servers and the smart on FHIR.
Some of them were experienced in machine learning.
So they tried a number of different algorithms and we
settled on a cox proportional hazard model that
aims to look at the patient data at the current time and make
predictions for sepsis up to six hours ahead of time.
With the use of this method we were able to achieve
a very high level of sensitivity and specificity.
As I recall the AUC of the model was around .85 at the level of 85 percent sensitivity.
Which means if you want to catch 85 percent of septic patients
their specificity was around 0.75,
which means around like 25 percent false alarm.
This is really remarkable.
That's why we're very excited about taking it to
the next step and having a clinical implementation of this algorithm.
Here at Emory we
have the privilege of working with very sharp and motivated clinicians.
Our director of critical care Dr. Buchman is
a huge supporter of this type of applications.
I'm currently working with him and
his team to come up with a clinical implementation of this.
So as a first step what we are planning to do is to hire some of
the Georgia Tech students to implement their app on our electronic medical record.
Once the app is in place within the context of our electronic medical record,
then we would need to run the application in the so called silent mode.
What it means is that you run the algorithm in
the background without actually influencing clinical decision making.
So since here you're dealing with prediction task,
the algorithm runs in the background and
gathers the statistics and the statistics tells us how
often the algorithm is able to detect sepsis before the clinicians.
Once that part is done and we can show that in
a real time setting the algorithm can detect sepsis before clinicians,
then we will be in the right setting for proposing
a clinical trial to show it in a more randomized setting.
So that's the next step of our work.
But the FHIR goes beyond this type of validation works.
We have a number of active collaborations with other teams across the country.
They have their own algorithms.
They want to verify and validate their algorithms on our data and vice versa.
FHIR gives us a common language for data exchange and collaboration.
And I think this is the way of.
